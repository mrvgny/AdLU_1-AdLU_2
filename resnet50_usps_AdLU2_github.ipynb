{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fvjp6TVbv_I-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "from collections import defaultdict, deque\n",
        "from sklearn.metrics import cohen_kappa_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import USPS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Y2YtKH5FxHXX"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "SEED = 45\n",
        "NUM_CLASSES = 10\n",
        "EPOCHS =5\n",
        "MAX_EPOCHS = 100\n",
        "PATIENCE = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AriStxaOzr1J",
        "outputId": "581ce790-d529-4e98-b55e-69ab9340c072"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed set as 45\n"
          ]
        }
      ],
      "source": [
        "def set_seed(seed =45) -> None:\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.use_deterministic_algorithms(True)\n",
        "\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    print(f\"Random seed set as {seed}\")\n",
        "\n",
        "set_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YCrcUcnz4Jeh"
      },
      "outputs": [],
      "source": [
        "def reduce_across_processes(val):\n",
        "    return torch.tensor(val)\n",
        "\n",
        "class SmoothedValue:\n",
        "    \"\"\"Track a series of values and provide access to smoothed values over a\n",
        "    window or the global series average.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, window_size=20, fmt=None):\n",
        "        if fmt is None:\n",
        "            fmt = \"{median:.4f} ({global_avg:.4f})\"\n",
        "        self.deque = deque(maxlen=window_size)\n",
        "        self.total = 0.0\n",
        "        self.count = 0\n",
        "        self.fmt = fmt\n",
        "\n",
        "    def update(self, value, n=1):\n",
        "        self.deque.append(value)\n",
        "        self.count += n\n",
        "        self.total += value * n\n",
        "\n",
        "    def synchronize_between_processes(self):\n",
        "        \"\"\"\n",
        "        Warning: does not synchronize the deque!\n",
        "        \"\"\"\n",
        "        t = reduce_across_processes([self.count, self.total])\n",
        "        t = t.tolist()\n",
        "        self.count = int(t[0])\n",
        "        self.total = t[1]\n",
        "\n",
        "    @property\n",
        "    def median(self):\n",
        "        d = torch.tensor(list(self.deque))\n",
        "        return d.median().item()\n",
        "\n",
        "    @property\n",
        "    def avg(self):\n",
        "        d = torch.tensor(list(self.deque), dtype=torch.float32)\n",
        "        return d.mean().item()\n",
        "\n",
        "    @property\n",
        "    def global_avg(self):\n",
        "        return self.total / self.count\n",
        "\n",
        "    @property\n",
        "    def max(self):\n",
        "        return max(self.deque)\n",
        "\n",
        "    @property\n",
        "    def value(self):\n",
        "        return self.deque[-1]\n",
        "\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.fmt.format(\n",
        "            median=self.median, avg=self.avg, global_avg=self.global_avg, max=self.max, value=self.value\n",
        "        )\n",
        "\n",
        "class MetricLogger:\n",
        "    def __init__(self, delimiter=\"\\t\"):\n",
        "        self.meters = defaultdict(SmoothedValue)\n",
        "        self.delimiter = delimiter\n",
        "\n",
        "    def update(self, **kwargs):\n",
        "        for k, v in kwargs.items():\n",
        "            if isinstance(v, torch.Tensor):\n",
        "                v = v.item()\n",
        "            assert isinstance(v, (float, int))\n",
        "            self.meters[k].update(v)\n",
        "\n",
        "    def __getattr__(self, attr):\n",
        "        if attr in self.meters:\n",
        "            return self.meters[attr]\n",
        "        if attr in self.__dict__:\n",
        "            return self.__dict__[attr]\n",
        "        raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{attr}'\")\n",
        "\n",
        "    def __str__(self):\n",
        "        loss_str = []\n",
        "        for name, meter in self.meters.items():\n",
        "            loss_str.append(f\"{name}: {str(meter)}\")\n",
        "        return self.delimiter.join(loss_str)\n",
        "\n",
        "    def synchronize_between_processes(self):\n",
        "        for meter in self.meters.values():\n",
        "            meter.synchronize_between_processes()\n",
        "\n",
        "    def add_meter(self, name, meter):\n",
        "        self.meters[name] = meter\n",
        "\n",
        "    def log_every(self, iterable, print_freq, header=None):\n",
        "        i = 0\n",
        "        if not header:\n",
        "            header = \"\"\n",
        "        start_time = time.time()\n",
        "        end = time.time()\n",
        "        iter_time = SmoothedValue(fmt=\"{avg:.4f}\")\n",
        "        data_time = SmoothedValue(fmt=\"{avg:.4f}\")\n",
        "        space_fmt = \":\" + str(len(str(len(iterable)))) + \"d\"\n",
        "        if torch.cuda.is_available():\n",
        "            log_msg = self.delimiter.join(\n",
        "                [\n",
        "                    header,\n",
        "                    \"[{0\" + space_fmt + \"}/{1}]\",\n",
        "                    \"eta: {eta}\",\n",
        "                    \"{meters}\",\n",
        "                    \"time: {time}\",\n",
        "                    \"data: {data}\",\n",
        "                    \"max mem: {memory:.0f}\",\n",
        "                ]\n",
        "            )\n",
        "        else:\n",
        "            log_msg = self.delimiter.join(\n",
        "                [header, \"[{0\" + space_fmt + \"}/{1}]\", \"eta: {eta}\", \"{meters}\", \"time: {time}\", \"data: {data}\"]\n",
        "            )\n",
        "        MB = 1024.0 * 1024.0\n",
        "        for obj in iterable:\n",
        "            data_time.update(time.time() - end)\n",
        "            yield obj\n",
        "            iter_time.update(time.time() - end)\n",
        "            if i % print_freq == 0:\n",
        "                eta_seconds = iter_time.global_avg * (len(iterable) - i)\n",
        "                eta_string = str(datetime.timedelta(seconds=int(eta_seconds)))\n",
        "                if torch.cuda.is_available():\n",
        "                    print(\n",
        "                        log_msg.format(\n",
        "                            i,\n",
        "                            len(iterable),\n",
        "                            eta=eta_string,\n",
        "                            meters=str(self),\n",
        "                            time=str(iter_time),\n",
        "                            data=str(data_time),\n",
        "                            memory=torch.cuda.max_memory_allocated() / MB,\n",
        "                        )\n",
        "                    )\n",
        "                else:\n",
        "                    print(\n",
        "                        log_msg.format(\n",
        "                            i, len(iterable), eta=eta_string, meters=str(self), time=str(iter_time), data=str(data_time)\n",
        "                        )\n",
        "                    )\n",
        "            i += 1\n",
        "            end = time.time()\n",
        "        total_time = time.time() - start_time\n",
        "        total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "        print(f\"{header} Total time: {total_time_str}\")\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.inference_mode():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "        if target.ndim == 2:\n",
        "            target = target.max(dim=1)[1]\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target[None])\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].flatten().sum(dtype=torch.float32)\n",
        "            res.append(correct_k * (100.0 / batch_size))\n",
        "        return res\n",
        "def plot_losses(train_losses, val_losses, save_path):\n",
        "  epochs = range(1, len(train_losses) + 1)\n",
        "  plt.plot(epochs, train_losses, 'b', label='Training loss')\n",
        "  plt.plot(epochs, val_losses, 'r', label='Validation loss')\n",
        "  plt.title('Training and Validation Losses')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.savefig(save_path)\n",
        "  plt.clf()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "x8di24PNZlnD"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, criterion, optimizer, data_loader, device, epoch):\n",
        "    model.train()\n",
        "    metric_logger = MetricLogger(delimiter=\"  \")\n",
        "    metric_logger.add_meter(\"lr\", SmoothedValue(window_size=1, fmt=\"{value}\"))\n",
        "    metric_logger.add_meter(\"img/s\", SmoothedValue(window_size=10, fmt=\"{value}\"))\n",
        "\n",
        "    header = f\"Epoch: [{epoch}]\"\n",
        "    for i, (image, target) in enumerate(metric_logger.log_every(data_loader, 10, header)):\n",
        "        start_time = time.time()\n",
        "        image, target = image.to(device), target.to(device)\n",
        "        output = model(image)\n",
        "        loss = criterion(output, target)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        batch_size = image.shape[0]\n",
        "        metric_logger.update(loss=loss.item(), lr=optimizer.param_groups[0][\"lr\"])\n",
        "        metric_logger.meters[\"acc1\"].update(acc1.item(), n=batch_size)\n",
        "        metric_logger.meters[\"acc5\"].update(acc5.item(), n=batch_size)\n",
        "        metric_logger.meters[\"img/s\"].update(batch_size / (time.time() - start_time))\n",
        "\n",
        "\n",
        "    return metric_logger\n",
        "\n",
        "def evaluate(model, criterion, data_loader, device, print_freq=100, log_suffix=\"\"):\n",
        "    model.eval()\n",
        "    metric_logger = MetricLogger(delimiter=\"  \")\n",
        "    header = f\"Test: {log_suffix}\"\n",
        "\n",
        "    num_processed_samples = 0\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "    with torch.inference_mode():\n",
        "        for image, target in metric_logger.log_every(data_loader, print_freq, header):\n",
        "            image = image.to(device, non_blocking=True)\n",
        "            target = target.to(device, non_blocking=True)\n",
        "            output = model(image)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "            batch_size = image.shape[0]\n",
        "            metric_logger.update(loss=loss.item())\n",
        "            metric_logger.meters[\"acc1\"].update(acc1.item(), n=batch_size)\n",
        "            metric_logger.meters[\"acc5\"].update(acc5.item(), n=batch_size)\n",
        "            num_processed_samples += batch_size\n",
        "            _, predictions = output.max(1)\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_targets.extend(target.cpu().numpy())\n",
        "\n",
        "    kappa_score = cohen_kappa_score(all_targets, all_predictions)\n",
        "    metric_logger.meters[\"Kappa\"] = kappa_score\n",
        "    print(f\"{header} Acc@1 {metric_logger.acc1.global_avg:.3f} Acc@5 {metric_logger.acc5.global_avg:.3f}  Kappa {kappa_score:.3f} Loss {metric_logger.loss.global_avg:.3f}\") # Validation Loss u print etme kısmı buraya eklendi\n",
        "    return metric_logger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2Q3B0BboyZ0",
        "outputId": "6e2a3b85-739a-47b2-ab45-ce5318266efe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.58M/6.58M [00:01<00:00, 3.48MB/s]\n",
            "100%|██████████| 1.83M/1.83M [00:01<00:00, 1.39MB/s]\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "\n",
        "# usps dataset\n",
        "train_set = USPS('./data', train=True, transform=transform, download=True)\n",
        "split_ratio = 0.8\n",
        "train_size = int(split_ratio * len(train_set))\n",
        "val_size = len(train_set) - train_size\n",
        "\n",
        "train_set, val_set = random_split(train_set, [train_size, val_size])\n",
        "test_set = USPS('./data', train=False, transform=transform, download=True)\n",
        "\n",
        "training_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=1, shuffle=False)\n",
        "test_loader = DataLoader(test_set, batch_size=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PhBRX6sblDED"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lhYpiTc-TzYX"
      },
      "outputs": [],
      "source": [
        "class MyActivationFunction(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyActivationFunction, self).__init__()\n",
        "\n",
        "        self.new_weights = nn.Parameter(torch.randn(3, 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "      return torch.where(\n",
        "        (0 <= x) & (x <= 1),\n",
        "        x,\n",
        "        torch.where(\n",
        "            x > 1,\n",
        "            x*(1/(1*(1+1.7*torch.exp(-1.6*x)))),\n",
        "            1.7*(-1+torch.exp(1.6*x))\n",
        "        ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "y-S6ILpDLmIT"
      },
      "outputs": [],
      "source": [
        "class EmptyActivationFunction(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(EmptyActivationFunction, self).__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nKmQXO7vGGJA"
      },
      "outputs": [],
      "source": [
        "from typing import Callable, Optional\n",
        "from torchvision.models.resnet import conv1x1, conv3x3, ResNet\n",
        "from torch import Tensor\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion: int = 1\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        inplanes: int,\n",
        "        planes: int,\n",
        "        stride: int = 1,\n",
        "        downsample: Optional[nn.Module] = None,\n",
        "        groups: int = 1,\n",
        "        base_width: int = 64,\n",
        "        dilation: int = 1,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError(\"BasicBlock only supports groups=1 and base_width=64\")\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = MyActivationFunction()\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.relu2 = MyActivationFunction()\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu2(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion: int = 4\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        inplanes: int,\n",
        "        planes: int,\n",
        "        stride: int = 1,\n",
        "        downsample: Optional[nn.Module] = None,\n",
        "        groups: int = 1,\n",
        "        base_width: int = 64,\n",
        "        dilation: int = 1,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        width = int(planes * (base_width / 64.0)) * groups\n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.relu1 = MyActivationFunction()\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.relu2 = MyActivationFunction()\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu3 = MyActivationFunction()\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu1(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu2(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu3(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gLTfeiLSwMSu"
      },
      "outputs": [],
      "source": [
        "class NResNet(nn.Module):\n",
        "  def __init__(self, num_classes=10, in_channels=1):\n",
        "    super(NResNet, self).__init__()\n",
        "    self.model = ResNet(Bottleneck, [3, 4, 6, 3], num_classes=num_classes)\n",
        "\n",
        "\n",
        "    self.model.relu=MyActivationFunction()\n",
        "\n",
        "    self.model.conv1 = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zp4mGhCdUn-k",
        "outputId": "c703ad5e-c1ac-43be-9628-ce34e8c72e70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NResNet(\n",
            "  (model): ResNet(\n",
            "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): MyActivationFunction()\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): MyActivationFunction()\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): MyActivationFunction()\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu3): MyActivationFunction()\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): MyActivationFunction()\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): MyActivationFunction()\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu3): MyActivationFunction()\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): MyActivationFunction()\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): MyActivationFunction()\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu3): MyActivationFunction()\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): MyActivationFunction()\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): MyActivationFunction()\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu3): MyActivationFunction()\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): MyActivationFunction()\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): MyActivationFunction()\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu3): MyActivationFunction()\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): MyActivationFunction()\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): MyActivationFunction()\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu3): MyActivationFunction()\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): MyActivationFunction()\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): MyActivationFunction()\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu3): MyActivationFunction()\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): MyActivationFunction()\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): MyActivationFunction()\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu3): MyActivationFunction()\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): MyActivationFunction()\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): MyActivationFunction()\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu3): MyActivationFunction()\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): MyActivationFunction()\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): MyActivationFunction()\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu3): MyActivationFunction()\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): MyActivationFunction()\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): MyActivationFunction()\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu3): MyActivationFunction()\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): MyActivationFunction()\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): MyActivationFunction()\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu3): MyActivationFunction()\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): MyActivationFunction()\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): MyActivationFunction()\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu3): MyActivationFunction()\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): MyActivationFunction()\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): MyActivationFunction()\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu3): MyActivationFunction()\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): MyActivationFunction()\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): MyActivationFunction()\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu3): MyActivationFunction()\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): MyActivationFunction()\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): MyActivationFunction()\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu3): MyActivationFunction()\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model=NResNet(in_channels=1)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CS7Lg-hmYuCe",
        "outputId": "5ab92ee7-3831-49fe-9797-943d1a2b32fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0]  [ 0/46]  eta: 0:01:33  lr: 0.0003  img/s: 64.0888300928461  loss: 2.7917 (2.7917)  acc1: 10.1562 (10.1562)  acc5: 44.5312 (44.5312)  time: 2.0281  data: 0.0309  max mem: 525\n",
            "Epoch: [0]  [10/46]  eta: 0:00:09  lr: 0.0003  img/s: 1786.348325186913  loss: 0.6742 (0.8597)  acc1: 80.4688 (73.2244)  acc5: 98.4375 (92.0455)  time: 0.2758  data: 0.0201  max mem: 649\n",
            "Epoch: [0]  [20/46]  eta: 0:00:04  lr: 0.0003  img/s: 1784.1874079859092  loss: 0.4360 (0.6533)  acc1: 86.7188 (80.3943)  acc5: 98.4375 (95.2753)  time: 0.0955  data: 0.0186  max mem: 649\n",
            "Epoch: [0]  [30/46]  eta: 0:00:02  lr: 0.0003  img/s: 1788.9614597703448  loss: 0.3532 (0.5420)  acc1: 89.0625 (83.7954)  acc5: 99.2188 (96.6986)  time: 0.0936  data: 0.0197  max mem: 649\n",
            "Epoch: [0]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 1778.2717534596861  loss: 0.3009 (0.4887)  acc1: 90.6250 (85.5945)  acc5: 100.0000 (97.4085)  time: 0.0971  data: 0.0210  max mem: 649\n",
            "Epoch: [0] Total time: 0:00:06\n",
            "Test:   [   0/1459]  eta: 0:03:12  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1317  data: 0.0007  max mem: 649\n",
            "Test:   [ 100/1459]  eta: 0:00:29  loss: 0.0011 (0.1183)  acc1: 100.0000 (97.0297)  acc5: 100.0000 (100.0000)  time: 0.0199  data: 0.0003  max mem: 649\n",
            "Test:   [ 200/1459]  eta: 0:00:25  loss: 0.0025 (0.1822)  acc1: 100.0000 (93.5323)  acc5: 100.0000 (100.0000)  time: 0.0196  data: 0.0003  max mem: 649\n",
            "Test:   [ 300/1459]  eta: 0:00:23  loss: 0.0000 (0.3046)  acc1: 100.0000 (92.3588)  acc5: 100.0000 (99.6678)  time: 0.0199  data: 0.0003  max mem: 649\n",
            "Test:   [ 400/1459]  eta: 0:00:21  loss: 0.0002 (0.3213)  acc1: 100.0000 (92.2693)  acc5: 100.0000 (99.7506)  time: 0.0196  data: 0.0003  max mem: 649\n",
            "Test:   [ 500/1459]  eta: 0:00:19  loss: 0.0001 (0.3484)  acc1: 100.0000 (91.4172)  acc5: 100.0000 (99.8004)  time: 0.0202  data: 0.0003  max mem: 649\n",
            "Test:   [ 600/1459]  eta: 0:00:17  loss: 0.0001 (0.3481)  acc1: 100.0000 (91.8469)  acc5: 100.0000 (99.6672)  time: 0.0198  data: 0.0003  max mem: 649\n",
            "Test:   [ 700/1459]  eta: 0:00:15  loss: 0.0001 (0.3116)  acc1: 100.0000 (92.7247)  acc5: 100.0000 (99.7147)  time: 0.0198  data: 0.0003  max mem: 649\n",
            "Test:   [ 800/1459]  eta: 0:00:13  loss: 0.0015 (0.3426)  acc1: 100.0000 (92.1348)  acc5: 100.0000 (99.6255)  time: 0.0203  data: 0.0003  max mem: 649\n",
            "Test:   [ 900/1459]  eta: 0:00:11  loss: 0.0006 (0.3272)  acc1: 100.0000 (92.4528)  acc5: 100.0000 (99.6670)  time: 0.0198  data: 0.0003  max mem: 649\n",
            "Test:   [1000/1459]  eta: 0:00:09  loss: 0.0016 (0.3174)  acc1: 100.0000 (92.6074)  acc5: 100.0000 (99.7003)  time: 0.0198  data: 0.0003  max mem: 649\n",
            "Test:   [1100/1459]  eta: 0:00:07  loss: 0.0004 (0.3029)  acc1: 100.0000 (92.6431)  acc5: 100.0000 (99.7275)  time: 0.0198  data: 0.0003  max mem: 649\n",
            "Test:   [1200/1459]  eta: 0:00:05  loss: 0.0004 (0.3098)  acc1: 100.0000 (92.5062)  acc5: 100.0000 (99.5837)  time: 0.0202  data: 0.0003  max mem: 649\n",
            "Test:   [1300/1459]  eta: 0:00:03  loss: 0.0002 (0.3143)  acc1: 100.0000 (92.4673)  acc5: 100.0000 (99.6157)  time: 0.0200  data: 0.0003  max mem: 649\n",
            "Test:   [1400/1459]  eta: 0:00:01  loss: 0.0040 (0.3073)  acc1: 100.0000 (92.4340)  acc5: 100.0000 (99.6431)  time: 0.0197  data: 0.0003  max mem: 649\n",
            "Test:  Total time: 0:00:29\n",
            "Test:  Acc@1 92.529 Acc@5 99.657  Kappa 0.916 Loss 0.301\n",
            "Epoch: [1]  [ 0/46]  eta: 0:00:05  lr: 0.0003  img/s: 1224.0810048541807  loss: 0.1641 (0.1641)  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.1272  data: 0.0226  max mem: 649\n",
            "Epoch: [1]  [10/46]  eta: 0:00:03  lr: 0.0003  img/s: 1760.988857509291  loss: 0.1718 (0.1665)  acc1: 95.3125 (95.4545)  acc5: 100.0000 (99.7869)  time: 0.0984  data: 0.0190  max mem: 649\n",
            "Epoch: [1]  [20/46]  eta: 0:00:02  lr: 0.0003  img/s: 1731.9813275264135  loss: 0.1375 (0.1578)  acc1: 96.0938 (95.9077)  acc5: 100.0000 (99.8140)  time: 0.0933  data: 0.0185  max mem: 649\n",
            "Epoch: [1]  [30/46]  eta: 0:00:01  lr: 0.0003  img/s: 1756.51789494348  loss: 0.1034 (0.1437)  acc1: 96.0938 (96.1190)  acc5: 100.0000 (99.8740)  time: 0.0919  data: 0.0189  max mem: 649\n",
            "Epoch: [1]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 1770.647388244296  loss: 0.1030 (0.1372)  acc1: 96.8750 (96.2462)  acc5: 100.0000 (99.8476)  time: 0.0933  data: 0.0196  max mem: 649\n",
            "Epoch: [1] Total time: 0:00:04\n",
            "Test:   [   0/1459]  eta: 0:00:30  loss: 0.0002 (0.0002)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0207  data: 0.0006  max mem: 649\n",
            "Test:   [ 100/1459]  eta: 0:00:27  loss: 0.0000 (0.1165)  acc1: 100.0000 (96.0396)  acc5: 100.0000 (100.0000)  time: 0.0199  data: 0.0003  max mem: 649\n",
            "Test:   [ 200/1459]  eta: 0:00:25  loss: 0.0001 (0.1328)  acc1: 100.0000 (94.5274)  acc5: 100.0000 (100.0000)  time: 0.0204  data: 0.0004  max mem: 649\n",
            "Test:   [ 300/1459]  eta: 0:00:23  loss: 0.0001 (0.2054)  acc1: 100.0000 (94.3522)  acc5: 100.0000 (99.6678)  time: 0.0202  data: 0.0003  max mem: 649\n",
            "Test:   [ 400/1459]  eta: 0:00:21  loss: 0.0001 (0.2374)  acc1: 100.0000 (93.5162)  acc5: 100.0000 (99.7506)  time: 0.0196  data: 0.0003  max mem: 649\n",
            "Test:   [ 500/1459]  eta: 0:00:19  loss: 0.0000 (0.2099)  acc1: 100.0000 (94.0120)  acc5: 100.0000 (99.8004)  time: 0.0200  data: 0.0003  max mem: 649\n",
            "Test:   [ 600/1459]  eta: 0:00:17  loss: 0.0000 (0.2119)  acc1: 100.0000 (94.3428)  acc5: 100.0000 (99.8336)  time: 0.0204  data: 0.0003  max mem: 649\n",
            "Test:   [ 700/1459]  eta: 0:00:15  loss: 0.0001 (0.1933)  acc1: 100.0000 (94.8645)  acc5: 100.0000 (99.8573)  time: 0.0201  data: 0.0003  max mem: 649\n",
            "Test:   [ 800/1459]  eta: 0:00:13  loss: 0.0004 (0.2258)  acc1: 100.0000 (94.6317)  acc5: 100.0000 (99.8752)  time: 0.0206  data: 0.0004  max mem: 649\n",
            "Test:   [ 900/1459]  eta: 0:00:11  loss: 0.0000 (0.2152)  acc1: 100.0000 (95.0055)  acc5: 100.0000 (99.8890)  time: 0.0200  data: 0.0003  max mem: 649\n",
            "Test:   [1000/1459]  eta: 0:00:09  loss: 0.0001 (0.2040)  acc1: 100.0000 (95.1049)  acc5: 100.0000 (99.9001)  time: 0.0206  data: 0.0004  max mem: 649\n",
            "Test:   [1100/1459]  eta: 0:00:07  loss: 0.0000 (0.2110)  acc1: 100.0000 (94.9137)  acc5: 100.0000 (99.9092)  time: 0.0203  data: 0.0003  max mem: 649\n",
            "Test:   [1200/1459]  eta: 0:00:05  loss: 0.0001 (0.2176)  acc1: 100.0000 (94.8376)  acc5: 100.0000 (99.9167)  time: 0.0199  data: 0.0003  max mem: 649\n",
            "Test:   [1300/1459]  eta: 0:00:03  loss: 0.0001 (0.2261)  acc1: 100.0000 (94.7733)  acc5: 100.0000 (99.9231)  time: 0.0202  data: 0.0003  max mem: 649\n",
            "Test:   [1400/1459]  eta: 0:00:01  loss: 0.0005 (0.2152)  acc1: 100.0000 (94.8608)  acc5: 100.0000 (99.9286)  time: 0.0199  data: 0.0003  max mem: 649\n",
            "Test:  Total time: 0:00:29\n",
            "Test:  Acc@1 94.928 Acc@5 99.931  Kappa 0.943 Loss 0.211\n",
            "Epoch: [2]  [ 0/46]  eta: 0:00:06  lr: 0.0003  img/s: 1073.6752561341198  loss: 0.0813 (0.0813)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.1395  data: 0.0203  max mem: 649\n",
            "Epoch: [2]  [10/46]  eta: 0:00:03  lr: 0.0003  img/s: 1766.3887976784663  loss: 0.0932 (0.0861)  acc1: 97.6562 (97.4432)  acc5: 100.0000 (100.0000)  time: 0.1025  data: 0.0196  max mem: 650\n",
            "Epoch: [2]  [20/46]  eta: 0:00:02  lr: 0.0003  img/s: 1738.9038449703796  loss: 0.0806 (0.0922)  acc1: 97.6562 (97.2470)  acc5: 100.0000 (100.0000)  time: 0.0966  data: 0.0196  max mem: 650\n",
            "Epoch: [2]  [30/46]  eta: 0:00:01  lr: 0.0003  img/s: 1752.4470369342755  loss: 0.0788 (0.0875)  acc1: 96.8750 (97.2782)  acc5: 100.0000 (99.9748)  time: 0.0947  data: 0.0201  max mem: 650\n",
            "Epoch: [2]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 1786.0808953178125  loss: 0.0714 (0.0857)  acc1: 97.6562 (97.2942)  acc5: 100.0000 (99.9809)  time: 0.0937  data: 0.0198  max mem: 650\n",
            "Epoch: [2] Total time: 0:00:04\n",
            "Test:   [   0/1459]  eta: 0:00:31  loss: 0.0004 (0.0004)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0216  data: 0.0006  max mem: 650\n",
            "Test:   [ 100/1459]  eta: 0:00:27  loss: 0.0000 (0.0800)  acc1: 100.0000 (97.0297)  acc5: 100.0000 (100.0000)  time: 0.0204  data: 0.0003  max mem: 650\n",
            "Test:   [ 200/1459]  eta: 0:00:25  loss: 0.0001 (0.0799)  acc1: 100.0000 (96.0199)  acc5: 100.0000 (100.0000)  time: 0.0203  data: 0.0003  max mem: 650\n",
            "Test:   [ 300/1459]  eta: 0:00:23  loss: 0.0001 (0.1546)  acc1: 100.0000 (96.0133)  acc5: 100.0000 (99.6678)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [ 400/1459]  eta: 0:00:21  loss: 0.0000 (0.2000)  acc1: 100.0000 (95.5112)  acc5: 100.0000 (99.7506)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [ 500/1459]  eta: 0:00:19  loss: 0.0000 (0.1776)  acc1: 100.0000 (95.8084)  acc5: 100.0000 (99.8004)  time: 0.0200  data: 0.0003  max mem: 650\n",
            "Test:   [ 600/1459]  eta: 0:00:17  loss: 0.0002 (0.1944)  acc1: 100.0000 (95.8403)  acc5: 100.0000 (99.6672)  time: 0.0203  data: 0.0003  max mem: 650\n",
            "Test:   [ 700/1459]  eta: 0:00:15  loss: 0.0001 (0.1863)  acc1: 100.0000 (96.1484)  acc5: 100.0000 (99.7147)  time: 0.0204  data: 0.0003  max mem: 650\n",
            "Test:   [ 800/1459]  eta: 0:00:13  loss: 0.0000 (0.2021)  acc1: 100.0000 (95.8801)  acc5: 100.0000 (99.7503)  time: 0.0204  data: 0.0003  max mem: 650\n",
            "Test:   [ 900/1459]  eta: 0:00:11  loss: 0.0002 (0.2172)  acc1: 100.0000 (95.3385)  acc5: 100.0000 (99.7780)  time: 0.0198  data: 0.0003  max mem: 650\n",
            "Test:   [1000/1459]  eta: 0:00:09  loss: 0.0000 (0.2095)  acc1: 100.0000 (95.4046)  acc5: 100.0000 (99.8002)  time: 0.0208  data: 0.0004  max mem: 650\n",
            "Test:   [1100/1459]  eta: 0:00:07  loss: 0.0000 (0.2097)  acc1: 100.0000 (95.4587)  acc5: 100.0000 (99.8183)  time: 0.0206  data: 0.0003  max mem: 650\n",
            "Test:   [1200/1459]  eta: 0:00:05  loss: 0.0001 (0.2102)  acc1: 100.0000 (95.4205)  acc5: 100.0000 (99.7502)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [1300/1459]  eta: 0:00:03  loss: 0.0001 (0.2169)  acc1: 100.0000 (95.3882)  acc5: 100.0000 (99.7694)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [1400/1459]  eta: 0:00:01  loss: 0.0003 (0.2107)  acc1: 100.0000 (95.5032)  acc5: 100.0000 (99.7859)  time: 0.0199  data: 0.0003  max mem: 650\n",
            "Test:  Total time: 0:00:29\n",
            "Test:  Acc@1 95.682 Acc@5 99.794  Kappa 0.952 Loss 0.203\n",
            "Epoch: [3]  [ 0/46]  eta: 0:00:06  lr: 0.0003  img/s: 1066.9729476202967  loss: 0.0349 (0.0349)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1434  data: 0.0235  max mem: 650\n",
            "Epoch: [3]  [10/46]  eta: 0:00:03  lr: 0.0003  img/s: 1674.8743136667665  loss: 0.0736 (0.0703)  acc1: 97.6562 (97.9403)  acc5: 100.0000 (100.0000)  time: 0.1045  data: 0.0211  max mem: 650\n",
            "Epoch: [3]  [20/46]  eta: 0:00:02  lr: 0.0003  img/s: 1728.6798404209076  loss: 0.0736 (0.0706)  acc1: 97.6562 (98.0283)  acc5: 100.0000 (100.0000)  time: 0.0982  data: 0.0210  max mem: 650\n",
            "Epoch: [3]  [30/46]  eta: 0:00:01  lr: 0.0003  img/s: 1748.4633336915776  loss: 0.0437 (0.0720)  acc1: 97.6562 (97.8075)  acc5: 100.0000 (100.0000)  time: 0.0948  data: 0.0205  max mem: 650\n",
            "Epoch: [3]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 1780.264855687606  loss: 0.0433 (0.0763)  acc1: 97.6562 (97.7515)  acc5: 100.0000 (100.0000)  time: 0.0934  data: 0.0194  max mem: 650\n",
            "Epoch: [3] Total time: 0:00:04\n",
            "Test:   [   0/1459]  eta: 0:00:31  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0216  data: 0.0007  max mem: 650\n",
            "Test:   [ 100/1459]  eta: 0:00:27  loss: 0.0000 (0.1166)  acc1: 100.0000 (98.0198)  acc5: 100.0000 (100.0000)  time: 0.0205  data: 0.0003  max mem: 650\n",
            "Test:   [ 200/1459]  eta: 0:00:25  loss: 0.0001 (0.1340)  acc1: 100.0000 (96.0199)  acc5: 100.0000 (100.0000)  time: 0.0202  data: 0.0004  max mem: 650\n",
            "Test:   [ 300/1459]  eta: 0:00:23  loss: 0.0000 (0.2190)  acc1: 100.0000 (96.0133)  acc5: 100.0000 (99.6678)  time: 0.0203  data: 0.0003  max mem: 650\n",
            "Test:   [ 400/1459]  eta: 0:00:21  loss: 0.0001 (0.2895)  acc1: 100.0000 (95.5112)  acc5: 100.0000 (99.5012)  time: 0.0205  data: 0.0004  max mem: 650\n",
            "Test:   [ 500/1459]  eta: 0:00:19  loss: 0.0000 (0.2662)  acc1: 100.0000 (95.8084)  acc5: 100.0000 (99.6008)  time: 0.0203  data: 0.0003  max mem: 650\n",
            "Test:   [ 600/1459]  eta: 0:00:17  loss: 0.0001 (0.2656)  acc1: 100.0000 (95.5075)  acc5: 100.0000 (99.5008)  time: 0.0204  data: 0.0004  max mem: 650\n",
            "Test:   [ 700/1459]  eta: 0:00:15  loss: 0.0000 (0.2468)  acc1: 100.0000 (95.8631)  acc5: 100.0000 (99.5720)  time: 0.0203  data: 0.0003  max mem: 650\n",
            "Test:   [ 800/1459]  eta: 0:00:13  loss: 0.0000 (0.2413)  acc1: 100.0000 (95.3808)  acc5: 100.0000 (99.6255)  time: 0.0205  data: 0.0003  max mem: 650\n",
            "Test:   [ 900/1459]  eta: 0:00:11  loss: 0.0000 (0.2294)  acc1: 100.0000 (95.4495)  acc5: 100.0000 (99.6670)  time: 0.0198  data: 0.0003  max mem: 650\n",
            "Test:   [1000/1459]  eta: 0:00:09  loss: 0.0000 (0.2159)  acc1: 100.0000 (95.6044)  acc5: 100.0000 (99.7003)  time: 0.0200  data: 0.0003  max mem: 650\n",
            "Test:   [1100/1459]  eta: 0:00:07  loss: 0.0000 (0.2130)  acc1: 100.0000 (95.7312)  acc5: 100.0000 (99.7275)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [1200/1459]  eta: 0:00:05  loss: 0.0000 (0.2169)  acc1: 100.0000 (95.7535)  acc5: 100.0000 (99.6669)  time: 0.0200  data: 0.0003  max mem: 650\n",
            "Test:   [1300/1459]  eta: 0:00:03  loss: 0.0000 (0.2116)  acc1: 100.0000 (95.8493)  acc5: 100.0000 (99.6925)  time: 0.0200  data: 0.0003  max mem: 650\n",
            "Test:   [1400/1459]  eta: 0:00:01  loss: 0.0000 (0.2032)  acc1: 100.0000 (95.8601)  acc5: 100.0000 (99.7145)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:  Total time: 0:00:29\n",
            "Test:  Acc@1 95.956 Acc@5 99.726  Kappa 0.955 Loss 0.196\n",
            "Epoch: [4]  [ 0/46]  eta: 0:00:06  lr: 0.0003  img/s: 1055.1936303654363  loss: 0.0023 (0.0023)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1430  data: 0.0217  max mem: 650\n",
            "Epoch: [4]  [10/46]  eta: 0:00:03  lr: 0.0003  img/s: 1716.3227718404235  loss: 0.0767 (0.0588)  acc1: 97.6562 (98.0114)  acc5: 100.0000 (100.0000)  time: 0.1014  data: 0.0198  max mem: 650\n",
            "Epoch: [4]  [20/46]  eta: 0:00:02  lr: 0.0003  img/s: 1760.35947510968  loss: 0.0767 (0.0686)  acc1: 97.6562 (97.8423)  acc5: 100.0000 (100.0000)  time: 0.0949  data: 0.0193  max mem: 650\n",
            "Epoch: [4]  [30/46]  eta: 0:00:01  lr: 0.0003  img/s: 1714.66184614795  loss: 0.0554 (0.0647)  acc1: 97.6562 (97.9335)  acc5: 100.0000 (100.0000)  time: 0.0928  data: 0.0192  max mem: 650\n",
            "Epoch: [4]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 1693.7593841688488  loss: 0.0357 (0.0632)  acc1: 98.4375 (98.0945)  acc5: 100.0000 (100.0000)  time: 0.0935  data: 0.0195  max mem: 650\n",
            "Epoch: [4] Total time: 0:00:04\n",
            "Test:   [   0/1459]  eta: 0:00:30  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0207  data: 0.0007  max mem: 650\n",
            "Test:   [ 100/1459]  eta: 0:00:27  loss: 0.0000 (0.1192)  acc1: 100.0000 (96.0396)  acc5: 100.0000 (100.0000)  time: 0.0198  data: 0.0003  max mem: 650\n",
            "Test:   [ 200/1459]  eta: 0:00:25  loss: 0.0000 (0.1205)  acc1: 100.0000 (96.5174)  acc5: 100.0000 (100.0000)  time: 0.0205  data: 0.0003  max mem: 650\n",
            "Test:   [ 300/1459]  eta: 0:00:23  loss: 0.0001 (0.1665)  acc1: 100.0000 (97.0100)  acc5: 100.0000 (99.6678)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [ 400/1459]  eta: 0:00:21  loss: 0.0002 (0.1929)  acc1: 100.0000 (97.0075)  acc5: 100.0000 (99.5012)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [ 500/1459]  eta: 0:00:19  loss: 0.0000 (0.1782)  acc1: 100.0000 (96.8064)  acc5: 100.0000 (99.6008)  time: 0.0205  data: 0.0004  max mem: 650\n",
            "Test:   [ 600/1459]  eta: 0:00:17  loss: 0.0000 (0.2205)  acc1: 100.0000 (96.1730)  acc5: 100.0000 (99.6672)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [ 700/1459]  eta: 0:00:15  loss: 0.0000 (0.2066)  acc1: 100.0000 (96.4337)  acc5: 100.0000 (99.7147)  time: 0.0204  data: 0.0004  max mem: 650\n",
            "Test:   [ 800/1459]  eta: 0:00:13  loss: 0.0000 (0.2270)  acc1: 100.0000 (96.2547)  acc5: 100.0000 (99.7503)  time: 0.0200  data: 0.0003  max mem: 650\n",
            "Test:   [ 900/1459]  eta: 0:00:11  loss: 0.0000 (0.2296)  acc1: 100.0000 (95.8935)  acc5: 100.0000 (99.7780)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [1000/1459]  eta: 0:00:09  loss: 0.0000 (0.2238)  acc1: 100.0000 (96.0040)  acc5: 100.0000 (99.8002)  time: 0.0204  data: 0.0003  max mem: 650\n",
            "Test:   [1100/1459]  eta: 0:00:07  loss: 0.0000 (0.2143)  acc1: 100.0000 (96.0036)  acc5: 100.0000 (99.8183)  time: 0.0206  data: 0.0004  max mem: 650\n",
            "Test:   [1200/1459]  eta: 0:00:05  loss: 0.0000 (0.2124)  acc1: 100.0000 (96.1699)  acc5: 100.0000 (99.8335)  time: 0.0206  data: 0.0004  max mem: 650\n",
            "Test:   [1300/1459]  eta: 0:00:03  loss: 0.0000 (0.2214)  acc1: 100.0000 (96.0031)  acc5: 100.0000 (99.8463)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [1400/1459]  eta: 0:00:01  loss: 0.0001 (0.2192)  acc1: 100.0000 (96.1456)  acc5: 100.0000 (99.8572)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:  Total time: 0:00:29\n",
            "Test:  Acc@1 96.230 Acc@5 99.863  Kappa 0.958 Loss 0.212\n",
            "Epoch: [5]  [ 0/46]  eta: 0:00:06  lr: 0.0003  img/s: 1075.0124887617164  loss: 0.0115 (0.0115)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1401  data: 0.0210  max mem: 650\n",
            "Epoch: [5]  [10/46]  eta: 0:00:03  lr: 0.0003  img/s: 1737.4182035889387  loss: 0.0285 (0.0499)  acc1: 98.4375 (98.5085)  acc5: 100.0000 (100.0000)  time: 0.1022  data: 0.0193  max mem: 650\n",
            "Epoch: [5]  [20/46]  eta: 0:00:02  lr: 0.0003  img/s: 1721.970870205307  loss: 0.0397 (0.0595)  acc1: 98.4375 (98.3259)  acc5: 100.0000 (100.0000)  time: 0.0959  data: 0.0190  max mem: 650\n",
            "Epoch: [5]  [30/46]  eta: 0:00:01  lr: 0.0003  img/s: 1722.3852012499117  loss: 0.0452 (0.0558)  acc1: 98.4375 (98.3619)  acc5: 100.0000 (100.0000)  time: 0.0936  data: 0.0192  max mem: 650\n",
            "Epoch: [5]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 1709.1920995326448  loss: 0.0414 (0.0586)  acc1: 98.4375 (98.3041)  acc5: 100.0000 (100.0000)  time: 0.0933  data: 0.0193  max mem: 650\n",
            "Epoch: [5] Total time: 0:00:04\n",
            "Test:   [   0/1459]  eta: 0:00:30  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0207  data: 0.0007  max mem: 650\n",
            "Test:   [ 100/1459]  eta: 0:00:27  loss: 0.0000 (0.1214)  acc1: 100.0000 (97.0297)  acc5: 100.0000 (100.0000)  time: 0.0205  data: 0.0003  max mem: 650\n",
            "Test:   [ 200/1459]  eta: 0:00:25  loss: 0.0000 (0.1759)  acc1: 100.0000 (96.5174)  acc5: 100.0000 (100.0000)  time: 0.0211  data: 0.0003  max mem: 650\n",
            "Test:   [ 300/1459]  eta: 0:00:23  loss: 0.0000 (0.2447)  acc1: 100.0000 (95.6811)  acc5: 100.0000 (100.0000)  time: 0.0206  data: 0.0003  max mem: 650\n",
            "Test:   [ 400/1459]  eta: 0:00:21  loss: 0.0000 (0.2664)  acc1: 100.0000 (95.5112)  acc5: 100.0000 (100.0000)  time: 0.0198  data: 0.0003  max mem: 650\n",
            "Test:   [ 500/1459]  eta: 0:00:19  loss: 0.0000 (0.2400)  acc1: 100.0000 (95.6088)  acc5: 100.0000 (100.0000)  time: 0.0196  data: 0.0003  max mem: 650\n",
            "Test:   [ 600/1459]  eta: 0:00:17  loss: 0.0000 (0.2584)  acc1: 100.0000 (95.1747)  acc5: 100.0000 (100.0000)  time: 0.0196  data: 0.0003  max mem: 650\n",
            "Test:   [ 700/1459]  eta: 0:00:15  loss: 0.0000 (0.2325)  acc1: 100.0000 (95.5777)  acc5: 100.0000 (100.0000)  time: 0.0198  data: 0.0003  max mem: 650\n",
            "Test:   [ 800/1459]  eta: 0:00:13  loss: 0.0000 (0.2677)  acc1: 100.0000 (94.8814)  acc5: 100.0000 (100.0000)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [ 900/1459]  eta: 0:00:11  loss: 0.0000 (0.2773)  acc1: 100.0000 (94.7836)  acc5: 100.0000 (100.0000)  time: 0.0199  data: 0.0003  max mem: 650\n",
            "Test:   [1000/1459]  eta: 0:00:09  loss: 0.0000 (0.2600)  acc1: 100.0000 (95.0050)  acc5: 100.0000 (100.0000)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [1100/1459]  eta: 0:00:07  loss: 0.0000 (0.2472)  acc1: 100.0000 (95.1862)  acc5: 100.0000 (100.0000)  time: 0.0200  data: 0.0004  max mem: 650\n",
            "Test:   [1200/1459]  eta: 0:00:05  loss: 0.0000 (0.2427)  acc1: 100.0000 (95.3372)  acc5: 100.0000 (100.0000)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [1300/1459]  eta: 0:00:03  loss: 0.0000 (0.2457)  acc1: 100.0000 (95.1576)  acc5: 100.0000 (100.0000)  time: 0.0200  data: 0.0003  max mem: 650\n",
            "Test:   [1400/1459]  eta: 0:00:01  loss: 0.0002 (0.2595)  acc1: 100.0000 (94.9322)  acc5: 100.0000 (100.0000)  time: 0.0212  data: 0.0004  max mem: 650\n",
            "Test:  Total time: 0:00:29\n",
            "Test:  Acc@1 95.065 Acc@5 99.931  Kappa 0.945 Loss 0.254\n",
            "Epoch: [6]  [ 0/46]  eta: 0:00:06  lr: 0.0003  img/s: 1073.524971955665  loss: 0.0887 (0.0887)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.1387  data: 0.0195  max mem: 650\n",
            "Epoch: [6]  [10/46]  eta: 0:00:03  lr: 0.0003  img/s: 1714.3004866335432  loss: 0.0383 (0.0440)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.1021  data: 0.0192  max mem: 650\n",
            "Epoch: [6]  [20/46]  eta: 0:00:02  lr: 0.0003  img/s: 1743.9763515818129  loss: 0.0383 (0.0524)  acc1: 98.4375 (98.3631)  acc5: 100.0000 (100.0000)  time: 0.0961  data: 0.0193  max mem: 650\n",
            "Epoch: [6]  [30/46]  eta: 0:00:01  lr: 0.0003  img/s: 1766.2086535424783  loss: 0.0489 (0.0589)  acc1: 98.4375 (98.1603)  acc5: 100.0000 (100.0000)  time: 0.0931  data: 0.0192  max mem: 650\n",
            "Epoch: [6]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 1745.3427220889332  loss: 0.0489 (0.0574)  acc1: 97.6562 (98.1136)  acc5: 100.0000 (100.0000)  time: 0.0923  data: 0.0190  max mem: 650\n",
            "Epoch: [6] Total time: 0:00:04\n",
            "Test:   [   0/1459]  eta: 0:00:33  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0231  data: 0.0007  max mem: 650\n",
            "Test:   [ 100/1459]  eta: 0:00:27  loss: 0.0000 (0.1414)  acc1: 100.0000 (97.0297)  acc5: 100.0000 (100.0000)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [ 200/1459]  eta: 0:00:25  loss: 0.0000 (0.1414)  acc1: 100.0000 (96.5174)  acc5: 100.0000 (100.0000)  time: 0.0200  data: 0.0003  max mem: 650\n",
            "Test:   [ 300/1459]  eta: 0:00:23  loss: 0.0000 (0.2229)  acc1: 100.0000 (96.0133)  acc5: 100.0000 (99.6678)  time: 0.0204  data: 0.0003  max mem: 650\n",
            "Test:   [ 400/1459]  eta: 0:00:21  loss: 0.0000 (0.2581)  acc1: 100.0000 (95.2618)  acc5: 100.0000 (99.7506)  time: 0.0202  data: 0.0004  max mem: 650\n",
            "Test:   [ 500/1459]  eta: 0:00:19  loss: 0.0000 (0.2137)  acc1: 100.0000 (96.0080)  acc5: 100.0000 (99.8004)  time: 0.0199  data: 0.0003  max mem: 650\n",
            "Test:   [ 600/1459]  eta: 0:00:17  loss: 0.0000 (0.2186)  acc1: 100.0000 (95.8403)  acc5: 100.0000 (99.8336)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [ 700/1459]  eta: 0:00:15  loss: 0.0000 (0.2088)  acc1: 100.0000 (96.1484)  acc5: 100.0000 (99.8573)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [ 800/1459]  eta: 0:00:13  loss: 0.0000 (0.2000)  acc1: 100.0000 (96.0050)  acc5: 100.0000 (99.8752)  time: 0.0202  data: 0.0004  max mem: 650\n",
            "Test:   [ 900/1459]  eta: 0:00:11  loss: 0.0000 (0.1980)  acc1: 100.0000 (96.0044)  acc5: 100.0000 (99.8890)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [1000/1459]  eta: 0:00:09  loss: 0.0000 (0.1851)  acc1: 100.0000 (96.1039)  acc5: 100.0000 (99.9001)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [1100/1459]  eta: 0:00:07  loss: 0.0000 (0.1769)  acc1: 100.0000 (96.2761)  acc5: 100.0000 (99.9092)  time: 0.0206  data: 0.0003  max mem: 650\n",
            "Test:   [1200/1459]  eta: 0:00:05  loss: 0.0000 (0.1853)  acc1: 100.0000 (96.0866)  acc5: 100.0000 (99.9167)  time: 0.0204  data: 0.0003  max mem: 650\n",
            "Test:   [1300/1459]  eta: 0:00:03  loss: 0.0000 (0.1803)  acc1: 100.0000 (96.0031)  acc5: 100.0000 (99.9231)  time: 0.0196  data: 0.0003  max mem: 650\n",
            "Test:   [1400/1459]  eta: 0:00:01  loss: 0.0000 (0.1833)  acc1: 100.0000 (96.0029)  acc5: 100.0000 (99.9286)  time: 0.0204  data: 0.0003  max mem: 650\n",
            "Test:  Total time: 0:00:29\n",
            "Test:  Acc@1 96.093 Acc@5 99.931  Kappa 0.956 Loss 0.177\n",
            "Epoch: [7]  [ 0/46]  eta: 0:00:06  lr: 0.0003  img/s: 1054.8722688547266  loss: 0.0833 (0.0833)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.1465  data: 0.0252  max mem: 650\n",
            "Epoch: [7]  [10/46]  eta: 0:00:03  lr: 0.0003  img/s: 1727.395002541844  loss: 0.0833 (0.0694)  acc1: 98.4375 (98.2244)  acc5: 100.0000 (100.0000)  time: 0.1016  data: 0.0202  max mem: 650\n",
            "Epoch: [7]  [20/46]  eta: 0:00:02  lr: 0.0003  img/s: 1730.9873256102633  loss: 0.0563 (0.0686)  acc1: 98.4375 (98.3259)  acc5: 100.0000 (100.0000)  time: 0.0951  data: 0.0195  max mem: 650\n",
            "Epoch: [7]  [30/46]  eta: 0:00:01  lr: 0.0003  img/s: 1710.6788981471154  loss: 0.0352 (0.0555)  acc1: 98.4375 (98.4879)  acc5: 100.0000 (100.0000)  time: 0.0927  data: 0.0191  max mem: 650\n",
            "Epoch: [7]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 1728.707671898043  loss: 0.0309 (0.0557)  acc1: 99.2188 (98.5709)  acc5: 100.0000 (100.0000)  time: 0.0932  data: 0.0194  max mem: 650\n",
            "Epoch: [7] Total time: 0:00:04\n",
            "Test:   [   0/1459]  eta: 0:00:29  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0200  data: 0.0006  max mem: 650\n",
            "Test:   [ 100/1459]  eta: 0:00:27  loss: 0.0000 (0.1395)  acc1: 100.0000 (96.0396)  acc5: 100.0000 (100.0000)  time: 0.0198  data: 0.0003  max mem: 650\n",
            "Test:   [ 200/1459]  eta: 0:00:25  loss: 0.0000 (0.0903)  acc1: 100.0000 (97.5124)  acc5: 100.0000 (100.0000)  time: 0.0200  data: 0.0003  max mem: 650\n",
            "Test:   [ 300/1459]  eta: 0:00:23  loss: 0.0000 (0.1934)  acc1: 100.0000 (97.0100)  acc5: 100.0000 (99.6678)  time: 0.0196  data: 0.0003  max mem: 650\n",
            "Test:   [ 400/1459]  eta: 0:00:21  loss: 0.0000 (0.2623)  acc1: 100.0000 (96.0100)  acc5: 100.0000 (99.7506)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [ 500/1459]  eta: 0:00:19  loss: 0.0000 (0.2375)  acc1: 100.0000 (96.4072)  acc5: 100.0000 (99.6008)  time: 0.0198  data: 0.0003  max mem: 650\n",
            "Test:   [ 600/1459]  eta: 0:00:17  loss: 0.0000 (0.2365)  acc1: 100.0000 (96.0067)  acc5: 100.0000 (99.5008)  time: 0.0195  data: 0.0003  max mem: 650\n",
            "Test:   [ 700/1459]  eta: 0:00:15  loss: 0.0000 (0.2257)  acc1: 100.0000 (95.8631)  acc5: 100.0000 (99.5720)  time: 0.0203  data: 0.0004  max mem: 650\n",
            "Test:   [ 800/1459]  eta: 0:00:13  loss: 0.0000 (0.2416)  acc1: 100.0000 (95.3808)  acc5: 100.0000 (99.6255)  time: 0.0210  data: 0.0004  max mem: 650\n",
            "Test:   [ 900/1459]  eta: 0:00:11  loss: 0.0000 (0.2497)  acc1: 100.0000 (95.4495)  acc5: 100.0000 (99.5560)  time: 0.0200  data: 0.0003  max mem: 650\n",
            "Test:   [1000/1459]  eta: 0:00:09  loss: 0.0000 (0.2474)  acc1: 100.0000 (95.6044)  acc5: 100.0000 (99.6004)  time: 0.0199  data: 0.0003  max mem: 650\n",
            "Test:   [1100/1459]  eta: 0:00:07  loss: 0.0000 (0.2384)  acc1: 100.0000 (95.6403)  acc5: 100.0000 (99.6367)  time: 0.0199  data: 0.0003  max mem: 650\n",
            "Test:   [1200/1459]  eta: 0:00:05  loss: 0.0000 (0.2437)  acc1: 100.0000 (95.5870)  acc5: 100.0000 (99.5837)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [1300/1459]  eta: 0:00:03  loss: 0.0000 (0.2466)  acc1: 100.0000 (95.5419)  acc5: 100.0000 (99.5388)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [1400/1459]  eta: 0:00:01  loss: 0.0000 (0.2328)  acc1: 100.0000 (95.7887)  acc5: 100.0000 (99.5717)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:  Total time: 0:00:29\n",
            "Test:  Acc@1 95.888 Acc@5 99.589  Kappa 0.954 Loss 0.225\n",
            "Epoch: [8]  [ 0/46]  eta: 0:00:06  lr: 0.0003  img/s: 1069.4916641267603  loss: 0.0169 (0.0169)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1407  data: 0.0210  max mem: 650\n",
            "Epoch: [8]  [10/46]  eta: 0:00:03  lr: 0.0003  img/s: 1727.650705385645  loss: 0.0265 (0.0421)  acc1: 99.2188 (98.8636)  acc5: 100.0000 (99.9290)  time: 0.1009  data: 0.0192  max mem: 650\n",
            "Epoch: [8]  [20/46]  eta: 0:00:02  lr: 0.0003  img/s: 1709.339030377514  loss: 0.0260 (0.0407)  acc1: 99.2188 (98.9583)  acc5: 100.0000 (99.9628)  time: 0.0962  data: 0.0194  max mem: 650\n",
            "Epoch: [8]  [30/46]  eta: 0:00:01  lr: 0.0003  img/s: 1713.512594313728  loss: 0.0151 (0.0348)  acc1: 99.2188 (99.0927)  acc5: 100.0000 (99.9748)  time: 0.0950  data: 0.0195  max mem: 650\n",
            "Epoch: [8]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 1680.8627121934114  loss: 0.0207 (0.0347)  acc1: 99.2188 (99.0473)  acc5: 100.0000 (99.9809)  time: 0.0948  data: 0.0194  max mem: 650\n",
            "Epoch: [8] Total time: 0:00:04\n",
            "Test:   [   0/1459]  eta: 0:00:33  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0232  data: 0.0008  max mem: 650\n",
            "Test:   [ 100/1459]  eta: 0:00:27  loss: 0.0000 (0.1487)  acc1: 100.0000 (96.0396)  acc5: 100.0000 (100.0000)  time: 0.0201  data: 0.0004  max mem: 650\n",
            "Test:   [ 200/1459]  eta: 0:00:25  loss: 0.0000 (0.0854)  acc1: 100.0000 (97.5124)  acc5: 100.0000 (100.0000)  time: 0.0208  data: 0.0004  max mem: 650\n",
            "Test:   [ 300/1459]  eta: 0:00:23  loss: 0.0000 (0.1302)  acc1: 100.0000 (97.3422)  acc5: 100.0000 (100.0000)  time: 0.0205  data: 0.0004  max mem: 650\n",
            "Test:   [ 400/1459]  eta: 0:00:21  loss: 0.0000 (0.1595)  acc1: 100.0000 (96.7581)  acc5: 100.0000 (100.0000)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [ 500/1459]  eta: 0:00:19  loss: 0.0000 (0.1423)  acc1: 100.0000 (97.0060)  acc5: 100.0000 (100.0000)  time: 0.0200  data: 0.0003  max mem: 650\n",
            "Test:   [ 600/1459]  eta: 0:00:17  loss: 0.0000 (0.1491)  acc1: 100.0000 (97.1714)  acc5: 100.0000 (99.8336)  time: 0.0199  data: 0.0003  max mem: 650\n",
            "Test:   [ 700/1459]  eta: 0:00:15  loss: 0.0000 (0.1453)  acc1: 100.0000 (97.2896)  acc5: 100.0000 (99.8573)  time: 0.0200  data: 0.0003  max mem: 650\n",
            "Test:   [ 800/1459]  eta: 0:00:13  loss: 0.0000 (0.1397)  acc1: 100.0000 (97.3783)  acc5: 100.0000 (99.8752)  time: 0.0207  data: 0.0004  max mem: 650\n",
            "Test:   [ 900/1459]  eta: 0:00:11  loss: 0.0000 (0.1568)  acc1: 100.0000 (97.2253)  acc5: 100.0000 (99.7780)  time: 0.0200  data: 0.0003  max mem: 650\n",
            "Test:   [1000/1459]  eta: 0:00:09  loss: 0.0000 (0.1468)  acc1: 100.0000 (97.3027)  acc5: 100.0000 (99.8002)  time: 0.0204  data: 0.0003  max mem: 650\n",
            "Test:   [1100/1459]  eta: 0:00:07  loss: 0.0000 (0.1614)  acc1: 100.0000 (97.0936)  acc5: 100.0000 (99.8183)  time: 0.0204  data: 0.0003  max mem: 650\n",
            "Test:   [1200/1459]  eta: 0:00:05  loss: 0.0000 (0.1802)  acc1: 100.0000 (96.9192)  acc5: 100.0000 (99.7502)  time: 0.0199  data: 0.0003  max mem: 650\n",
            "Test:   [1300/1459]  eta: 0:00:03  loss: 0.0000 (0.1782)  acc1: 100.0000 (97.0023)  acc5: 100.0000 (99.7694)  time: 0.0210  data: 0.0004  max mem: 650\n",
            "Test:   [1400/1459]  eta: 0:00:01  loss: 0.0000 (0.1765)  acc1: 100.0000 (96.9308)  acc5: 100.0000 (99.7859)  time: 0.0214  data: 0.0004  max mem: 650\n",
            "Test:  Total time: 0:00:29\n",
            "Test:  Acc@1 96.984 Acc@5 99.794  Kappa 0.966 Loss 0.172\n",
            "Epoch: [9]  [ 0/46]  eta: 0:00:06  lr: 0.0003  img/s: 1057.6923995295388  loss: 0.0634 (0.0634)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.1449  data: 0.0239  max mem: 650\n",
            "Epoch: [9]  [10/46]  eta: 0:00:03  lr: 0.0003  img/s: 1728.3459325815206  loss: 0.0287 (0.0340)  acc1: 98.4375 (98.7926)  acc5: 100.0000 (100.0000)  time: 0.1018  data: 0.0197  max mem: 650\n",
            "Epoch: [9]  [20/46]  eta: 0:00:02  lr: 0.0003  img/s: 1629.7212172725203  loss: 0.0322 (0.0475)  acc1: 98.4375 (98.4747)  acc5: 100.0000 (100.0000)  time: 0.0956  data: 0.0192  max mem: 650\n",
            "Epoch: [9]  [30/46]  eta: 0:00:01  lr: 0.0003  img/s: 1711.2841605997628  loss: 0.0447 (0.0492)  acc1: 98.4375 (98.5635)  acc5: 100.0000 (100.0000)  time: 0.0935  data: 0.0192  max mem: 650\n",
            "Epoch: [9]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 1677.7897602090086  loss: 0.0243 (0.0458)  acc1: 98.4375 (98.7043)  acc5: 100.0000 (100.0000)  time: 0.0931  data: 0.0191  max mem: 650\n",
            "Epoch: [9] Total time: 0:00:04\n",
            "Test:   [   0/1459]  eta: 0:00:30  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0210  data: 0.0006  max mem: 650\n",
            "Test:   [ 100/1459]  eta: 0:00:27  loss: 0.0000 (0.1260)  acc1: 100.0000 (98.0198)  acc5: 100.0000 (100.0000)  time: 0.0199  data: 0.0003  max mem: 650\n",
            "Test:   [ 200/1459]  eta: 0:00:25  loss: 0.0000 (0.1205)  acc1: 100.0000 (98.0100)  acc5: 100.0000 (100.0000)  time: 0.0199  data: 0.0003  max mem: 650\n",
            "Test:   [ 300/1459]  eta: 0:00:23  loss: 0.0000 (0.2395)  acc1: 100.0000 (96.6777)  acc5: 100.0000 (100.0000)  time: 0.0198  data: 0.0003  max mem: 650\n",
            "Test:   [ 400/1459]  eta: 0:00:21  loss: 0.0000 (0.2544)  acc1: 100.0000 (96.0100)  acc5: 100.0000 (100.0000)  time: 0.0200  data: 0.0003  max mem: 650\n",
            "Test:   [ 500/1459]  eta: 0:00:19  loss: 0.0000 (0.2149)  acc1: 100.0000 (96.2076)  acc5: 100.0000 (100.0000)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [ 600/1459]  eta: 0:00:17  loss: 0.0000 (0.2076)  acc1: 100.0000 (96.0067)  acc5: 100.0000 (100.0000)  time: 0.0200  data: 0.0003  max mem: 650\n",
            "Test:   [ 700/1459]  eta: 0:00:15  loss: 0.0000 (0.2042)  acc1: 100.0000 (96.1484)  acc5: 100.0000 (100.0000)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [ 800/1459]  eta: 0:00:13  loss: 0.0000 (0.1928)  acc1: 100.0000 (96.2547)  acc5: 100.0000 (100.0000)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [ 900/1459]  eta: 0:00:11  loss: 0.0000 (0.2046)  acc1: 100.0000 (96.3374)  acc5: 100.0000 (99.8890)  time: 0.0198  data: 0.0003  max mem: 650\n",
            "Test:   [1000/1459]  eta: 0:00:09  loss: 0.0000 (0.1951)  acc1: 100.0000 (96.5035)  acc5: 100.0000 (99.9001)  time: 0.0200  data: 0.0003  max mem: 650\n",
            "Test:   [1100/1459]  eta: 0:00:07  loss: 0.0000 (0.1915)  acc1: 100.0000 (96.2761)  acc5: 100.0000 (99.9092)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [1200/1459]  eta: 0:00:05  loss: 0.0000 (0.2008)  acc1: 100.0000 (96.2531)  acc5: 100.0000 (99.9167)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [1300/1459]  eta: 0:00:03  loss: 0.0000 (0.1976)  acc1: 100.0000 (96.3105)  acc5: 100.0000 (99.9231)  time: 0.0204  data: 0.0003  max mem: 650\n",
            "Test:   [1400/1459]  eta: 0:00:01  loss: 0.0000 (0.1893)  acc1: 100.0000 (96.4311)  acc5: 100.0000 (99.9286)  time: 0.0215  data: 0.0004  max mem: 650\n",
            "Test:  Total time: 0:00:29\n",
            "Test:  Acc@1 96.504 Acc@5 99.931  Kappa 0.961 Loss 0.183\n",
            "Epoch: [10]  [ 0/46]  eta: 0:00:05  lr: 0.0003  img/s: 1219.0169499992053  loss: 0.0109 (0.0109)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1247  data: 0.0197  max mem: 650\n",
            "Epoch: [10]  [10/46]  eta: 0:00:03  lr: 0.0003  img/s: 1767.1446411702166  loss: 0.0216 (0.0415)  acc1: 99.2188 (99.0767)  acc5: 100.0000 (100.0000)  time: 0.0984  data: 0.0188  max mem: 650\n",
            "Epoch: [10]  [20/46]  eta: 0:00:02  lr: 0.0003  img/s: 1733.7095838742387  loss: 0.0216 (0.0428)  acc1: 99.2188 (98.9583)  acc5: 100.0000 (100.0000)  time: 0.0943  data: 0.0188  max mem: 650\n",
            "Epoch: [10]  [30/46]  eta: 0:00:01  lr: 0.0003  img/s: 1701.0310409834767  loss: 0.0188 (0.0381)  acc1: 99.2188 (99.0171)  acc5: 100.0000 (100.0000)  time: 0.0936  data: 0.0192  max mem: 650\n",
            "Epoch: [10]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 1718.0528916310386  loss: 0.0188 (0.0351)  acc1: 99.2188 (99.0663)  acc5: 100.0000 (100.0000)  time: 0.0941  data: 0.0197  max mem: 650\n",
            "Epoch: [10] Total time: 0:00:04\n",
            "Test:   [   0/1459]  eta: 0:00:30  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0210  data: 0.0006  max mem: 650\n",
            "Test:   [ 100/1459]  eta: 0:00:27  loss: 0.0000 (0.0630)  acc1: 100.0000 (97.0297)  acc5: 100.0000 (100.0000)  time: 0.0200  data: 0.0003  max mem: 650\n",
            "Test:   [ 200/1459]  eta: 0:00:25  loss: 0.0000 (0.1099)  acc1: 100.0000 (96.5174)  acc5: 100.0000 (100.0000)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [ 300/1459]  eta: 0:00:23  loss: 0.0000 (0.1802)  acc1: 100.0000 (96.3455)  acc5: 100.0000 (100.0000)  time: 0.0204  data: 0.0003  max mem: 650\n",
            "Test:   [ 400/1459]  eta: 0:00:21  loss: 0.0000 (0.1860)  acc1: 100.0000 (96.5087)  acc5: 100.0000 (100.0000)  time: 0.0200  data: 0.0003  max mem: 650\n",
            "Test:   [ 500/1459]  eta: 0:00:19  loss: 0.0000 (0.1566)  acc1: 100.0000 (97.0060)  acc5: 100.0000 (100.0000)  time: 0.0200  data: 0.0003  max mem: 650\n",
            "Test:   [ 600/1459]  eta: 0:00:17  loss: 0.0000 (0.1612)  acc1: 100.0000 (97.1714)  acc5: 100.0000 (100.0000)  time: 0.0200  data: 0.0003  max mem: 650\n",
            "Test:   [ 700/1459]  eta: 0:00:15  loss: 0.0000 (0.1488)  acc1: 100.0000 (97.1469)  acc5: 100.0000 (100.0000)  time: 0.0217  data: 0.0004  max mem: 650\n",
            "Test:   [ 800/1459]  eta: 0:00:13  loss: 0.0000 (0.1550)  acc1: 100.0000 (97.1286)  acc5: 100.0000 (100.0000)  time: 0.0199  data: 0.0003  max mem: 650\n",
            "Test:   [ 900/1459]  eta: 0:00:11  loss: 0.0000 (0.1716)  acc1: 100.0000 (97.0033)  acc5: 100.0000 (99.8890)  time: 0.0202  data: 0.0004  max mem: 650\n",
            "Test:   [1000/1459]  eta: 0:00:09  loss: 0.0000 (0.1824)  acc1: 100.0000 (96.9031)  acc5: 100.0000 (99.9001)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [1100/1459]  eta: 0:00:07  loss: 0.0000 (0.1872)  acc1: 100.0000 (96.8211)  acc5: 100.0000 (99.9092)  time: 0.0197  data: 0.0003  max mem: 650\n",
            "Test:   [1200/1459]  eta: 0:00:05  loss: 0.0000 (0.1842)  acc1: 100.0000 (97.0025)  acc5: 100.0000 (99.8335)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [1300/1459]  eta: 0:00:03  loss: 0.0000 (0.1902)  acc1: 100.0000 (96.8486)  acc5: 100.0000 (99.8463)  time: 0.0197  data: 0.0003  max mem: 650\n",
            "Test:   [1400/1459]  eta: 0:00:01  loss: 0.0000 (0.1909)  acc1: 100.0000 (96.7880)  acc5: 100.0000 (99.8572)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:  Total time: 0:00:29\n",
            "Test:  Acc@1 96.847 Acc@5 99.863  Kappa 0.965 Loss 0.186\n",
            "Epoch: [11]  [ 0/46]  eta: 0:00:06  lr: 0.0003  img/s: 1072.0929450505123  loss: 0.0146 (0.0146)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1401  data: 0.0207  max mem: 650\n",
            "Epoch: [11]  [10/46]  eta: 0:00:03  lr: 0.0003  img/s: 1693.7914463472193  loss: 0.0159 (0.0373)  acc1: 99.2188 (99.0767)  acc5: 100.0000 (100.0000)  time: 0.1017  data: 0.0191  max mem: 650\n",
            "Epoch: [11]  [20/46]  eta: 0:00:02  lr: 0.0003  img/s: 1734.0567692923864  loss: 0.0236 (0.0454)  acc1: 99.2188 (98.9583)  acc5: 100.0000 (100.0000)  time: 0.0953  data: 0.0189  max mem: 650\n",
            "Epoch: [11]  [30/46]  eta: 0:00:01  lr: 0.0003  img/s: 1714.0870275948162  loss: 0.0331 (0.0466)  acc1: 98.4375 (98.8407)  acc5: 100.0000 (100.0000)  time: 0.0935  data: 0.0192  max mem: 650\n",
            "Epoch: [11]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 1718.289337323369  loss: 0.0398 (0.0475)  acc1: 98.4375 (98.7995)  acc5: 100.0000 (100.0000)  time: 0.0936  data: 0.0191  max mem: 650\n",
            "Epoch: [11] Total time: 0:00:04\n",
            "Test:   [   0/1459]  eta: 0:00:29  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0200  data: 0.0006  max mem: 650\n",
            "Test:   [ 100/1459]  eta: 0:00:27  loss: 0.0000 (0.0728)  acc1: 100.0000 (99.0099)  acc5: 100.0000 (100.0000)  time: 0.0209  data: 0.0003  max mem: 650\n",
            "Test:   [ 200/1459]  eta: 0:00:25  loss: 0.0000 (0.0674)  acc1: 100.0000 (98.5075)  acc5: 100.0000 (100.0000)  time: 0.0205  data: 0.0003  max mem: 650\n",
            "Test:   [ 300/1459]  eta: 0:00:23  loss: 0.0000 (0.1809)  acc1: 100.0000 (97.6744)  acc5: 100.0000 (99.6678)  time: 0.0204  data: 0.0003  max mem: 650\n",
            "Test:   [ 400/1459]  eta: 0:00:21  loss: 0.0000 (0.2242)  acc1: 100.0000 (97.2569)  acc5: 100.0000 (99.7506)  time: 0.0204  data: 0.0003  max mem: 650\n",
            "Test:   [ 500/1459]  eta: 0:00:19  loss: 0.0000 (0.2027)  acc1: 100.0000 (97.0060)  acc5: 100.0000 (99.8004)  time: 0.0199  data: 0.0003  max mem: 650\n",
            "Test:   [ 600/1459]  eta: 0:00:17  loss: 0.0000 (0.1960)  acc1: 100.0000 (96.8386)  acc5: 100.0000 (99.8336)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [ 700/1459]  eta: 0:00:15  loss: 0.0000 (0.1710)  acc1: 100.0000 (97.1469)  acc5: 100.0000 (99.8573)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [ 800/1459]  eta: 0:00:13  loss: 0.0000 (0.1996)  acc1: 100.0000 (96.8789)  acc5: 100.0000 (99.8752)  time: 0.0203  data: 0.0003  max mem: 650\n",
            "Test:   [ 900/1459]  eta: 0:00:11  loss: 0.0000 (0.1968)  acc1: 100.0000 (97.0033)  acc5: 100.0000 (99.8890)  time: 0.0203  data: 0.0003  max mem: 650\n",
            "Test:   [1000/1459]  eta: 0:00:09  loss: 0.0000 (0.1870)  acc1: 100.0000 (97.0030)  acc5: 100.0000 (99.9001)  time: 0.0202  data: 0.0004  max mem: 650\n",
            "Test:   [1100/1459]  eta: 0:00:07  loss: 0.0000 (0.1879)  acc1: 100.0000 (96.9119)  acc5: 100.0000 (99.9092)  time: 0.0206  data: 0.0003  max mem: 650\n",
            "Test:   [1200/1459]  eta: 0:00:05  loss: 0.0000 (0.1962)  acc1: 100.0000 (96.6694)  acc5: 100.0000 (99.9167)  time: 0.0203  data: 0.0003  max mem: 650\n",
            "Test:   [1300/1459]  eta: 0:00:03  loss: 0.0000 (0.2082)  acc1: 100.0000 (96.6180)  acc5: 100.0000 (99.9231)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [1400/1459]  eta: 0:00:01  loss: 0.0001 (0.2032)  acc1: 100.0000 (96.5739)  acc5: 100.0000 (99.9286)  time: 0.0206  data: 0.0003  max mem: 650\n",
            "Test:  Total time: 0:00:29\n",
            "Test:  Acc@1 96.504 Acc@5 99.931  Kappa 0.961 Loss 0.198\n",
            "Epoch: [12]  [ 0/46]  eta: 0:00:05  lr: 0.0003  img/s: 1259.8108468339935  loss: 0.0718 (0.0718)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.1233  data: 0.0217  max mem: 650\n",
            "Epoch: [12]  [10/46]  eta: 0:00:03  lr: 0.0003  img/s: 1725.1247947507607  loss: 0.0788 (0.0728)  acc1: 98.4375 (98.0824)  acc5: 100.0000 (100.0000)  time: 0.1007  data: 0.0199  max mem: 650\n",
            "Epoch: [12]  [20/46]  eta: 0:00:02  lr: 0.0003  img/s: 1650.3261853236277  loss: 0.0208 (0.0508)  acc1: 98.4375 (98.6979)  acc5: 100.0000 (100.0000)  time: 0.0974  data: 0.0201  max mem: 650\n",
            "Epoch: [12]  [30/46]  eta: 0:00:01  lr: 0.0003  img/s: 1721.910118413794  loss: 0.0134 (0.0441)  acc1: 99.2188 (98.7651)  acc5: 100.0000 (100.0000)  time: 0.0963  data: 0.0204  max mem: 650\n",
            "Epoch: [12]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 1713.2610590945935  loss: 0.0271 (0.0438)  acc1: 99.2188 (98.7995)  acc5: 100.0000 (100.0000)  time: 0.0956  data: 0.0201  max mem: 650\n",
            "Epoch: [12] Total time: 0:00:04\n",
            "Test:   [   0/1459]  eta: 0:00:30  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0210  data: 0.0007  max mem: 650\n",
            "Test:   [ 100/1459]  eta: 0:00:27  loss: 0.0000 (0.1144)  acc1: 100.0000 (98.0198)  acc5: 100.0000 (100.0000)  time: 0.0198  data: 0.0003  max mem: 650\n",
            "Test:   [ 200/1459]  eta: 0:00:25  loss: 0.0000 (0.0680)  acc1: 100.0000 (98.5075)  acc5: 100.0000 (100.0000)  time: 0.0199  data: 0.0003  max mem: 650\n",
            "Test:   [ 300/1459]  eta: 0:00:23  loss: 0.0000 (0.1441)  acc1: 100.0000 (98.3389)  acc5: 100.0000 (99.6678)  time: 0.0208  data: 0.0003  max mem: 650\n",
            "Test:   [ 400/1459]  eta: 0:00:21  loss: 0.0000 (0.1719)  acc1: 100.0000 (97.7556)  acc5: 100.0000 (99.7506)  time: 0.0199  data: 0.0003  max mem: 650\n",
            "Test:   [ 500/1459]  eta: 0:00:19  loss: 0.0000 (0.1602)  acc1: 100.0000 (97.6048)  acc5: 100.0000 (99.8004)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [ 600/1459]  eta: 0:00:17  loss: 0.0000 (0.1438)  acc1: 100.0000 (97.6705)  acc5: 100.0000 (99.8336)  time: 0.0213  data: 0.0004  max mem: 650\n",
            "Test:   [ 700/1459]  eta: 0:00:15  loss: 0.0000 (0.1420)  acc1: 100.0000 (97.4322)  acc5: 100.0000 (99.8573)  time: 0.0203  data: 0.0003  max mem: 650\n",
            "Test:   [ 800/1459]  eta: 0:00:13  loss: 0.0000 (0.1347)  acc1: 100.0000 (97.5031)  acc5: 100.0000 (99.8752)  time: 0.0207  data: 0.0003  max mem: 650\n",
            "Test:   [ 900/1459]  eta: 0:00:11  loss: 0.0000 (0.1437)  acc1: 100.0000 (97.4473)  acc5: 100.0000 (99.7780)  time: 0.0279  data: 0.0007  max mem: 650\n",
            "Test:   [1000/1459]  eta: 0:00:09  loss: 0.0000 (0.1337)  acc1: 100.0000 (97.5025)  acc5: 100.0000 (99.8002)  time: 0.0206  data: 0.0003  max mem: 650\n",
            "Test:   [1100/1459]  eta: 0:00:07  loss: 0.0000 (0.1448)  acc1: 100.0000 (97.4569)  acc5: 100.0000 (99.8183)  time: 0.0210  data: 0.0004  max mem: 650\n",
            "Test:   [1200/1459]  eta: 0:00:05  loss: 0.0000 (0.1407)  acc1: 100.0000 (97.5021)  acc5: 100.0000 (99.7502)  time: 0.0203  data: 0.0003  max mem: 650\n",
            "Test:   [1300/1459]  eta: 0:00:03  loss: 0.0000 (0.1505)  acc1: 100.0000 (97.3098)  acc5: 100.0000 (99.7694)  time: 0.0200  data: 0.0003  max mem: 650\n",
            "Test:   [1400/1459]  eta: 0:00:01  loss: 0.0000 (0.1498)  acc1: 100.0000 (97.2877)  acc5: 100.0000 (99.7859)  time: 0.0203  data: 0.0003  max mem: 650\n",
            "Test:  Total time: 0:00:30\n",
            "Test:  Acc@1 97.395 Acc@5 99.794  Kappa 0.971 Loss 0.144\n",
            "Epoch: [13]  [ 0/46]  eta: 0:00:06  lr: 0.0003  img/s: 1054.3729921344893  loss: 0.0311 (0.0311)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1451  data: 0.0237  max mem: 650\n",
            "Epoch: [13]  [10/46]  eta: 0:00:03  lr: 0.0003  img/s: 1667.720488694361  loss: 0.0089 (0.0144)  acc1: 100.0000 (99.5739)  acc5: 100.0000 (100.0000)  time: 0.1053  data: 0.0209  max mem: 650\n",
            "Epoch: [13]  [20/46]  eta: 0:00:02  lr: 0.0003  img/s: 1662.1030256310235  loss: 0.0072 (0.0142)  acc1: 100.0000 (99.4792)  acc5: 100.0000 (100.0000)  time: 0.0983  data: 0.0205  max mem: 650\n",
            "Epoch: [13]  [30/46]  eta: 0:00:01  lr: 0.0003  img/s: 1722.3907270108214  loss: 0.0052 (0.0150)  acc1: 100.0000 (99.4960)  acc5: 100.0000 (100.0000)  time: 0.0957  data: 0.0203  max mem: 650\n",
            "Epoch: [13]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 1688.3901150394051  loss: 0.0070 (0.0173)  acc1: 100.0000 (99.5046)  acc5: 100.0000 (100.0000)  time: 0.0960  data: 0.0203  max mem: 650\n",
            "Epoch: [13] Total time: 0:00:04\n",
            "Test:   [   0/1459]  eta: 0:00:29  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0202  data: 0.0006  max mem: 650\n",
            "Test:   [ 100/1459]  eta: 0:00:27  loss: 0.0000 (0.1343)  acc1: 100.0000 (98.0198)  acc5: 100.0000 (100.0000)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [ 200/1459]  eta: 0:00:25  loss: 0.0000 (0.0734)  acc1: 100.0000 (99.0050)  acc5: 100.0000 (100.0000)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [ 300/1459]  eta: 0:00:23  loss: 0.0000 (0.1983)  acc1: 100.0000 (97.6744)  acc5: 100.0000 (99.6678)  time: 0.0200  data: 0.0003  max mem: 650\n",
            "Test:   [ 400/1459]  eta: 0:00:21  loss: 0.0000 (0.2201)  acc1: 100.0000 (97.2569)  acc5: 100.0000 (99.7506)  time: 0.0208  data: 0.0004  max mem: 650\n",
            "Test:   [ 500/1459]  eta: 0:00:19  loss: 0.0000 (0.1929)  acc1: 100.0000 (97.2056)  acc5: 100.0000 (99.8004)  time: 0.0205  data: 0.0003  max mem: 650\n",
            "Test:   [ 600/1459]  eta: 0:00:17  loss: 0.0000 (0.1894)  acc1: 100.0000 (97.0050)  acc5: 100.0000 (99.8336)  time: 0.0214  data: 0.0004  max mem: 650\n",
            "Test:   [ 700/1459]  eta: 0:00:15  loss: 0.0000 (0.1755)  acc1: 100.0000 (97.0043)  acc5: 100.0000 (99.8573)  time: 0.0216  data: 0.0004  max mem: 650\n",
            "Test:   [ 800/1459]  eta: 0:00:13  loss: 0.0000 (0.1808)  acc1: 100.0000 (96.8789)  acc5: 100.0000 (99.8752)  time: 0.0210  data: 0.0004  max mem: 650\n",
            "Test:   [ 900/1459]  eta: 0:00:11  loss: 0.0000 (0.1797)  acc1: 100.0000 (97.0033)  acc5: 100.0000 (99.7780)  time: 0.0207  data: 0.0004  max mem: 650\n",
            "Test:   [1000/1459]  eta: 0:00:09  loss: 0.0000 (0.1718)  acc1: 100.0000 (97.1029)  acc5: 100.0000 (99.8002)  time: 0.0216  data: 0.0005  max mem: 650\n",
            "Test:   [1100/1459]  eta: 0:00:07  loss: 0.0000 (0.1751)  acc1: 100.0000 (97.0936)  acc5: 100.0000 (99.8183)  time: 0.0208  data: 0.0004  max mem: 650\n",
            "Test:   [1200/1459]  eta: 0:00:05  loss: 0.0000 (0.1731)  acc1: 100.0000 (97.1690)  acc5: 100.0000 (99.8335)  time: 0.0208  data: 0.0004  max mem: 650\n",
            "Test:   [1300/1459]  eta: 0:00:03  loss: 0.0000 (0.1723)  acc1: 100.0000 (97.1560)  acc5: 100.0000 (99.8463)  time: 0.0209  data: 0.0004  max mem: 650\n",
            "Test:   [1400/1459]  eta: 0:00:01  loss: 0.0000 (0.1628)  acc1: 100.0000 (97.2877)  acc5: 100.0000 (99.8572)  time: 0.0203  data: 0.0004  max mem: 650\n",
            "Test:  Total time: 0:00:30\n",
            "Test:  Acc@1 97.395 Acc@5 99.863  Kappa 0.971 Loss 0.156\n",
            "Epoch: [14]  [ 0/46]  eta: 0:00:06  lr: 0.0003  img/s: 1053.5288200583602  loss: 0.0002 (0.0002)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1443  data: 0.0228  max mem: 650\n",
            "Epoch: [14]  [10/46]  eta: 0:00:03  lr: 0.0003  img/s: 1629.7212172725203  loss: 0.0024 (0.0074)  acc1: 100.0000 (99.8580)  acc5: 100.0000 (100.0000)  time: 0.1061  data: 0.0212  max mem: 650\n",
            "Epoch: [14]  [20/46]  eta: 0:00:02  lr: 0.0003  img/s: 1687.9919761800707  loss: 0.0032 (0.0063)  acc1: 100.0000 (99.8884)  acc5: 100.0000 (100.0000)  time: 0.1002  data: 0.0211  max mem: 650\n",
            "Epoch: [14]  [30/46]  eta: 0:00:01  lr: 0.0003  img/s: 1654.945413743357  loss: 0.0056 (0.0112)  acc1: 100.0000 (99.7732)  acc5: 100.0000 (100.0000)  time: 0.0972  data: 0.0206  max mem: 650\n",
            "Epoch: [14]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 1674.7541449993294  loss: 0.0062 (0.0117)  acc1: 100.0000 (99.7142)  acc5: 100.0000 (100.0000)  time: 0.0964  data: 0.0202  max mem: 650\n",
            "Epoch: [14] Total time: 0:00:04\n",
            "Test:   [   0/1459]  eta: 0:00:33  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0230  data: 0.0007  max mem: 650\n",
            "Test:   [ 100/1459]  eta: 0:00:28  loss: 0.0000 (0.0477)  acc1: 100.0000 (98.0198)  acc5: 100.0000 (100.0000)  time: 0.0205  data: 0.0003  max mem: 650\n",
            "Test:   [ 200/1459]  eta: 0:00:25  loss: 0.0000 (0.0341)  acc1: 100.0000 (98.5075)  acc5: 100.0000 (100.0000)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [ 300/1459]  eta: 0:00:23  loss: 0.0000 (0.1178)  acc1: 100.0000 (98.0066)  acc5: 100.0000 (100.0000)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [ 400/1459]  eta: 0:00:21  loss: 0.0000 (0.1440)  acc1: 100.0000 (97.5062)  acc5: 100.0000 (100.0000)  time: 0.0214  data: 0.0004  max mem: 650\n",
            "Test:   [ 500/1459]  eta: 0:00:19  loss: 0.0000 (0.1278)  acc1: 100.0000 (97.6048)  acc5: 100.0000 (100.0000)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [ 600/1459]  eta: 0:00:17  loss: 0.0000 (0.1311)  acc1: 100.0000 (97.5042)  acc5: 100.0000 (100.0000)  time: 0.0199  data: 0.0003  max mem: 650\n",
            "Test:   [ 700/1459]  eta: 0:00:15  loss: 0.0000 (0.1318)  acc1: 100.0000 (97.5749)  acc5: 100.0000 (100.0000)  time: 0.0216  data: 0.0004  max mem: 650\n",
            "Test:   [ 800/1459]  eta: 0:00:13  loss: 0.0000 (0.1413)  acc1: 100.0000 (97.3783)  acc5: 100.0000 (100.0000)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [ 900/1459]  eta: 0:00:11  loss: 0.0000 (0.1426)  acc1: 100.0000 (97.4473)  acc5: 100.0000 (99.8890)  time: 0.0216  data: 0.0004  max mem: 650\n",
            "Test:   [1000/1459]  eta: 0:00:09  loss: 0.0000 (0.1526)  acc1: 100.0000 (97.3027)  acc5: 100.0000 (99.9001)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [1100/1459]  eta: 0:00:07  loss: 0.0000 (0.1520)  acc1: 100.0000 (97.3660)  acc5: 100.0000 (99.9092)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [1200/1459]  eta: 0:00:05  loss: 0.0000 (0.1482)  acc1: 100.0000 (97.4188)  acc5: 100.0000 (99.9167)  time: 0.0208  data: 0.0004  max mem: 650\n",
            "Test:   [1300/1459]  eta: 0:00:03  loss: 0.0000 (0.1586)  acc1: 100.0000 (97.3866)  acc5: 100.0000 (99.9231)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [1400/1459]  eta: 0:00:01  loss: 0.0000 (0.1547)  acc1: 100.0000 (97.5018)  acc5: 100.0000 (99.9286)  time: 0.0203  data: 0.0003  max mem: 650\n",
            "Test:  Total time: 0:00:29\n",
            "Test:  Acc@1 97.533 Acc@5 99.931  Kappa 0.972 Loss 0.153\n",
            "Epoch: [15]  [ 0/46]  eta: 0:00:06  lr: 0.0003  img/s: 1073.567905999228  loss: 0.0094 (0.0094)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1394  data: 0.0201  max mem: 650\n",
            "Epoch: [15]  [10/46]  eta: 0:00:03  lr: 0.0003  img/s: 1751.9609450463386  loss: 0.0055 (0.0153)  acc1: 100.0000 (99.5028)  acc5: 100.0000 (100.0000)  time: 0.1032  data: 0.0195  max mem: 650\n",
            "Epoch: [15]  [20/46]  eta: 0:00:02  lr: 0.0003  img/s: 1737.5419100727224  loss: 0.0020 (0.0128)  acc1: 100.0000 (99.5536)  acc5: 100.0000 (100.0000)  time: 0.0965  data: 0.0194  max mem: 650\n",
            "Epoch: [15]  [30/46]  eta: 0:00:01  lr: 0.0003  img/s: 1687.254588424599  loss: 0.0049 (0.0146)  acc1: 99.2188 (99.5464)  acc5: 100.0000 (100.0000)  time: 0.0935  data: 0.0193  max mem: 650\n",
            "Epoch: [15]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 1737.8512533664803  loss: 0.0049 (0.0162)  acc1: 99.2188 (99.5046)  acc5: 100.0000 (100.0000)  time: 0.0943  data: 0.0197  max mem: 650\n",
            "Epoch: [15] Total time: 0:00:04\n",
            "Test:   [   0/1459]  eta: 0:00:29  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0200  data: 0.0006  max mem: 650\n",
            "Test:   [ 100/1459]  eta: 0:00:27  loss: 0.0000 (0.0547)  acc1: 100.0000 (99.0099)  acc5: 100.0000 (100.0000)  time: 0.0206  data: 0.0003  max mem: 650\n",
            "Test:   [ 200/1459]  eta: 0:00:25  loss: 0.0000 (0.0665)  acc1: 100.0000 (99.0050)  acc5: 100.0000 (100.0000)  time: 0.0204  data: 0.0003  max mem: 650\n",
            "Test:   [ 300/1459]  eta: 0:00:23  loss: 0.0000 (0.1460)  acc1: 100.0000 (98.3389)  acc5: 100.0000 (100.0000)  time: 0.0214  data: 0.0004  max mem: 650\n",
            "Test:   [ 400/1459]  eta: 0:00:21  loss: 0.0000 (0.1533)  acc1: 100.0000 (98.0050)  acc5: 100.0000 (100.0000)  time: 0.0199  data: 0.0003  max mem: 650\n",
            "Test:   [ 500/1459]  eta: 0:00:19  loss: 0.0000 (0.1261)  acc1: 100.0000 (98.2036)  acc5: 100.0000 (100.0000)  time: 0.0203  data: 0.0003  max mem: 650\n",
            "Test:   [ 600/1459]  eta: 0:00:17  loss: 0.0000 (0.1292)  acc1: 100.0000 (98.1697)  acc5: 100.0000 (100.0000)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [ 700/1459]  eta: 0:00:15  loss: 0.0000 (0.1274)  acc1: 100.0000 (98.1455)  acc5: 100.0000 (100.0000)  time: 0.0205  data: 0.0003  max mem: 650\n",
            "Test:   [ 800/1459]  eta: 0:00:13  loss: 0.0000 (0.1152)  acc1: 100.0000 (98.2522)  acc5: 100.0000 (100.0000)  time: 0.0206  data: 0.0003  max mem: 650\n",
            "Test:   [ 900/1459]  eta: 0:00:11  loss: 0.0000 (0.1329)  acc1: 100.0000 (98.2242)  acc5: 100.0000 (99.8890)  time: 0.0203  data: 0.0003  max mem: 650\n",
            "Test:   [1000/1459]  eta: 0:00:09  loss: 0.0000 (0.1256)  acc1: 100.0000 (98.2018)  acc5: 100.0000 (99.9001)  time: 0.0203  data: 0.0003  max mem: 650\n",
            "Test:   [1100/1459]  eta: 0:00:07  loss: 0.0000 (0.1289)  acc1: 100.0000 (98.0926)  acc5: 100.0000 (99.9092)  time: 0.0204  data: 0.0003  max mem: 650\n",
            "Test:   [1200/1459]  eta: 0:00:05  loss: 0.0000 (0.1384)  acc1: 100.0000 (98.0849)  acc5: 100.0000 (99.9167)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [1300/1459]  eta: 0:00:03  loss: 0.0000 (0.1380)  acc1: 100.0000 (98.1553)  acc5: 100.0000 (99.9231)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [1400/1459]  eta: 0:00:01  loss: 0.0000 (0.1362)  acc1: 100.0000 (98.2156)  acc5: 100.0000 (99.9286)  time: 0.0220  data: 0.0004  max mem: 650\n",
            "Test:  Total time: 0:00:29\n",
            "Test:  Acc@1 98.218 Acc@5 99.931  Kappa 0.980 Loss 0.135\n",
            "Epoch: [16]  [ 0/46]  eta: 0:00:05  lr: 0.0003  img/s: 1223.8828802130113  loss: 0.0020 (0.0020)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1247  data: 0.0201  max mem: 650\n",
            "Epoch: [16]  [10/46]  eta: 0:00:03  lr: 0.0003  img/s: 1731.9366287828686  loss: 0.0134 (0.0190)  acc1: 99.2188 (99.4318)  acc5: 100.0000 (100.0000)  time: 0.0994  data: 0.0195  max mem: 650\n",
            "Epoch: [16]  [20/46]  eta: 0:00:02  lr: 0.0003  img/s: 1717.3659188837316  loss: 0.0054 (0.0173)  acc1: 99.2188 (99.4420)  acc5: 100.0000 (100.0000)  time: 0.0954  data: 0.0195  max mem: 650\n",
            "Epoch: [16]  [30/46]  eta: 0:00:01  lr: 0.0003  img/s: 1702.3795031154377  loss: 0.0054 (0.0165)  acc1: 100.0000 (99.5212)  acc5: 100.0000 (100.0000)  time: 0.0941  data: 0.0194  max mem: 650\n",
            "Epoch: [16]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 1713.1681191145547  loss: 0.0106 (0.0187)  acc1: 99.2188 (99.4665)  acc5: 100.0000 (100.0000)  time: 0.0941  data: 0.0193  max mem: 650\n",
            "Epoch: [16] Total time: 0:00:04\n",
            "Test:   [   0/1459]  eta: 0:00:33  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0226  data: 0.0006  max mem: 650\n",
            "Test:   [ 100/1459]  eta: 0:00:27  loss: 0.0000 (0.0950)  acc1: 100.0000 (98.0198)  acc5: 100.0000 (100.0000)  time: 0.0203  data: 0.0004  max mem: 650\n",
            "Test:   [ 200/1459]  eta: 0:00:25  loss: 0.0000 (0.0667)  acc1: 100.0000 (98.5075)  acc5: 100.0000 (100.0000)  time: 0.0205  data: 0.0003  max mem: 650\n",
            "Test:   [ 300/1459]  eta: 0:00:23  loss: 0.0000 (0.1741)  acc1: 100.0000 (97.0100)  acc5: 100.0000 (100.0000)  time: 0.0204  data: 0.0003  max mem: 650\n",
            "Test:   [ 400/1459]  eta: 0:00:21  loss: 0.0000 (0.2070)  acc1: 100.0000 (96.7581)  acc5: 100.0000 (100.0000)  time: 0.0205  data: 0.0003  max mem: 650\n",
            "Test:   [ 500/1459]  eta: 0:00:19  loss: 0.0000 (0.1980)  acc1: 100.0000 (96.8064)  acc5: 100.0000 (100.0000)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [ 600/1459]  eta: 0:00:17  loss: 0.0000 (0.2010)  acc1: 100.0000 (96.6722)  acc5: 100.0000 (100.0000)  time: 0.0205  data: 0.0004  max mem: 650\n",
            "Test:   [ 700/1459]  eta: 0:00:15  loss: 0.0000 (0.1975)  acc1: 100.0000 (96.7190)  acc5: 100.0000 (100.0000)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [ 800/1459]  eta: 0:00:13  loss: 0.0000 (0.1854)  acc1: 100.0000 (96.7541)  acc5: 100.0000 (100.0000)  time: 0.0200  data: 0.0003  max mem: 650\n",
            "Test:   [ 900/1459]  eta: 0:00:11  loss: 0.0000 (0.1987)  acc1: 100.0000 (96.5594)  acc5: 100.0000 (99.8890)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [1000/1459]  eta: 0:00:09  loss: 0.0000 (0.1793)  acc1: 100.0000 (96.9031)  acc5: 100.0000 (99.9001)  time: 0.0200  data: 0.0003  max mem: 650\n",
            "Test:   [1100/1459]  eta: 0:00:07  loss: 0.0000 (0.1883)  acc1: 100.0000 (96.9119)  acc5: 100.0000 (99.9092)  time: 0.0204  data: 0.0003  max mem: 650\n",
            "Test:   [1200/1459]  eta: 0:00:05  loss: 0.0000 (0.2002)  acc1: 100.0000 (96.7527)  acc5: 100.0000 (99.9167)  time: 0.0209  data: 0.0004  max mem: 650\n",
            "Test:   [1300/1459]  eta: 0:00:03  loss: 0.0000 (0.1954)  acc1: 100.0000 (96.8486)  acc5: 100.0000 (99.9231)  time: 0.0203  data: 0.0003  max mem: 650\n",
            "Test:   [1400/1459]  eta: 0:00:01  loss: 0.0000 (0.1906)  acc1: 100.0000 (96.8594)  acc5: 100.0000 (99.9286)  time: 0.0200  data: 0.0003  max mem: 650\n",
            "Test:  Total time: 0:00:29\n",
            "Test:  Acc@1 96.847 Acc@5 99.931  Kappa 0.965 Loss 0.187\n",
            "Epoch: [17]  [ 0/46]  eta: 0:00:06  lr: 0.0003  img/s: 1130.7949525352115  loss: 0.0459 (0.0459)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1357  data: 0.0225  max mem: 650\n",
            "Epoch: [17]  [10/46]  eta: 0:00:03  lr: 0.0003  img/s: 1700.1745298852977  loss: 0.0036 (0.0119)  acc1: 100.0000 (99.7159)  acc5: 100.0000 (100.0000)  time: 0.1028  data: 0.0197  max mem: 650\n",
            "Epoch: [17]  [20/46]  eta: 0:00:02  lr: 0.0003  img/s: 1762.5498179573801  loss: 0.0027 (0.0133)  acc1: 100.0000 (99.5908)  acc5: 100.0000 (100.0000)  time: 0.0965  data: 0.0194  max mem: 650\n",
            "Epoch: [17]  [30/46]  eta: 0:00:01  lr: 0.0003  img/s: 1720.1446678713778  loss: 0.0047 (0.0138)  acc1: 99.2188 (99.4960)  acc5: 100.0000 (100.0000)  time: 0.0932  data: 0.0192  max mem: 650\n",
            "Epoch: [17]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 1704.6280889921861  loss: 0.0060 (0.0143)  acc1: 99.2188 (99.4855)  acc5: 100.0000 (100.0000)  time: 0.0928  data: 0.0190  max mem: 650\n",
            "Epoch: [17] Total time: 0:00:04\n",
            "Test:   [   0/1459]  eta: 0:00:29  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0204  data: 0.0005  max mem: 650\n",
            "Test:   [ 100/1459]  eta: 0:00:27  loss: 0.0000 (0.1219)  acc1: 100.0000 (97.0297)  acc5: 100.0000 (100.0000)  time: 0.0203  data: 0.0003  max mem: 650\n",
            "Test:   [ 200/1459]  eta: 0:00:25  loss: 0.0000 (0.0849)  acc1: 100.0000 (97.5124)  acc5: 100.0000 (100.0000)  time: 0.0204  data: 0.0004  max mem: 650\n",
            "Test:   [ 300/1459]  eta: 0:00:23  loss: 0.0000 (0.2090)  acc1: 100.0000 (96.6777)  acc5: 100.0000 (99.3355)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [ 400/1459]  eta: 0:00:21  loss: 0.0000 (0.2348)  acc1: 100.0000 (96.7581)  acc5: 100.0000 (99.5012)  time: 0.0199  data: 0.0003  max mem: 650\n",
            "Test:   [ 500/1459]  eta: 0:00:19  loss: 0.0000 (0.2398)  acc1: 100.0000 (96.6068)  acc5: 100.0000 (99.6008)  time: 0.0208  data: 0.0003  max mem: 650\n",
            "Test:   [ 600/1459]  eta: 0:00:17  loss: 0.0000 (0.2359)  acc1: 100.0000 (96.6722)  acc5: 100.0000 (99.6672)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [ 700/1459]  eta: 0:00:15  loss: 0.0000 (0.2323)  acc1: 100.0000 (96.8616)  acc5: 100.0000 (99.7147)  time: 0.0203  data: 0.0003  max mem: 650\n",
            "Test:   [ 800/1459]  eta: 0:00:13  loss: 0.0000 (0.2355)  acc1: 100.0000 (96.6292)  acc5: 100.0000 (99.7503)  time: 0.0204  data: 0.0003  max mem: 650\n",
            "Test:   [ 900/1459]  eta: 0:00:11  loss: 0.0000 (0.2486)  acc1: 100.0000 (96.4484)  acc5: 100.0000 (99.6670)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [1000/1459]  eta: 0:00:09  loss: 0.0000 (0.2375)  acc1: 100.0000 (96.5035)  acc5: 100.0000 (99.7003)  time: 0.0198  data: 0.0003  max mem: 650\n",
            "Test:   [1100/1459]  eta: 0:00:07  loss: 0.0000 (0.2296)  acc1: 100.0000 (96.4578)  acc5: 100.0000 (99.7275)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [1200/1459]  eta: 0:00:05  loss: 0.0000 (0.2344)  acc1: 100.0000 (96.4197)  acc5: 100.0000 (99.7502)  time: 0.0208  data: 0.0003  max mem: 650\n",
            "Test:   [1300/1459]  eta: 0:00:03  loss: 0.0000 (0.2441)  acc1: 100.0000 (96.3874)  acc5: 100.0000 (99.7694)  time: 0.0212  data: 0.0004  max mem: 650\n",
            "Test:   [1400/1459]  eta: 0:00:01  loss: 0.0000 (0.2294)  acc1: 100.0000 (96.5739)  acc5: 100.0000 (99.7859)  time: 0.0204  data: 0.0003  max mem: 650\n",
            "Test:  Total time: 0:00:29\n",
            "Test:  Acc@1 96.504 Acc@5 99.794  Kappa 0.961 Loss 0.230\n",
            "Epoch: [18]  [ 0/46]  eta: 0:00:05  lr: 0.0003  img/s: 1229.0522392672447  loss: 0.0001 (0.0001)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1259  data: 0.0218  max mem: 650\n",
            "Epoch: [18]  [10/46]  eta: 0:00:03  lr: 0.0003  img/s: 1667.725669269814  loss: 0.0089 (0.0172)  acc1: 99.2188 (99.3608)  acc5: 100.0000 (100.0000)  time: 0.1026  data: 0.0203  max mem: 650\n",
            "Epoch: [18]  [20/46]  eta: 0:00:02  lr: 0.0003  img/s: 1689.3357835116426  loss: 0.0136 (0.0210)  acc1: 99.2188 (99.3304)  acc5: 100.0000 (100.0000)  time: 0.0983  data: 0.0202  max mem: 650\n",
            "Epoch: [18]  [30/46]  eta: 0:00:01  lr: 0.0003  img/s: 1680.3681798833163  loss: 0.0088 (0.0202)  acc1: 99.2188 (99.4204)  acc5: 100.0000 (100.0000)  time: 0.0966  data: 0.0203  max mem: 650\n",
            "Epoch: [18]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 1686.8198847533886  loss: 0.0031 (0.0206)  acc1: 100.0000 (99.4474)  acc5: 100.0000 (100.0000)  time: 0.0969  data: 0.0205  max mem: 650\n",
            "Epoch: [18] Total time: 0:00:04\n",
            "Test:   [   0/1459]  eta: 0:00:32  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0221  data: 0.0008  max mem: 650\n",
            "Test:   [ 100/1459]  eta: 0:00:28  loss: 0.0000 (0.1352)  acc1: 100.0000 (96.0396)  acc5: 100.0000 (99.0099)  time: 0.0207  data: 0.0004  max mem: 650\n",
            "Test:   [ 200/1459]  eta: 0:00:26  loss: 0.0000 (0.0749)  acc1: 100.0000 (97.5124)  acc5: 100.0000 (99.5025)  time: 0.0217  data: 0.0005  max mem: 650\n",
            "Test:   [ 300/1459]  eta: 0:00:24  loss: 0.0000 (0.2188)  acc1: 100.0000 (96.6777)  acc5: 100.0000 (99.0033)  time: 0.0206  data: 0.0004  max mem: 650\n",
            "Test:   [ 400/1459]  eta: 0:00:22  loss: 0.0000 (0.2640)  acc1: 100.0000 (96.7581)  acc5: 100.0000 (99.2519)  time: 0.0232  data: 0.0005  max mem: 650\n",
            "Test:   [ 500/1459]  eta: 0:00:20  loss: 0.0000 (0.2175)  acc1: 100.0000 (97.2056)  acc5: 100.0000 (99.4012)  time: 0.0204  data: 0.0003  max mem: 650\n",
            "Test:   [ 600/1459]  eta: 0:00:18  loss: 0.0000 (0.2212)  acc1: 100.0000 (96.8386)  acc5: 100.0000 (99.5008)  time: 0.0207  data: 0.0003  max mem: 650\n",
            "Test:   [ 700/1459]  eta: 0:00:15  loss: 0.0000 (0.2078)  acc1: 100.0000 (97.0043)  acc5: 100.0000 (99.4294)  time: 0.0212  data: 0.0004  max mem: 650\n",
            "Test:   [ 800/1459]  eta: 0:00:13  loss: 0.0000 (0.2259)  acc1: 100.0000 (96.6292)  acc5: 100.0000 (99.5006)  time: 0.0206  data: 0.0003  max mem: 650\n",
            "Test:   [ 900/1459]  eta: 0:00:11  loss: 0.0000 (0.2275)  acc1: 100.0000 (96.6704)  acc5: 100.0000 (99.3341)  time: 0.0204  data: 0.0003  max mem: 650\n",
            "Test:   [1000/1459]  eta: 0:00:09  loss: 0.0000 (0.2159)  acc1: 100.0000 (96.7033)  acc5: 100.0000 (99.4006)  time: 0.0204  data: 0.0003  max mem: 650\n",
            "Test:   [1100/1459]  eta: 0:00:07  loss: 0.0000 (0.2238)  acc1: 100.0000 (96.6394)  acc5: 100.0000 (99.4550)  time: 0.0210  data: 0.0004  max mem: 650\n",
            "Test:   [1200/1459]  eta: 0:00:05  loss: 0.0000 (0.2269)  acc1: 100.0000 (96.5029)  acc5: 100.0000 (99.4172)  time: 0.0208  data: 0.0004  max mem: 650\n",
            "Test:   [1300/1459]  eta: 0:00:03  loss: 0.0000 (0.2438)  acc1: 100.0000 (96.3874)  acc5: 100.0000 (99.4620)  time: 0.0203  data: 0.0004  max mem: 650\n",
            "Test:   [1400/1459]  eta: 0:00:01  loss: 0.0000 (0.2336)  acc1: 100.0000 (96.4311)  acc5: 100.0000 (99.5004)  time: 0.0206  data: 0.0004  max mem: 650\n",
            "Test:  Total time: 0:00:30\n",
            "Test:  Acc@1 96.504 Acc@5 99.520  Kappa 0.961 Loss 0.226\n",
            "Epoch: [19]  [ 0/46]  eta: 0:00:05  lr: 0.0003  img/s: 1225.120115741216  loss: 0.0221 (0.0221)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1266  data: 0.0221  max mem: 650\n",
            "Epoch: [19]  [10/46]  eta: 0:00:03  lr: 0.0003  img/s: 1697.4759766785971  loss: 0.0204 (0.0276)  acc1: 99.2188 (99.1477)  acc5: 100.0000 (100.0000)  time: 0.1019  data: 0.0203  max mem: 650\n",
            "Epoch: [19]  [20/46]  eta: 0:00:02  lr: 0.0003  img/s: 1661.0539616535327  loss: 0.0087 (0.0276)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0979  data: 0.0201  max mem: 650\n",
            "Epoch: [19]  [30/46]  eta: 0:00:01  lr: 0.0003  img/s: 1686.6291099871194  loss: 0.0136 (0.0264)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0962  data: 0.0200  max mem: 650\n",
            "Epoch: [19]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 1680.0737031844583  loss: 0.0063 (0.0240)  acc1: 100.0000 (99.3140)  acc5: 100.0000 (100.0000)  time: 0.0965  data: 0.0202  max mem: 650\n",
            "Epoch: [19] Total time: 0:00:04\n",
            "Test:   [   0/1459]  eta: 0:00:35  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0243  data: 0.0008  max mem: 650\n",
            "Test:   [ 100/1459]  eta: 0:00:29  loss: 0.0000 (0.0827)  acc1: 100.0000 (98.0198)  acc5: 100.0000 (100.0000)  time: 0.0213  data: 0.0004  max mem: 650\n",
            "Test:   [ 200/1459]  eta: 0:00:26  loss: 0.0000 (0.0476)  acc1: 100.0000 (99.0050)  acc5: 100.0000 (100.0000)  time: 0.0207  data: 0.0004  max mem: 650\n",
            "Test:   [ 300/1459]  eta: 0:00:24  loss: 0.0000 (0.1917)  acc1: 100.0000 (98.0066)  acc5: 100.0000 (99.6678)  time: 0.0210  data: 0.0004  max mem: 650\n",
            "Test:   [ 400/1459]  eta: 0:00:22  loss: 0.0000 (0.2420)  acc1: 100.0000 (97.2569)  acc5: 100.0000 (99.7506)  time: 0.0209  data: 0.0004  max mem: 650\n",
            "Test:   [ 500/1459]  eta: 0:00:19  loss: 0.0000 (0.2262)  acc1: 100.0000 (97.0060)  acc5: 100.0000 (99.8004)  time: 0.0213  data: 0.0005  max mem: 650\n",
            "Test:   [ 600/1459]  eta: 0:00:17  loss: 0.0000 (0.2038)  acc1: 100.0000 (96.8386)  acc5: 100.0000 (99.8336)  time: 0.0218  data: 0.0005  max mem: 650\n",
            "Test:   [ 700/1459]  eta: 0:00:15  loss: 0.0000 (0.1962)  acc1: 100.0000 (97.0043)  acc5: 100.0000 (99.8573)  time: 0.0206  data: 0.0004  max mem: 650\n",
            "Test:   [ 800/1459]  eta: 0:00:13  loss: 0.0000 (0.2081)  acc1: 100.0000 (96.7541)  acc5: 100.0000 (99.8752)  time: 0.0203  data: 0.0004  max mem: 650\n",
            "Test:   [ 900/1459]  eta: 0:00:11  loss: 0.0000 (0.2104)  acc1: 100.0000 (96.7814)  acc5: 100.0000 (99.7780)  time: 0.0204  data: 0.0004  max mem: 650\n",
            "Test:   [1000/1459]  eta: 0:00:09  loss: 0.0000 (0.2036)  acc1: 100.0000 (96.8032)  acc5: 100.0000 (99.8002)  time: 0.0219  data: 0.0004  max mem: 650\n",
            "Test:   [1100/1459]  eta: 0:00:07  loss: 0.0000 (0.2008)  acc1: 100.0000 (96.8211)  acc5: 100.0000 (99.8183)  time: 0.0202  data: 0.0004  max mem: 650\n",
            "Test:   [1200/1459]  eta: 0:00:05  loss: 0.0000 (0.1952)  acc1: 100.0000 (96.9192)  acc5: 100.0000 (99.8335)  time: 0.0207  data: 0.0004  max mem: 650\n",
            "Test:   [1300/1459]  eta: 0:00:03  loss: 0.0000 (0.1943)  acc1: 100.0000 (96.8486)  acc5: 100.0000 (99.8463)  time: 0.0206  data: 0.0004  max mem: 650\n",
            "Test:   [1400/1459]  eta: 0:00:01  loss: 0.0000 (0.1876)  acc1: 100.0000 (97.0021)  acc5: 100.0000 (99.8572)  time: 0.0210  data: 0.0004  max mem: 650\n",
            "Test:  Total time: 0:00:30\n",
            "Test:  Acc@1 97.121 Acc@5 99.863  Kappa 0.968 Loss 0.180\n",
            "Epoch: [20]  [ 0/46]  eta: 0:00:06  lr: 0.0003  img/s: 1063.2644164403964  loss: 0.0050 (0.0050)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1414  data: 0.0210  max mem: 650\n",
            "Epoch: [20]  [10/46]  eta: 0:00:03  lr: 0.0003  img/s: 1656.436392358197  loss: 0.0102 (0.0221)  acc1: 99.2188 (99.3608)  acc5: 100.0000 (100.0000)  time: 0.1031  data: 0.0201  max mem: 650\n",
            "Epoch: [20]  [20/46]  eta: 0:00:02  lr: 0.0003  img/s: 1683.2394693855797  loss: 0.0073 (0.0194)  acc1: 99.2188 (99.3304)  acc5: 100.0000 (100.0000)  time: 0.0984  data: 0.0205  max mem: 650\n",
            "Epoch: [20]  [30/46]  eta: 0:00:01  lr: 0.0003  img/s: 1682.7435377454592  loss: 0.0124 (0.0218)  acc1: 99.2188 (99.2944)  acc5: 100.0000 (100.0000)  time: 0.0974  data: 0.0207  max mem: 650\n",
            "Epoch: [20]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 1600.4498792666568  loss: 0.0201 (0.0238)  acc1: 99.2188 (99.2569)  acc5: 100.0000 (99.9809)  time: 0.0968  data: 0.0203  max mem: 650\n",
            "Epoch: [20] Total time: 0:00:04\n",
            "Test:   [   0/1459]  eta: 0:00:30  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0208  data: 0.0007  max mem: 650\n",
            "Test:   [ 100/1459]  eta: 0:00:28  loss: 0.0000 (0.1788)  acc1: 100.0000 (99.0099)  acc5: 100.0000 (100.0000)  time: 0.0208  data: 0.0004  max mem: 650\n",
            "Test:   [ 200/1459]  eta: 0:00:25  loss: 0.0000 (0.1678)  acc1: 100.0000 (98.0100)  acc5: 100.0000 (100.0000)  time: 0.0205  data: 0.0004  max mem: 650\n",
            "Test:   [ 300/1459]  eta: 0:00:23  loss: 0.0000 (0.3025)  acc1: 100.0000 (96.6777)  acc5: 100.0000 (99.6678)  time: 0.0206  data: 0.0004  max mem: 650\n",
            "Test:   [ 400/1459]  eta: 0:00:21  loss: 0.0000 (0.3005)  acc1: 100.0000 (96.7581)  acc5: 100.0000 (99.7506)  time: 0.0203  data: 0.0004  max mem: 650\n",
            "Test:   [ 500/1459]  eta: 0:00:19  loss: 0.0000 (0.2806)  acc1: 100.0000 (96.2076)  acc5: 100.0000 (99.8004)  time: 0.0203  data: 0.0004  max mem: 650\n",
            "Test:   [ 600/1459]  eta: 0:00:17  loss: 0.0000 (0.2630)  acc1: 100.0000 (96.5058)  acc5: 100.0000 (99.8336)  time: 0.0199  data: 0.0003  max mem: 650\n",
            "Test:   [ 700/1459]  eta: 0:00:15  loss: 0.0000 (0.2367)  acc1: 100.0000 (96.8616)  acc5: 100.0000 (99.8573)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [ 800/1459]  eta: 0:00:13  loss: 0.0000 (0.2377)  acc1: 100.0000 (96.7541)  acc5: 100.0000 (99.8752)  time: 0.0197  data: 0.0003  max mem: 650\n",
            "Test:   [ 900/1459]  eta: 0:00:11  loss: 0.0000 (0.2628)  acc1: 100.0000 (96.5594)  acc5: 100.0000 (99.7780)  time: 0.0203  data: 0.0003  max mem: 650\n",
            "Test:   [1000/1459]  eta: 0:00:09  loss: 0.0000 (0.2589)  acc1: 100.0000 (96.4036)  acc5: 100.0000 (99.8002)  time: 0.0198  data: 0.0003  max mem: 650\n",
            "Test:   [1100/1459]  eta: 0:00:07  loss: 0.0000 (0.2467)  acc1: 100.0000 (96.5486)  acc5: 100.0000 (99.8183)  time: 0.0206  data: 0.0003  max mem: 650\n",
            "Test:   [1200/1459]  eta: 0:00:05  loss: 0.0000 (0.2533)  acc1: 100.0000 (96.5029)  acc5: 100.0000 (99.8335)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [1300/1459]  eta: 0:00:03  loss: 0.0000 (0.2402)  acc1: 100.0000 (96.6949)  acc5: 100.0000 (99.8463)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [1400/1459]  eta: 0:00:01  loss: 0.0000 (0.2280)  acc1: 100.0000 (96.8594)  acc5: 100.0000 (99.8572)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:  Total time: 0:00:29\n",
            "Test:  Acc@1 96.847 Acc@5 99.863  Kappa 0.965 Loss 0.223\n",
            "Epoch: [21]  [ 0/46]  eta: 0:00:06  lr: 0.0003  img/s: 1071.8040023637263  loss: 0.0014 (0.0014)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1409  data: 0.0214  max mem: 650\n",
            "Epoch: [21]  [10/46]  eta: 0:00:03  lr: 0.0003  img/s: 1700.319914361815  loss: 0.0374 (0.0544)  acc1: 99.2188 (98.7216)  acc5: 100.0000 (100.0000)  time: 0.1036  data: 0.0197  max mem: 650\n",
            "Epoch: [21]  [20/46]  eta: 0:00:02  lr: 0.0003  img/s: 1672.734759498246  loss: 0.0187 (0.0404)  acc1: 99.2188 (98.9955)  acc5: 100.0000 (100.0000)  time: 0.0980  data: 0.0199  max mem: 650\n",
            "Epoch: [21]  [30/46]  eta: 0:00:01  lr: 0.0003  img/s: 1630.7805996761956  loss: 0.0191 (0.0376)  acc1: 99.2188 (99.0423)  acc5: 100.0000 (100.0000)  time: 0.0965  data: 0.0204  max mem: 650\n",
            "Epoch: [21]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 1595.4985779708818  loss: 0.0191 (0.0349)  acc1: 99.2188 (99.1235)  acc5: 100.0000 (99.9809)  time: 0.0974  data: 0.0210  max mem: 650\n",
            "Epoch: [21] Total time: 0:00:04\n",
            "Test:   [   0/1459]  eta: 0:00:29  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0204  data: 0.0006  max mem: 650\n",
            "Test:   [ 100/1459]  eta: 0:00:27  loss: 0.0000 (0.0695)  acc1: 100.0000 (98.0198)  acc5: 100.0000 (100.0000)  time: 0.0205  data: 0.0003  max mem: 650\n",
            "Test:   [ 200/1459]  eta: 0:00:25  loss: 0.0000 (0.0760)  acc1: 100.0000 (97.5124)  acc5: 100.0000 (100.0000)  time: 0.0204  data: 0.0004  max mem: 650\n",
            "Test:   [ 300/1459]  eta: 0:00:23  loss: 0.0000 (0.1510)  acc1: 100.0000 (96.6777)  acc5: 100.0000 (100.0000)  time: 0.0207  data: 0.0004  max mem: 650\n",
            "Test:   [ 400/1459]  eta: 0:00:21  loss: 0.0000 (0.2146)  acc1: 100.0000 (96.2594)  acc5: 100.0000 (100.0000)  time: 0.0212  data: 0.0004  max mem: 650\n",
            "Test:   [ 500/1459]  eta: 0:00:19  loss: 0.0000 (0.1854)  acc1: 100.0000 (96.2076)  acc5: 100.0000 (100.0000)  time: 0.0211  data: 0.0004  max mem: 650\n",
            "Test:   [ 600/1459]  eta: 0:00:17  loss: 0.0000 (0.1865)  acc1: 100.0000 (96.5058)  acc5: 100.0000 (100.0000)  time: 0.0199  data: 0.0003  max mem: 650\n",
            "Test:   [ 700/1459]  eta: 0:00:15  loss: 0.0000 (0.1694)  acc1: 100.0000 (96.7190)  acc5: 100.0000 (100.0000)  time: 0.0203  data: 0.0004  max mem: 650\n",
            "Test:   [ 800/1459]  eta: 0:00:13  loss: 0.0000 (0.1843)  acc1: 100.0000 (96.3795)  acc5: 100.0000 (100.0000)  time: 0.0207  data: 0.0004  max mem: 650\n",
            "Test:   [ 900/1459]  eta: 0:00:11  loss: 0.0000 (0.1901)  acc1: 100.0000 (96.4484)  acc5: 100.0000 (99.8890)  time: 0.0209  data: 0.0004  max mem: 650\n",
            "Test:   [1000/1459]  eta: 0:00:09  loss: 0.0000 (0.1950)  acc1: 100.0000 (96.4036)  acc5: 100.0000 (99.9001)  time: 0.0203  data: 0.0003  max mem: 650\n",
            "Test:   [1100/1459]  eta: 0:00:07  loss: 0.0000 (0.1958)  acc1: 100.0000 (96.4578)  acc5: 100.0000 (99.9092)  time: 0.0213  data: 0.0004  max mem: 650\n",
            "Test:   [1200/1459]  eta: 0:00:05  loss: 0.0000 (0.2066)  acc1: 100.0000 (96.5029)  acc5: 100.0000 (99.8335)  time: 0.0203  data: 0.0004  max mem: 650\n",
            "Test:   [1300/1459]  eta: 0:00:03  loss: 0.0000 (0.2067)  acc1: 100.0000 (96.4643)  acc5: 100.0000 (99.8463)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [1400/1459]  eta: 0:00:01  loss: 0.0000 (0.1975)  acc1: 100.0000 (96.5739)  acc5: 100.0000 (99.8572)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:  Total time: 0:00:30\n",
            "Test:  Acc@1 96.642 Acc@5 99.863  Kappa 0.962 Loss 0.192\n",
            "Epoch: [22]  [ 0/46]  eta: 0:00:06  lr: 0.0003  img/s: 1067.9981300565557  loss: 0.0119 (0.0119)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1417  data: 0.0218  max mem: 650\n",
            "Epoch: [22]  [10/46]  eta: 0:00:03  lr: 0.0003  img/s: 1712.1737460972506  loss: 0.0185 (0.0217)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (99.9290)  time: 0.1042  data: 0.0204  max mem: 650\n",
            "Epoch: [22]  [20/46]  eta: 0:00:02  lr: 0.0003  img/s: 1734.5217675052743  loss: 0.0112 (0.0215)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (99.9628)  time: 0.0979  data: 0.0201  max mem: 650\n",
            "Epoch: [22]  [30/46]  eta: 0:00:01  lr: 0.0003  img/s: 1733.5528360252379  loss: 0.0112 (0.0295)  acc1: 99.2188 (99.1683)  acc5: 100.0000 (99.9748)  time: 0.0960  data: 0.0201  max mem: 650\n",
            "Epoch: [22]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 1727.8341910214695  loss: 0.0307 (0.0324)  acc1: 99.2188 (99.1616)  acc5: 100.0000 (99.9809)  time: 0.0960  data: 0.0202  max mem: 650\n",
            "Epoch: [22] Total time: 0:00:04\n",
            "Test:   [   0/1459]  eta: 0:00:31  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0216  data: 0.0006  max mem: 650\n",
            "Test:   [ 100/1459]  eta: 0:00:27  loss: 0.0000 (0.0561)  acc1: 100.0000 (99.0099)  acc5: 100.0000 (100.0000)  time: 0.0201  data: 0.0004  max mem: 650\n",
            "Test:   [ 200/1459]  eta: 0:00:25  loss: 0.0000 (0.0577)  acc1: 100.0000 (99.0050)  acc5: 100.0000 (100.0000)  time: 0.0200  data: 0.0003  max mem: 650\n",
            "Test:   [ 300/1459]  eta: 0:00:23  loss: 0.0000 (0.1759)  acc1: 100.0000 (98.3389)  acc5: 100.0000 (99.6678)  time: 0.0200  data: 0.0003  max mem: 650\n",
            "Test:   [ 400/1459]  eta: 0:00:21  loss: 0.0000 (0.2370)  acc1: 100.0000 (97.2569)  acc5: 100.0000 (99.7506)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [ 500/1459]  eta: 0:00:19  loss: 0.0000 (0.2125)  acc1: 100.0000 (97.2056)  acc5: 100.0000 (99.8004)  time: 0.0203  data: 0.0003  max mem: 650\n",
            "Test:   [ 600/1459]  eta: 0:00:17  loss: 0.0000 (0.2054)  acc1: 100.0000 (97.1714)  acc5: 100.0000 (99.8336)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [ 700/1459]  eta: 0:00:15  loss: 0.0000 (0.1845)  acc1: 100.0000 (97.2896)  acc5: 100.0000 (99.8573)  time: 0.0203  data: 0.0003  max mem: 650\n",
            "Test:   [ 800/1459]  eta: 0:00:13  loss: 0.0000 (0.2152)  acc1: 100.0000 (96.8789)  acc5: 100.0000 (99.8752)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [ 900/1459]  eta: 0:00:11  loss: 0.0000 (0.2083)  acc1: 100.0000 (97.1143)  acc5: 100.0000 (99.7780)  time: 0.0200  data: 0.0004  max mem: 650\n",
            "Test:   [1000/1459]  eta: 0:00:09  loss: 0.0000 (0.2023)  acc1: 100.0000 (97.1029)  acc5: 100.0000 (99.8002)  time: 0.0206  data: 0.0003  max mem: 650\n",
            "Test:   [1100/1459]  eta: 0:00:07  loss: 0.0000 (0.1961)  acc1: 100.0000 (97.1844)  acc5: 100.0000 (99.8183)  time: 0.0203  data: 0.0003  max mem: 650\n",
            "Test:   [1200/1459]  eta: 0:00:05  loss: 0.0000 (0.2075)  acc1: 100.0000 (97.0858)  acc5: 100.0000 (99.8335)  time: 0.0204  data: 0.0003  max mem: 650\n",
            "Test:   [1300/1459]  eta: 0:00:03  loss: 0.0000 (0.2112)  acc1: 100.0000 (97.0023)  acc5: 100.0000 (99.8463)  time: 0.0204  data: 0.0003  max mem: 650\n",
            "Test:   [1400/1459]  eta: 0:00:01  loss: 0.0000 (0.1990)  acc1: 100.0000 (97.0735)  acc5: 100.0000 (99.8572)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:  Total time: 0:00:29\n",
            "Test:  Acc@1 97.190 Acc@5 99.863  Kappa 0.968 Loss 0.192\n",
            "Epoch: [23]  [ 0/46]  eta: 0:00:06  lr: 0.0003  img/s: 1057.6278067365618  loss: 0.0068 (0.0068)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1431  data: 0.0221  max mem: 650\n",
            "Epoch: [23]  [10/46]  eta: 0:00:03  lr: 0.0003  img/s: 1735.0543005435873  loss: 0.0082 (0.0211)  acc1: 100.0000 (99.5028)  acc5: 100.0000 (100.0000)  time: 0.1041  data: 0.0204  max mem: 650\n",
            "Epoch: [23]  [20/46]  eta: 0:00:02  lr: 0.0003  img/s: 1694.3634257725093  loss: 0.0094 (0.0328)  acc1: 99.2188 (99.1071)  acc5: 100.0000 (100.0000)  time: 0.0983  data: 0.0206  max mem: 650\n",
            "Epoch: [23]  [30/46]  eta: 0:00:01  lr: 0.0003  img/s: 1708.9309515018017  loss: 0.0330 (0.0309)  acc1: 99.2188 (99.1683)  acc5: 100.0000 (100.0000)  time: 0.0958  data: 0.0205  max mem: 650\n",
            "Epoch: [23]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 1672.729547755916  loss: 0.0104 (0.0314)  acc1: 99.2188 (99.2569)  acc5: 100.0000 (100.0000)  time: 0.0948  data: 0.0199  max mem: 650\n",
            "Epoch: [23] Total time: 0:00:04\n",
            "Test:   [   0/1459]  eta: 0:00:31  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0217  data: 0.0006  max mem: 650\n",
            "Test:   [ 100/1459]  eta: 0:00:27  loss: 0.0000 (0.0865)  acc1: 100.0000 (99.0099)  acc5: 100.0000 (99.0099)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [ 200/1459]  eta: 0:00:25  loss: 0.0000 (0.0984)  acc1: 100.0000 (98.5075)  acc5: 100.0000 (99.5025)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [ 300/1459]  eta: 0:00:23  loss: 0.0000 (0.2143)  acc1: 100.0000 (97.6744)  acc5: 100.0000 (99.6678)  time: 0.0206  data: 0.0004  max mem: 650\n",
            "Test:   [ 400/1459]  eta: 0:00:21  loss: 0.0000 (0.2218)  acc1: 100.0000 (97.0075)  acc5: 100.0000 (99.7506)  time: 0.0204  data: 0.0004  max mem: 650\n",
            "Test:   [ 500/1459]  eta: 0:00:19  loss: 0.0000 (0.1802)  acc1: 100.0000 (97.6048)  acc5: 100.0000 (99.8004)  time: 0.0205  data: 0.0004  max mem: 650\n",
            "Test:   [ 600/1459]  eta: 0:00:17  loss: 0.0000 (0.1783)  acc1: 100.0000 (97.5042)  acc5: 100.0000 (99.8336)  time: 0.0200  data: 0.0003  max mem: 650\n",
            "Test:   [ 700/1459]  eta: 0:00:15  loss: 0.0000 (0.1549)  acc1: 100.0000 (97.7175)  acc5: 100.0000 (99.8573)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [ 800/1459]  eta: 0:00:13  loss: 0.0000 (0.1617)  acc1: 100.0000 (97.5031)  acc5: 100.0000 (99.8752)  time: 0.0203  data: 0.0003  max mem: 650\n",
            "Test:   [ 900/1459]  eta: 0:00:11  loss: 0.0000 (0.1909)  acc1: 100.0000 (97.1143)  acc5: 100.0000 (99.7780)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [1000/1459]  eta: 0:00:09  loss: 0.0000 (0.1947)  acc1: 100.0000 (97.1029)  acc5: 100.0000 (99.8002)  time: 0.0207  data: 0.0004  max mem: 650\n",
            "Test:   [1100/1459]  eta: 0:00:07  loss: 0.0000 (0.1909)  acc1: 100.0000 (97.1844)  acc5: 100.0000 (99.8183)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [1200/1459]  eta: 0:00:05  loss: 0.0000 (0.1979)  acc1: 100.0000 (97.0025)  acc5: 100.0000 (99.8335)  time: 0.0206  data: 0.0003  max mem: 650\n",
            "Test:   [1300/1459]  eta: 0:00:03  loss: 0.0000 (0.1999)  acc1: 100.0000 (97.0023)  acc5: 100.0000 (99.8463)  time: 0.0200  data: 0.0003  max mem: 650\n",
            "Test:   [1400/1459]  eta: 0:00:01  loss: 0.0000 (0.1880)  acc1: 100.0000 (97.1449)  acc5: 100.0000 (99.8572)  time: 0.0209  data: 0.0004  max mem: 650\n",
            "Test:  Total time: 0:00:29\n",
            "Test:  Acc@1 97.190 Acc@5 99.863  Kappa 0.968 Loss 0.181\n",
            "Epoch: [24]  [ 0/46]  eta: 0:00:05  lr: 0.0003  img/s: 1209.6809279604877  loss: 0.0086 (0.0086)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.1276  data: 0.0218  max mem: 650\n",
            "Epoch: [24]  [10/46]  eta: 0:00:03  lr: 0.0003  img/s: 1643.3700308244233  loss: 0.0086 (0.0445)  acc1: 100.0000 (99.0057)  acc5: 100.0000 (99.9290)  time: 0.1031  data: 0.0203  max mem: 650\n",
            "Epoch: [24]  [20/46]  eta: 0:00:02  lr: 0.0003  img/s: 1738.5153071467894  loss: 0.0043 (0.0362)  acc1: 99.2188 (99.0699)  acc5: 100.0000 (99.9628)  time: 0.0978  data: 0.0200  max mem: 650\n",
            "Epoch: [24]  [30/46]  eta: 0:00:01  lr: 0.0003  img/s: 1698.7865532604294  loss: 0.0153 (0.0329)  acc1: 99.2188 (99.1683)  acc5: 100.0000 (99.9748)  time: 0.0948  data: 0.0197  max mem: 650\n",
            "Epoch: [24]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 1673.0006014278458  loss: 0.0220 (0.0332)  acc1: 99.2188 (99.1806)  acc5: 100.0000 (99.9809)  time: 0.0947  data: 0.0198  max mem: 650\n",
            "Epoch: [24] Total time: 0:00:04\n",
            "Test:   [   0/1459]  eta: 0:00:31  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0219  data: 0.0007  max mem: 650\n",
            "Test:   [ 100/1459]  eta: 0:00:27  loss: 0.0000 (0.1521)  acc1: 100.0000 (97.0297)  acc5: 100.0000 (99.0099)  time: 0.0199  data: 0.0003  max mem: 650\n",
            "Test:   [ 200/1459]  eta: 0:00:25  loss: 0.0000 (0.1008)  acc1: 100.0000 (97.5124)  acc5: 100.0000 (99.5025)  time: 0.0200  data: 0.0003  max mem: 650\n",
            "Test:   [ 300/1459]  eta: 0:00:23  loss: 0.0000 (0.1819)  acc1: 100.0000 (96.6777)  acc5: 100.0000 (99.6678)  time: 0.0210  data: 0.0004  max mem: 650\n",
            "Test:   [ 400/1459]  eta: 0:00:21  loss: 0.0000 (0.2585)  acc1: 100.0000 (95.7606)  acc5: 100.0000 (99.7506)  time: 0.0204  data: 0.0003  max mem: 650\n",
            "Test:   [ 500/1459]  eta: 0:00:19  loss: 0.0000 (0.2257)  acc1: 100.0000 (96.4072)  acc5: 100.0000 (99.6008)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [ 600/1459]  eta: 0:00:17  loss: 0.0000 (0.2254)  acc1: 100.0000 (96.5058)  acc5: 100.0000 (99.6672)  time: 0.0203  data: 0.0003  max mem: 650\n",
            "Test:   [ 700/1459]  eta: 0:00:15  loss: 0.0000 (0.2022)  acc1: 100.0000 (96.7190)  acc5: 100.0000 (99.7147)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [ 800/1459]  eta: 0:00:13  loss: 0.0000 (0.2198)  acc1: 100.0000 (96.6292)  acc5: 100.0000 (99.7503)  time: 0.0207  data: 0.0004  max mem: 650\n",
            "Test:   [ 900/1459]  eta: 0:00:11  loss: 0.0000 (0.2150)  acc1: 100.0000 (96.6704)  acc5: 100.0000 (99.6670)  time: 0.0208  data: 0.0004  max mem: 650\n",
            "Test:   [1000/1459]  eta: 0:00:09  loss: 0.0000 (0.2170)  acc1: 100.0000 (96.8032)  acc5: 100.0000 (99.7003)  time: 0.0199  data: 0.0003  max mem: 650\n",
            "Test:   [1100/1459]  eta: 0:00:07  loss: 0.0000 (0.2175)  acc1: 100.0000 (96.7302)  acc5: 100.0000 (99.7275)  time: 0.0200  data: 0.0003  max mem: 650\n",
            "Test:   [1200/1459]  eta: 0:00:05  loss: 0.0000 (0.2316)  acc1: 100.0000 (96.6694)  acc5: 100.0000 (99.7502)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [1300/1459]  eta: 0:00:03  loss: 0.0000 (0.2370)  acc1: 100.0000 (96.5411)  acc5: 100.0000 (99.7694)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [1400/1459]  eta: 0:00:01  loss: 0.0000 (0.2328)  acc1: 100.0000 (96.5739)  acc5: 100.0000 (99.7859)  time: 0.0203  data: 0.0003  max mem: 650\n",
            "Test:  Total time: 0:00:29\n",
            "Test:  Acc@1 96.710 Acc@5 99.794  Kappa 0.963 Loss 0.224\n",
            "Epoch: [25]  [ 0/46]  eta: 0:00:06  lr: 0.0003  img/s: 1067.787839009682  loss: 0.0630 (0.0630)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1494  data: 0.0295  max mem: 650\n",
            "Epoch: [25]  [10/46]  eta: 0:00:03  lr: 0.0003  img/s: 1705.0882666802174  loss: 0.0164 (0.0293)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.1064  data: 0.0211  max mem: 650\n",
            "Epoch: [25]  [20/46]  eta: 0:00:02  lr: 0.0003  img/s: 1722.5896780196686  loss: 0.0164 (0.0244)  acc1: 99.2188 (99.2560)  acc5: 100.0000 (100.0000)  time: 0.0993  data: 0.0204  max mem: 650\n",
            "Epoch: [25]  [30/46]  eta: 0:00:01  lr: 0.0003  img/s: 1741.2387238224353  loss: 0.0158 (0.0241)  acc1: 99.2188 (99.2692)  acc5: 100.0000 (100.0000)  time: 0.0959  data: 0.0204  max mem: 650\n",
            "Epoch: [25]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 1745.5413357089674  loss: 0.0155 (0.0302)  acc1: 99.2188 (99.1806)  acc5: 100.0000 (100.0000)  time: 0.0945  data: 0.0197  max mem: 650\n",
            "Epoch: [25] Total time: 0:00:04\n",
            "Test:   [   0/1459]  eta: 0:00:30  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0208  data: 0.0005  max mem: 650\n",
            "Test:   [ 100/1459]  eta: 0:00:27  loss: 0.0000 (0.0520)  acc1: 100.0000 (98.0198)  acc5: 100.0000 (100.0000)  time: 0.0203  data: 0.0003  max mem: 650\n",
            "Test:   [ 200/1459]  eta: 0:00:25  loss: 0.0000 (0.0808)  acc1: 100.0000 (97.5124)  acc5: 100.0000 (100.0000)  time: 0.0203  data: 0.0003  max mem: 650\n",
            "Test:   [ 300/1459]  eta: 0:00:23  loss: 0.0000 (0.1750)  acc1: 100.0000 (97.0100)  acc5: 100.0000 (100.0000)  time: 0.0209  data: 0.0004  max mem: 650\n",
            "Test:   [ 400/1459]  eta: 0:00:21  loss: 0.0000 (0.2173)  acc1: 100.0000 (97.0075)  acc5: 100.0000 (99.7506)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [ 500/1459]  eta: 0:00:19  loss: 0.0000 (0.1982)  acc1: 100.0000 (97.4052)  acc5: 100.0000 (99.6008)  time: 0.0202  data: 0.0004  max mem: 650\n",
            "Test:   [ 600/1459]  eta: 0:00:17  loss: 0.0000 (0.1802)  acc1: 100.0000 (97.6705)  acc5: 100.0000 (99.6672)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [ 700/1459]  eta: 0:00:15  loss: 0.0000 (0.1549)  acc1: 100.0000 (98.0029)  acc5: 100.0000 (99.7147)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [ 800/1459]  eta: 0:00:13  loss: 0.0000 (0.1771)  acc1: 100.0000 (97.7528)  acc5: 100.0000 (99.7503)  time: 0.0210  data: 0.0004  max mem: 650\n",
            "Test:   [ 900/1459]  eta: 0:00:11  loss: 0.0000 (0.1817)  acc1: 100.0000 (97.5583)  acc5: 100.0000 (99.6670)  time: 0.0209  data: 0.0004  max mem: 650\n",
            "Test:   [1000/1459]  eta: 0:00:09  loss: 0.0000 (0.1696)  acc1: 100.0000 (97.6024)  acc5: 100.0000 (99.7003)  time: 0.0202  data: 0.0004  max mem: 650\n",
            "Test:   [1100/1459]  eta: 0:00:07  loss: 0.0000 (0.1771)  acc1: 100.0000 (97.5477)  acc5: 100.0000 (99.7275)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [1200/1459]  eta: 0:00:05  loss: 0.0000 (0.1781)  acc1: 100.0000 (97.5021)  acc5: 100.0000 (99.7502)  time: 0.0200  data: 0.0003  max mem: 650\n",
            "Test:   [1300/1459]  eta: 0:00:03  loss: 0.0000 (0.1797)  acc1: 100.0000 (97.3866)  acc5: 100.0000 (99.7694)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [1400/1459]  eta: 0:00:01  loss: 0.0000 (0.1768)  acc1: 100.0000 (97.4304)  acc5: 100.0000 (99.7859)  time: 0.0206  data: 0.0004  max mem: 650\n",
            "Test:  Total time: 0:00:29\n",
            "Test:  Acc@1 97.464 Acc@5 99.794  Kappa 0.972 Loss 0.174\n",
            "Early stopping triggered\n",
            "Training time 0:15:11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "best_kappa = 0.0\n",
        "epochs_without_improvement = 0\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(0, MAX_EPOCHS):\n",
        "  train_metric_logger = train_one_epoch(model, criterion, optimizer, training_loader, device, epoch)\n",
        "  val_metric_logger = evaluate(model, criterion, val_loader, device=device)\n",
        "\n",
        "  checkpoint = {\"model\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
        "\n",
        "  train_loss = train_metric_logger.meters[\"loss\"].global_avg\n",
        "  train_losses.append(train_loss)\n",
        "\n",
        "  val_loss = val_metric_logger.meters[\"loss\"].global_avg\n",
        "  val_losses.append(val_loss)\n",
        "\n",
        "  kappa = val_metric_logger.meters[\"Kappa\"]\n",
        "\n",
        "  plot_losses(train_losses, val_losses, \"train_val_loss_graph.png\")\n",
        "\n",
        "\n",
        "  torch.save(checkpoint, \"checkpoint.pth\")\n",
        "\n",
        "  if kappa > best_kappa:\n",
        "      torch.save(checkpoint, \"best_model.pth\")\n",
        "      epochs_without_improvement = 0\n",
        "      best_kappa = kappa\n",
        "  else:\n",
        "      epochs_without_improvement += 1\n",
        "\n",
        "  if epochs_without_improvement >= PATIENCE:\n",
        "      print(\"Early stopping triggered\")\n",
        "      break\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "print(f\"Training time {total_time_str}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tMkC-whdeyrU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYbnLvvtbfdK"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nVN9hnG6gER"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4iMYPmBma9dy"
      },
      "outputs": [],
      "source": [
        "CLASSES = [\n",
        "    \"0\",\n",
        "    \"1\",\n",
        "    \"2\",\n",
        "    \"3\",\n",
        "    \"4\",\n",
        "    \"5\",\n",
        "    \"6\",\n",
        "    \"7\",\n",
        "    \"8\",\n",
        "    \"9\"\n",
        "]\n",
        "\n",
        "\n",
        "def test(model, data_loader, device, print_freq=100, log_suffix=\"\"):\n",
        "    model.eval()\n",
        "    metric_logger = MetricLogger(delimiter=\"  \")\n",
        "    header = f\"Test: {log_suffix}\"\n",
        "\n",
        "    num_processed_samples = 0\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "    with torch.inference_mode():\n",
        "        for image, target in metric_logger.log_every(data_loader, print_freq, header):\n",
        "            image = image.to(device, non_blocking=True)\n",
        "            target = target.to(device, non_blocking=True)\n",
        "            output = model(image)\n",
        "            loss = criterion(output, target)\n",
        "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "\n",
        "            batch_size = image.shape[0]\n",
        "            metric_logger.update(loss=loss.item())\n",
        "            metric_logger.meters[\"acc1\"].update(acc1.item(), n=batch_size)\n",
        "            metric_logger.meters[\"acc5\"].update(acc5.item(), n=batch_size)\n",
        "            num_processed_samples += batch_size\n",
        "            _, predictions = output.max(1)\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_targets.extend(target.cpu().numpy())\n",
        "\n",
        "    metric_logger.synchronize_between_processes()\n",
        "\n",
        "    print(f\"{header} Acc@1 {metric_logger.acc1.global_avg:.3f} Acc@5 {metric_logger.acc5.global_avg:.3f} Loss {metric_logger.loss.global_avg:.3f}\") # Test Loss u print etme kısmı buraya eklendi\n",
        "\n",
        "\n",
        "    conf_matrix = confusion_matrix(all_targets, all_predictions)\n",
        "    kappa_score = cohen_kappa_score(all_targets, all_predictions)\n",
        "    print(\"Kappa score: \", kappa_score)\n",
        "\n",
        "\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=CLASSES)\n",
        "    disp.plot()\n",
        "    plt.savefig(os.path.join(\"confusion_matrix.png\"))\n",
        "    plt.clf()\n",
        "    return metric_logger.acc1.global_avg\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "LcqRfaEjTUH9",
        "outputId": "1554e511-83d8-41d3-dbd1-dd1c61a1af99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start validating\n",
            "Test:   [   0/1459]  eta: 0:00:32  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0224  data: 0.0010  max mem: 650\n",
            "Test:   [ 100/1459]  eta: 0:00:27  loss: 0.0000 (0.0547)  acc1: 100.0000 (99.0099)  acc5: 100.0000 (100.0000)  time: 0.0204  data: 0.0004  max mem: 650\n",
            "Test:   [ 200/1459]  eta: 0:00:25  loss: 0.0000 (0.0665)  acc1: 100.0000 (99.0050)  acc5: 100.0000 (100.0000)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [ 300/1459]  eta: 0:00:23  loss: 0.0000 (0.1460)  acc1: 100.0000 (98.3389)  acc5: 100.0000 (100.0000)  time: 0.0203  data: 0.0003  max mem: 650\n",
            "Test:   [ 400/1459]  eta: 0:00:21  loss: 0.0000 (0.1533)  acc1: 100.0000 (98.0050)  acc5: 100.0000 (100.0000)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [ 500/1459]  eta: 0:00:19  loss: 0.0000 (0.1261)  acc1: 100.0000 (98.2036)  acc5: 100.0000 (100.0000)  time: 0.0213  data: 0.0004  max mem: 650\n",
            "Test:   [ 600/1459]  eta: 0:00:17  loss: 0.0000 (0.1292)  acc1: 100.0000 (98.1697)  acc5: 100.0000 (100.0000)  time: 0.0205  data: 0.0004  max mem: 650\n",
            "Test:   [ 700/1459]  eta: 0:00:15  loss: 0.0000 (0.1274)  acc1: 100.0000 (98.1455)  acc5: 100.0000 (100.0000)  time: 0.0198  data: 0.0003  max mem: 650\n",
            "Test:   [ 800/1459]  eta: 0:00:13  loss: 0.0000 (0.1152)  acc1: 100.0000 (98.2522)  acc5: 100.0000 (100.0000)  time: 0.0200  data: 0.0003  max mem: 650\n",
            "Test:   [ 900/1459]  eta: 0:00:11  loss: 0.0000 (0.1329)  acc1: 100.0000 (98.2242)  acc5: 100.0000 (99.8890)  time: 0.0205  data: 0.0003  max mem: 650\n",
            "Test:   [1000/1459]  eta: 0:00:09  loss: 0.0000 (0.1256)  acc1: 100.0000 (98.2018)  acc5: 100.0000 (99.9001)  time: 0.0207  data: 0.0004  max mem: 650\n",
            "Test:   [1100/1459]  eta: 0:00:07  loss: 0.0000 (0.1289)  acc1: 100.0000 (98.0926)  acc5: 100.0000 (99.9092)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [1200/1459]  eta: 0:00:05  loss: 0.0000 (0.1384)  acc1: 100.0000 (98.0849)  acc5: 100.0000 (99.9167)  time: 0.0199  data: 0.0003  max mem: 650\n",
            "Test:   [1300/1459]  eta: 0:00:03  loss: 0.0000 (0.1380)  acc1: 100.0000 (98.1553)  acc5: 100.0000 (99.9231)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [1400/1459]  eta: 0:00:01  loss: 0.0000 (0.1362)  acc1: 100.0000 (98.2156)  acc5: 100.0000 (99.9286)  time: 0.0200  data: 0.0003  max mem: 650\n",
            "Test:  Total time: 0:00:29\n",
            "Test:  Acc@1 98.218 Acc@5 99.931 Loss 0.135\n",
            "Kappa score:  0.9800103705358743\n",
            "Validating time 0:00:29\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Validation results\n",
        "\n",
        "checkpoint = torch.load(\"best_model.pth\", map_location=\"cpu\")\n",
        "model.load_state_dict(checkpoint[\"model\"])\n",
        "\n",
        "print(\"Start validating\")\n",
        "start_time = time.time()\n",
        "test(model, val_loader, device=device)\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "print(f\"Validating time {total_time_str}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVHtrVgOggyn"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "zKADmqDOi3i2",
        "outputId": "b36b2cb6-39e8-4e87-d39b-1b0a6e16299d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start testing\n",
            "Test:   [   0/2007]  eta: 0:00:46  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0231  data: 0.0010  max mem: 650\n",
            "Test:   [ 100/2007]  eta: 0:00:38  loss: 0.0000 (0.1035)  acc1: 100.0000 (95.0495)  acc5: 100.0000 (100.0000)  time: 0.0205  data: 0.0003  max mem: 650\n",
            "Test:   [ 200/2007]  eta: 0:00:37  loss: 0.0000 (0.3076)  acc1: 100.0000 (92.5373)  acc5: 100.0000 (99.5025)  time: 0.0212  data: 0.0004  max mem: 650\n",
            "Test:   [ 300/2007]  eta: 0:00:34  loss: 0.0000 (0.3509)  acc1: 100.0000 (93.3555)  acc5: 100.0000 (99.3355)  time: 0.0201  data: 0.0003  max mem: 650\n",
            "Test:   [ 400/2007]  eta: 0:00:32  loss: 0.0000 (0.2969)  acc1: 100.0000 (94.5137)  acc5: 100.0000 (99.5012)  time: 0.0205  data: 0.0003  max mem: 650\n",
            "Test:   [ 500/2007]  eta: 0:00:30  loss: 0.0000 (0.3157)  acc1: 100.0000 (94.4112)  acc5: 100.0000 (99.4012)  time: 0.0205  data: 0.0003  max mem: 650\n",
            "Test:   [ 600/2007]  eta: 0:00:28  loss: 0.0000 (0.3630)  acc1: 100.0000 (94.1764)  acc5: 100.0000 (99.5008)  time: 0.0207  data: 0.0004  max mem: 650\n",
            "Test:   [ 700/2007]  eta: 0:00:26  loss: 0.0000 (0.3180)  acc1: 100.0000 (94.5792)  acc5: 100.0000 (99.5720)  time: 0.0205  data: 0.0003  max mem: 650\n",
            "Test:   [ 800/2007]  eta: 0:00:24  loss: 0.0000 (0.2971)  acc1: 100.0000 (94.5069)  acc5: 100.0000 (99.6255)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [ 900/2007]  eta: 0:00:22  loss: 0.0000 (0.2920)  acc1: 100.0000 (94.5616)  acc5: 100.0000 (99.6670)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [1000/2007]  eta: 0:00:20  loss: 0.0000 (0.3195)  acc1: 100.0000 (94.4056)  acc5: 100.0000 (99.6004)  time: 0.0206  data: 0.0003  max mem: 650\n",
            "Test:   [1100/2007]  eta: 0:00:18  loss: 0.0004 (0.3350)  acc1: 100.0000 (94.0963)  acc5: 100.0000 (99.6367)  time: 0.0205  data: 0.0004  max mem: 650\n",
            "Test:   [1200/2007]  eta: 0:00:16  loss: 0.0000 (0.3191)  acc1: 100.0000 (94.3381)  acc5: 100.0000 (99.6669)  time: 0.0214  data: 0.0004  max mem: 650\n",
            "Test:   [1300/2007]  eta: 0:00:14  loss: 0.0000 (0.2979)  acc1: 100.0000 (94.6964)  acc5: 100.0000 (99.6925)  time: 0.0203  data: 0.0004  max mem: 650\n",
            "Test:   [1400/2007]  eta: 0:00:12  loss: 0.0000 (0.3319)  acc1: 100.0000 (94.2184)  acc5: 100.0000 (99.7145)  time: 0.0203  data: 0.0003  max mem: 650\n",
            "Test:   [1500/2007]  eta: 0:00:10  loss: 0.0000 (0.3294)  acc1: 100.0000 (94.3371)  acc5: 100.0000 (99.6669)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [1600/2007]  eta: 0:00:08  loss: 0.0000 (0.3348)  acc1: 100.0000 (94.4410)  acc5: 100.0000 (99.6252)  time: 0.0205  data: 0.0003  max mem: 650\n",
            "Test:   [1700/2007]  eta: 0:00:06  loss: 0.0000 (0.3236)  acc1: 100.0000 (94.5326)  acc5: 100.0000 (99.6473)  time: 0.0207  data: 0.0005  max mem: 650\n",
            "Test:   [1800/2007]  eta: 0:00:04  loss: 0.0000 (0.3153)  acc1: 100.0000 (94.6141)  acc5: 100.0000 (99.6669)  time: 0.0204  data: 0.0004  max mem: 650\n",
            "Test:   [1900/2007]  eta: 0:00:02  loss: 0.0001 (0.3584)  acc1: 100.0000 (94.3188)  acc5: 100.0000 (99.5792)  time: 0.0202  data: 0.0003  max mem: 650\n",
            "Test:   [2000/2007]  eta: 0:00:00  loss: 0.0000 (0.3620)  acc1: 100.0000 (94.3028)  acc5: 100.0000 (99.5502)  time: 0.0211  data: 0.0005  max mem: 650\n",
            "Test:  Total time: 0:00:41\n",
            "Test:  Acc@1 94.320 Acc@5 99.552 Loss 0.361\n",
            "Kappa score:  0.9362225762346182\n",
            "Testing time 0:00:41\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Test results\n",
        "\n",
        "checkpoint = torch.load(\"best_model.pth\", map_location=\"cpu\")\n",
        "model.load_state_dict(checkpoint[\"model\"])\n",
        "\n",
        "print(\"Start testing\")\n",
        "start_time = time.time()\n",
        "test(model, test_loader, device=device)\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "print(f\"Testing time {total_time_str}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu4bIxSSdSBm"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "4Nai1iGCmkAF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}