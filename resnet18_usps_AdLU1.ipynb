{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fvjp6TVbv_I-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "from collections import defaultdict, deque\n",
        "from sklearn.metrics import cohen_kappa_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import USPS,FashionMNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Y2YtKH5FxHXX"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "SEED = 45\n",
        "NUM_CLASSES = 10\n",
        "EPOCHS =5\n",
        "MAX_EPOCHS = 100\n",
        "PATIENCE = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AriStxaOzr1J",
        "outputId": "b9d8d8a5-3ca1-44df-94cb-dbac1b8bf063"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed set as 45\n"
          ]
        }
      ],
      "source": [
        "def set_seed(seed =45) -> None:\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.use_deterministic_algorithms(True)\n",
        "\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    print(f\"Random seed set as {seed}\")\n",
        "\n",
        "set_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YCrcUcnz4Jeh"
      },
      "outputs": [],
      "source": [
        "def reduce_across_processes(val):\n",
        "    return torch.tensor(val)\n",
        "\n",
        "class SmoothedValue:\n",
        "    \"\"\"Track a series of values and provide access to smoothed values over a\n",
        "    window or the global series average.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, window_size=20, fmt=None):\n",
        "        if fmt is None:\n",
        "            fmt = \"{median:.4f} ({global_avg:.4f})\"\n",
        "        self.deque = deque(maxlen=window_size)\n",
        "        self.total = 0.0\n",
        "        self.count = 0\n",
        "        self.fmt = fmt\n",
        "\n",
        "    def update(self, value, n=1):\n",
        "        self.deque.append(value)\n",
        "        self.count += n\n",
        "        self.total += value * n\n",
        "\n",
        "    def synchronize_between_processes(self):\n",
        "        \"\"\"\n",
        "        Warning: does not synchronize the deque!\n",
        "        \"\"\"\n",
        "        t = reduce_across_processes([self.count, self.total])\n",
        "        t = t.tolist()\n",
        "        self.count = int(t[0])\n",
        "        self.total = t[1]\n",
        "\n",
        "    @property\n",
        "    def median(self):\n",
        "        d = torch.tensor(list(self.deque))\n",
        "        return d.median().item()\n",
        "\n",
        "    @property\n",
        "    def avg(self):\n",
        "        d = torch.tensor(list(self.deque), dtype=torch.float32)\n",
        "        return d.mean().item()\n",
        "\n",
        "    @property\n",
        "    def global_avg(self):\n",
        "        return self.total / self.count\n",
        "\n",
        "    @property\n",
        "    def max(self):\n",
        "        return max(self.deque)\n",
        "\n",
        "    @property\n",
        "    def value(self):\n",
        "        return self.deque[-1]\n",
        "\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.fmt.format(\n",
        "            median=self.median, avg=self.avg, global_avg=self.global_avg, max=self.max, value=self.value\n",
        "        )\n",
        "\n",
        "class MetricLogger:\n",
        "    def __init__(self, delimiter=\"\\t\"):\n",
        "        self.meters = defaultdict(SmoothedValue)\n",
        "        self.delimiter = delimiter\n",
        "\n",
        "    def update(self, **kwargs):\n",
        "        for k, v in kwargs.items():\n",
        "            if isinstance(v, torch.Tensor):\n",
        "                v = v.item()\n",
        "            assert isinstance(v, (float, int))\n",
        "            self.meters[k].update(v)\n",
        "\n",
        "    def __getattr__(self, attr):\n",
        "        if attr in self.meters:\n",
        "            return self.meters[attr]\n",
        "        if attr in self.__dict__:\n",
        "            return self.__dict__[attr]\n",
        "        raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{attr}'\")\n",
        "\n",
        "    def __str__(self):\n",
        "        loss_str = []\n",
        "        for name, meter in self.meters.items():\n",
        "            loss_str.append(f\"{name}: {str(meter)}\")\n",
        "        return self.delimiter.join(loss_str)\n",
        "\n",
        "    def synchronize_between_processes(self):\n",
        "        for meter in self.meters.values():\n",
        "            meter.synchronize_between_processes()\n",
        "\n",
        "    def add_meter(self, name, meter):\n",
        "        self.meters[name] = meter\n",
        "\n",
        "    def log_every(self, iterable, print_freq, header=None):\n",
        "        i = 0\n",
        "        if not header:\n",
        "            header = \"\"\n",
        "        start_time = time.time()\n",
        "        end = time.time()\n",
        "        iter_time = SmoothedValue(fmt=\"{avg:.4f}\")\n",
        "        data_time = SmoothedValue(fmt=\"{avg:.4f}\")\n",
        "        space_fmt = \":\" + str(len(str(len(iterable)))) + \"d\"\n",
        "        if torch.cuda.is_available():\n",
        "            log_msg = self.delimiter.join(\n",
        "                [\n",
        "                    header,\n",
        "                    \"[{0\" + space_fmt + \"}/{1}]\",\n",
        "                    \"eta: {eta}\",\n",
        "                    \"{meters}\",\n",
        "                    \"time: {time}\",\n",
        "                    \"data: {data}\",\n",
        "                    \"max mem: {memory:.0f}\",\n",
        "                ]\n",
        "            )\n",
        "        else:\n",
        "            log_msg = self.delimiter.join(\n",
        "                [header, \"[{0\" + space_fmt + \"}/{1}]\", \"eta: {eta}\", \"{meters}\", \"time: {time}\", \"data: {data}\"]\n",
        "            )\n",
        "        MB = 1024.0 * 1024.0\n",
        "        for obj in iterable:\n",
        "            data_time.update(time.time() - end)\n",
        "            yield obj\n",
        "            iter_time.update(time.time() - end)\n",
        "            if i % print_freq == 0:\n",
        "                eta_seconds = iter_time.global_avg * (len(iterable) - i)\n",
        "                eta_string = str(datetime.timedelta(seconds=int(eta_seconds)))\n",
        "                if torch.cuda.is_available():\n",
        "                    print(\n",
        "                        log_msg.format(\n",
        "                            i,\n",
        "                            len(iterable),\n",
        "                            eta=eta_string,\n",
        "                            meters=str(self),\n",
        "                            time=str(iter_time),\n",
        "                            data=str(data_time),\n",
        "                            memory=torch.cuda.max_memory_allocated() / MB,\n",
        "                        )\n",
        "                    )\n",
        "                else:\n",
        "                    print(\n",
        "                        log_msg.format(\n",
        "                            i, len(iterable), eta=eta_string, meters=str(self), time=str(iter_time), data=str(data_time)\n",
        "                        )\n",
        "                    )\n",
        "            i += 1\n",
        "            end = time.time()\n",
        "        total_time = time.time() - start_time\n",
        "        total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "        print(f\"{header} Total time: {total_time_str}\")\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.inference_mode():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "        if target.ndim == 2:\n",
        "            target = target.max(dim=1)[1]\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target[None])\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].flatten().sum(dtype=torch.float32)\n",
        "            res.append(correct_k * (100.0 / batch_size))\n",
        "        return res\n",
        "def plot_losses(train_losses, val_losses, save_path):\n",
        "  epochs = range(1, len(train_losses) + 1)\n",
        "  plt.plot(epochs, train_losses, 'b', label='Training loss')\n",
        "  plt.plot(epochs, val_losses, 'r', label='Validation loss')\n",
        "  plt.title('Training and Validation Losses')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.savefig(save_path)\n",
        "  plt.clf()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "x8di24PNZlnD"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, criterion, optimizer, data_loader, device, epoch):\n",
        "    model.train()\n",
        "    metric_logger = MetricLogger(delimiter=\"  \")\n",
        "    metric_logger.add_meter(\"lr\", SmoothedValue(window_size=1, fmt=\"{value}\"))\n",
        "    metric_logger.add_meter(\"img/s\", SmoothedValue(window_size=10, fmt=\"{value}\"))\n",
        "\n",
        "    header = f\"Epoch: [{epoch}]\"\n",
        "    for i, (image, target) in enumerate(metric_logger.log_every(data_loader, 10, header)):\n",
        "        start_time = time.time()\n",
        "        image, target = image.to(device), target.to(device)\n",
        "        output = model(image)\n",
        "        loss = criterion(output, target)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        batch_size = image.shape[0]\n",
        "        metric_logger.update(loss=loss.item(), lr=optimizer.param_groups[0][\"lr\"])\n",
        "        metric_logger.meters[\"acc1\"].update(acc1.item(), n=batch_size)\n",
        "        metric_logger.meters[\"acc5\"].update(acc5.item(), n=batch_size)\n",
        "        metric_logger.meters[\"img/s\"].update(batch_size / (time.time() - start_time))\n",
        "\n",
        "\n",
        "    return metric_logger\n",
        "\n",
        "def evaluate(model, criterion, data_loader, device, print_freq=100, log_suffix=\"\"):\n",
        "    model.eval()\n",
        "    metric_logger = MetricLogger(delimiter=\"  \")\n",
        "    header = f\"Test: {log_suffix}\"\n",
        "\n",
        "    num_processed_samples = 0\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "    with torch.inference_mode():\n",
        "        for image, target in metric_logger.log_every(data_loader, print_freq, header):\n",
        "            image = image.to(device, non_blocking=True)\n",
        "            target = target.to(device, non_blocking=True)\n",
        "            output = model(image)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "            batch_size = image.shape[0]\n",
        "            metric_logger.update(loss=loss.item())\n",
        "            metric_logger.meters[\"acc1\"].update(acc1.item(), n=batch_size)\n",
        "            metric_logger.meters[\"acc5\"].update(acc5.item(), n=batch_size)\n",
        "            num_processed_samples += batch_size\n",
        "            _, predictions = output.max(1)\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_targets.extend(target.cpu().numpy())\n",
        "\n",
        "    kappa_score = cohen_kappa_score(all_targets, all_predictions)\n",
        "    metric_logger.meters[\"Kappa\"] = kappa_score\n",
        "    print(f\"{header} Acc@1 {metric_logger.acc1.global_avg:.3f} Acc@5 {metric_logger.acc5.global_avg:.3f}  Kappa {kappa_score:.3f} Loss {metric_logger.loss.global_avg:.3f}\") # Validation Loss u print etme kısmı buraya eklendi\n",
        "    return metric_logger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2Q3B0BboyZ0",
        "outputId": "3652fff7-6b46-49cf-e25f-77db9cad22fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.58M/6.58M [00:00<00:00, 62.9MB/s]\n",
            "100%|██████████| 1.83M/1.83M [00:00<00:00, 25.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "\n",
        "# usps dataset\n",
        "train_set = USPS('./data', train=True, transform=transform, download=True)\n",
        "split_ratio = 0.8\n",
        "train_size = int(split_ratio * len(train_set))\n",
        "val_size = len(train_set) - train_size\n",
        "\n",
        "train_set, val_set = random_split(train_set, [train_size, val_size])\n",
        "test_set = USPS('./data', train=False, transform=transform, download=True)\n",
        "\n",
        "training_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=1, shuffle=False)\n",
        "test_loader = DataLoader(test_set, batch_size=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PhBRX6sblDED"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lhYpiTc-TzYX"
      },
      "outputs": [],
      "source": [
        "class MyActivationFunction(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyActivationFunction, self).__init__()\n",
        "\n",
        "        self.new_weights = nn.Parameter(torch.randn(3, 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "      return torch.where(\n",
        "            0 <=x,\n",
        "            x,\n",
        "            1.5*(-1+torch.exp(0.6*x))\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Varsayılan başlık metni\n"
      ],
      "metadata": {
        "id": "WMeqWjRsYsSY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LoN01scUtiuK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "y-S6ILpDLmIT"
      },
      "outputs": [],
      "source": [
        "class EmptyActivationFunction(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(EmptyActivationFunction, self).__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nKmQXO7vGGJA"
      },
      "outputs": [],
      "source": [
        "from typing import Callable, Optional\n",
        "from torchvision.models.resnet import conv1x1, conv3x3, ResNet\n",
        "from torch import Tensor\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion: int = 1\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        inplanes: int,\n",
        "        planes: int,\n",
        "        stride: int = 1,\n",
        "        downsample: Optional[nn.Module] = None,\n",
        "        groups: int = 1,\n",
        "        base_width: int = 64,\n",
        "        dilation: int = 1,\n",
        "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError(\"BasicBlock only supports groups=1 and base_width=64\")\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = MyActivationFunction()\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.relu2 = MyActivationFunction()\n",
        "\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu2(out)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gLTfeiLSwMSu"
      },
      "outputs": [],
      "source": [
        "class NResNet(nn.Module):\n",
        "  def __init__(self, num_classes=10, in_channels=1):\n",
        "    super(NResNet, self).__init__()\n",
        "\n",
        "    self.model = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n",
        "\n",
        "    self.model.relu=MyActivationFunction()\n",
        "\n",
        "\n",
        "    self.model.conv1 = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zp4mGhCdUn-k",
        "outputId": "b7d2b4a7-d36d-4965-9cef-0348275c6c83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NResNet(\n",
            "  (model): ResNet(\n",
            "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): MyActivationFunction()\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): MyActivationFunction()\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): MyActivationFunction()\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): MyActivationFunction()\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): MyActivationFunction()\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): MyActivationFunction()\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (relu2): MyActivationFunction()\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): MyActivationFunction()\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): MyActivationFunction()\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): MyActivationFunction()\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (relu2): MyActivationFunction()\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): MyActivationFunction()\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): MyActivationFunction()\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): MyActivationFunction()\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (relu2): MyActivationFunction()\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): MyActivationFunction()\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): MyActivationFunction()\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model=NResNet(in_channels=1)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CS7Lg-hmYuCe",
        "outputId": "a8a07add-c531-43fa-e40e-c15db53c961c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0]  [ 0/46]  eta: 0:00:59  lr: 0.0003  img/s: 101.04816319155584  loss: 2.5703 (2.5703)  acc1: 9.3750 (9.3750)  acc5: 44.5312 (44.5312)  time: 1.2954  data: 0.0287  max mem: 280\n",
            "Epoch: [0]  [10/46]  eta: 0:00:06  lr: 0.0003  img/s: 4732.475159550087  loss: 0.2895 (0.5902)  acc1: 90.6250 (80.9659)  acc5: 100.0000 (94.1761)  time: 0.1696  data: 0.0219  max mem: 282\n",
            "Epoch: [0]  [20/46]  eta: 0:00:02  lr: 0.0003  img/s: 5218.165058074549  loss: 0.2685 (0.4099)  acc1: 91.4062 (87.0536)  acc5: 99.2188 (96.6890)  time: 0.0513  data: 0.0208  max mem: 282\n",
            "Epoch: [0]  [30/46]  eta: 0:00:01  lr: 0.0003  img/s: 5337.856310525164  loss: 0.1621 (0.3271)  acc1: 94.5312 (89.7681)  acc5: 99.2188 (97.6562)  time: 0.0452  data: 0.0206  max mem: 282\n",
            "Epoch: [0]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 5338.015530698483  loss: 0.1252 (0.2746)  acc1: 96.0938 (91.4062)  acc5: 100.0000 (98.2088)  time: 0.0443  data: 0.0203  max mem: 282\n",
            "Epoch: [0] Total time: 0:00:03\n",
            "Test:   [   0/1459]  eta: 0:01:25  loss: 0.0002 (0.0002)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0588  data: 0.0006  max mem: 282\n",
            "Test:   [ 100/1459]  eta: 0:00:07  loss: 0.0002 (0.0878)  acc1: 100.0000 (98.0198)  acc5: 100.0000 (100.0000)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [ 200/1459]  eta: 0:00:06  loss: 0.0006 (0.0897)  acc1: 100.0000 (97.0149)  acc5: 100.0000 (100.0000)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 300/1459]  eta: 0:00:06  loss: 0.0004 (0.1559)  acc1: 100.0000 (96.3455)  acc5: 100.0000 (99.6678)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 400/1459]  eta: 0:00:05  loss: 0.0001 (0.1438)  acc1: 100.0000 (96.2594)  acc5: 100.0000 (99.7506)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 500/1459]  eta: 0:00:05  loss: 0.0002 (0.1467)  acc1: 100.0000 (95.6088)  acc5: 100.0000 (99.8004)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 600/1459]  eta: 0:00:04  loss: 0.0001 (0.1425)  acc1: 100.0000 (95.1747)  acc5: 100.0000 (99.8336)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 700/1459]  eta: 0:00:03  loss: 0.0003 (0.1372)  acc1: 100.0000 (95.4351)  acc5: 100.0000 (99.7147)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 800/1459]  eta: 0:00:03  loss: 0.0012 (0.1412)  acc1: 100.0000 (95.1311)  acc5: 100.0000 (99.7503)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 900/1459]  eta: 0:00:02  loss: 0.0003 (0.1359)  acc1: 100.0000 (95.3385)  acc5: 100.0000 (99.6670)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [1000/1459]  eta: 0:00:02  loss: 0.0003 (0.1277)  acc1: 100.0000 (95.6044)  acc5: 100.0000 (99.7003)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [1100/1459]  eta: 0:00:01  loss: 0.0002 (0.1212)  acc1: 100.0000 (95.7312)  acc5: 100.0000 (99.7275)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1200/1459]  eta: 0:00:01  loss: 0.0009 (0.1313)  acc1: 100.0000 (95.7535)  acc5: 100.0000 (99.6669)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [1300/1459]  eta: 0:00:00  loss: 0.0008 (0.1337)  acc1: 100.0000 (95.7725)  acc5: 100.0000 (99.6925)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [1400/1459]  eta: 0:00:00  loss: 0.0009 (0.1319)  acc1: 100.0000 (95.8601)  acc5: 100.0000 (99.7145)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:  Total time: 0:00:07\n",
            "Test:  Acc@1 96.025 Acc@5 99.726  Kappa 0.955 Loss 0.127\n",
            "Epoch: [1]  [ 0/46]  eta: 0:00:02  lr: 0.0003  img/s: 4494.185553202354  loss: 0.0838 (0.0838)  acc1: 96.0938 (96.0938)  acc5: 100.0000 (100.0000)  time: 0.0481  data: 0.0196  max mem: 282\n",
            "Epoch: [1]  [10/46]  eta: 0:00:01  lr: 0.0003  img/s: 4994.75203512983  loss: 0.0897 (0.0892)  acc1: 97.6562 (97.2301)  acc5: 100.0000 (99.8580)  time: 0.0471  data: 0.0200  max mem: 282\n",
            "Epoch: [1]  [20/46]  eta: 0:00:01  lr: 0.0003  img/s: 5349.7176224403365  loss: 0.0744 (0.0819)  acc1: 97.6562 (97.4702)  acc5: 100.0000 (99.9256)  time: 0.0457  data: 0.0200  max mem: 282\n",
            "Epoch: [1]  [30/46]  eta: 0:00:00  lr: 0.0003  img/s: 5303.004889420085  loss: 0.0715 (0.0795)  acc1: 97.6562 (97.5554)  acc5: 100.0000 (99.9244)  time: 0.0444  data: 0.0201  max mem: 282\n",
            "Epoch: [1]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 5291.036701226002  loss: 0.0612 (0.0736)  acc1: 97.6562 (97.7325)  acc5: 100.0000 (99.9238)  time: 0.0447  data: 0.0205  max mem: 282\n",
            "Epoch: [1] Total time: 0:00:02\n",
            "Test:   [   0/1459]  eta: 0:00:08  loss: 0.0007 (0.0007)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0058  data: 0.0006  max mem: 282\n",
            "Test:   [ 100/1459]  eta: 0:00:07  loss: 0.0004 (0.0577)  acc1: 100.0000 (98.0198)  acc5: 100.0000 (100.0000)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 200/1459]  eta: 0:00:06  loss: 0.0026 (0.0579)  acc1: 100.0000 (98.5075)  acc5: 100.0000 (100.0000)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 300/1459]  eta: 0:00:06  loss: 0.0003 (0.0885)  acc1: 100.0000 (98.3389)  acc5: 100.0000 (99.6678)  time: 0.0073  data: 0.0004  max mem: 282\n",
            "Test:   [ 400/1459]  eta: 0:00:05  loss: 0.0038 (0.0847)  acc1: 100.0000 (98.0050)  acc5: 100.0000 (99.7506)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 500/1459]  eta: 0:00:05  loss: 0.0011 (0.0850)  acc1: 100.0000 (97.4052)  acc5: 100.0000 (99.8004)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 600/1459]  eta: 0:00:04  loss: 0.0006 (0.0946)  acc1: 100.0000 (97.1714)  acc5: 100.0000 (99.8336)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 700/1459]  eta: 0:00:04  loss: 0.0007 (0.0875)  acc1: 100.0000 (97.1469)  acc5: 100.0000 (99.8573)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 800/1459]  eta: 0:00:03  loss: 0.0008 (0.0932)  acc1: 100.0000 (97.2534)  acc5: 100.0000 (99.8752)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 900/1459]  eta: 0:00:02  loss: 0.0006 (0.0930)  acc1: 100.0000 (97.2253)  acc5: 100.0000 (99.8890)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1000/1459]  eta: 0:00:02  loss: 0.0003 (0.0859)  acc1: 100.0000 (97.5025)  acc5: 100.0000 (99.9001)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1100/1459]  eta: 0:00:01  loss: 0.0001 (0.0852)  acc1: 100.0000 (97.4569)  acc5: 100.0000 (99.9092)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1200/1459]  eta: 0:00:01  loss: 0.0003 (0.0845)  acc1: 100.0000 (97.1690)  acc5: 100.0000 (99.9167)  time: 0.0055  data: 0.0003  max mem: 282\n",
            "Test:   [1300/1459]  eta: 0:00:00  loss: 0.0005 (0.0833)  acc1: 100.0000 (97.1560)  acc5: 100.0000 (99.9231)  time: 0.0056  data: 0.0003  max mem: 282\n",
            "Test:   [1400/1459]  eta: 0:00:00  loss: 0.0034 (0.0860)  acc1: 100.0000 (97.1449)  acc5: 100.0000 (99.9286)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:  Total time: 0:00:07\n",
            "Test:  Acc@1 97.190 Acc@5 99.931  Kappa 0.968 Loss 0.085\n",
            "Epoch: [2]  [ 0/46]  eta: 0:00:02  lr: 0.0003  img/s: 4863.666038556313  loss: 0.0221 (0.0221)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0518  data: 0.0254  max mem: 282\n",
            "Epoch: [2]  [10/46]  eta: 0:00:01  lr: 0.0003  img/s: 5153.647413437263  loss: 0.0221 (0.0291)  acc1: 99.2188 (99.0767)  acc5: 100.0000 (100.0000)  time: 0.0464  data: 0.0212  max mem: 282\n",
            "Epoch: [2]  [20/46]  eta: 0:00:01  lr: 0.0003  img/s: 5428.366871922428  loss: 0.0181 (0.0320)  acc1: 99.2188 (98.9955)  acc5: 100.0000 (100.0000)  time: 0.0447  data: 0.0203  max mem: 282\n",
            "Epoch: [2]  [30/46]  eta: 0:00:00  lr: 0.0003  img/s: 5406.936158641596  loss: 0.0255 (0.0364)  acc1: 99.2188 (98.8659)  acc5: 100.0000 (100.0000)  time: 0.0439  data: 0.0201  max mem: 282\n",
            "Epoch: [2]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 5544.926896779658  loss: 0.0428 (0.0410)  acc1: 98.4375 (98.7043)  acc5: 100.0000 (99.9809)  time: 0.0435  data: 0.0198  max mem: 282\n",
            "Epoch: [2] Total time: 0:00:02\n",
            "Test:   [   0/1459]  eta: 0:00:08  loss: 0.0003 (0.0003)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0058  data: 0.0006  max mem: 282\n",
            "Test:   [ 100/1459]  eta: 0:00:07  loss: 0.0003 (0.0972)  acc1: 100.0000 (97.0297)  acc5: 100.0000 (99.0099)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 200/1459]  eta: 0:00:06  loss: 0.0005 (0.0763)  acc1: 100.0000 (97.5124)  acc5: 100.0000 (99.5025)  time: 0.0054  data: 0.0003  max mem: 282\n",
            "Test:   [ 300/1459]  eta: 0:00:06  loss: 0.0001 (0.1323)  acc1: 100.0000 (95.6811)  acc5: 100.0000 (99.3355)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 400/1459]  eta: 0:00:05  loss: 0.0011 (0.1177)  acc1: 100.0000 (96.2594)  acc5: 100.0000 (99.5012)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 500/1459]  eta: 0:00:05  loss: 0.0013 (0.1143)  acc1: 100.0000 (96.2076)  acc5: 100.0000 (99.6008)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [ 600/1459]  eta: 0:00:04  loss: 0.0000 (0.1193)  acc1: 100.0000 (96.0067)  acc5: 100.0000 (99.6672)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 700/1459]  eta: 0:00:03  loss: 0.0003 (0.1079)  acc1: 100.0000 (96.4337)  acc5: 100.0000 (99.7147)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [ 800/1459]  eta: 0:00:03  loss: 0.0003 (0.1131)  acc1: 100.0000 (96.1298)  acc5: 100.0000 (99.7503)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 900/1459]  eta: 0:00:02  loss: 0.0006 (0.1083)  acc1: 100.0000 (96.3374)  acc5: 100.0000 (99.7780)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [1000/1459]  eta: 0:00:02  loss: 0.0008 (0.1028)  acc1: 100.0000 (96.5035)  acc5: 100.0000 (99.8002)  time: 0.0057  data: 0.0003  max mem: 282\n",
            "Test:   [1100/1459]  eta: 0:00:01  loss: 0.0001 (0.0986)  acc1: 100.0000 (96.5486)  acc5: 100.0000 (99.8183)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1200/1459]  eta: 0:00:01  loss: 0.0002 (0.1089)  acc1: 100.0000 (96.5029)  acc5: 100.0000 (99.8335)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1300/1459]  eta: 0:00:00  loss: 0.0002 (0.1084)  acc1: 100.0000 (96.3874)  acc5: 100.0000 (99.8463)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [1400/1459]  eta: 0:00:00  loss: 0.0001 (0.1092)  acc1: 100.0000 (96.5025)  acc5: 100.0000 (99.8572)  time: 0.0054  data: 0.0003  max mem: 282\n",
            "Test:  Total time: 0:00:07\n",
            "Test:  Acc@1 96.642 Acc@5 99.863  Kappa 0.962 Loss 0.106\n",
            "Epoch: [3]  [ 0/46]  eta: 0:00:02  lr: 0.0003  img/s: 4582.4520049847215  loss: 0.0328 (0.0328)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0488  data: 0.0209  max mem: 282\n",
            "Epoch: [3]  [10/46]  eta: 0:00:01  lr: 0.0003  img/s: 5179.152151263746  loss: 0.0152 (0.0295)  acc1: 100.0000 (99.3608)  acc5: 100.0000 (100.0000)  time: 0.0465  data: 0.0201  max mem: 282\n",
            "Epoch: [3]  [20/46]  eta: 0:00:01  lr: 0.0003  img/s: 5440.524037292258  loss: 0.0263 (0.0340)  acc1: 99.2188 (99.0699)  acc5: 100.0000 (100.0000)  time: 0.0446  data: 0.0198  max mem: 282\n",
            "Epoch: [3]  [30/46]  eta: 0:00:00  lr: 0.0003  img/s: 5482.078503451375  loss: 0.0294 (0.0327)  acc1: 99.2188 (99.0423)  acc5: 100.0000 (99.9748)  time: 0.0435  data: 0.0199  max mem: 282\n",
            "Epoch: [3]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 5351.744091230798  loss: 0.0173 (0.0298)  acc1: 99.2188 (99.1425)  acc5: 100.0000 (99.9809)  time: 0.0437  data: 0.0199  max mem: 282\n",
            "Epoch: [3] Total time: 0:00:02\n",
            "Test:   [   0/1459]  eta: 0:00:07  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0053  data: 0.0005  max mem: 282\n",
            "Test:   [ 100/1459]  eta: 0:00:06  loss: 0.0000 (0.0676)  acc1: 100.0000 (99.0099)  acc5: 100.0000 (99.0099)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 200/1459]  eta: 0:00:06  loss: 0.0003 (0.0949)  acc1: 100.0000 (96.5174)  acc5: 100.0000 (99.5025)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [ 300/1459]  eta: 0:00:05  loss: 0.0001 (0.1238)  acc1: 100.0000 (97.0100)  acc5: 100.0000 (99.3355)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 400/1459]  eta: 0:00:05  loss: 0.0000 (0.1183)  acc1: 100.0000 (97.0075)  acc5: 100.0000 (99.5012)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [ 500/1459]  eta: 0:00:04  loss: 0.0000 (0.1020)  acc1: 100.0000 (97.4052)  acc5: 100.0000 (99.6008)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 600/1459]  eta: 0:00:04  loss: 0.0000 (0.1110)  acc1: 100.0000 (96.8386)  acc5: 100.0000 (99.6672)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 700/1459]  eta: 0:00:03  loss: 0.0000 (0.1069)  acc1: 100.0000 (96.8616)  acc5: 100.0000 (99.7147)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 800/1459]  eta: 0:00:03  loss: 0.0003 (0.1150)  acc1: 100.0000 (96.3795)  acc5: 100.0000 (99.7503)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 900/1459]  eta: 0:00:02  loss: 0.0002 (0.1074)  acc1: 100.0000 (96.4484)  acc5: 100.0000 (99.7780)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1000/1459]  eta: 0:00:02  loss: 0.0001 (0.0987)  acc1: 100.0000 (96.6034)  acc5: 100.0000 (99.8002)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1100/1459]  eta: 0:00:01  loss: 0.0000 (0.0958)  acc1: 100.0000 (96.7302)  acc5: 100.0000 (99.8183)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1200/1459]  eta: 0:00:01  loss: 0.0000 (0.0947)  acc1: 100.0000 (96.6694)  acc5: 100.0000 (99.8335)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1300/1459]  eta: 0:00:00  loss: 0.0000 (0.0937)  acc1: 100.0000 (96.7717)  acc5: 100.0000 (99.8463)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1400/1459]  eta: 0:00:00  loss: 0.0002 (0.0926)  acc1: 100.0000 (96.9308)  acc5: 100.0000 (99.8572)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:  Total time: 0:00:07\n",
            "Test:  Acc@1 97.053 Acc@5 99.863  Kappa 0.967 Loss 0.090\n",
            "Epoch: [4]  [ 0/46]  eta: 0:00:02  lr: 0.0003  img/s: 4395.969081619285  loss: 0.0064 (0.0064)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0588  data: 0.0297  max mem: 282\n",
            "Epoch: [4]  [10/46]  eta: 0:00:01  lr: 0.0003  img/s: 5186.557230079604  loss: 0.0072 (0.0231)  acc1: 100.0000 (99.6449)  acc5: 100.0000 (100.0000)  time: 0.0482  data: 0.0216  max mem: 282\n",
            "Epoch: [4]  [20/46]  eta: 0:00:01  lr: 0.0003  img/s: 5289.368591133005  loss: 0.0144 (0.0210)  acc1: 99.2188 (99.4048)  acc5: 100.0000 (100.0000)  time: 0.0480  data: 0.0222  max mem: 282\n",
            "Epoch: [4]  [30/46]  eta: 0:00:00  lr: 0.0003  img/s: 5276.217035369965  loss: 0.0118 (0.0215)  acc1: 99.2188 (99.4708)  acc5: 100.0000 (100.0000)  time: 0.0465  data: 0.0219  max mem: 282\n",
            "Epoch: [4]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 5530.361589253891  loss: 0.0107 (0.0212)  acc1: 100.0000 (99.4093)  acc5: 100.0000 (100.0000)  time: 0.0437  data: 0.0199  max mem: 282\n",
            "Epoch: [4] Total time: 0:00:02\n",
            "Test:   [   0/1459]  eta: 0:00:08  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0057  data: 0.0005  max mem: 282\n",
            "Test:   [ 100/1459]  eta: 0:00:07  loss: 0.0002 (0.0557)  acc1: 100.0000 (97.0297)  acc5: 100.0000 (100.0000)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 200/1459]  eta: 0:00:06  loss: 0.0000 (0.0796)  acc1: 100.0000 (97.0149)  acc5: 100.0000 (100.0000)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 300/1459]  eta: 0:00:05  loss: 0.0000 (0.1531)  acc1: 100.0000 (96.0133)  acc5: 100.0000 (99.6678)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 400/1459]  eta: 0:00:05  loss: 0.0009 (0.1400)  acc1: 100.0000 (96.2594)  acc5: 100.0000 (99.7506)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [ 500/1459]  eta: 0:00:04  loss: 0.0003 (0.1309)  acc1: 100.0000 (96.4072)  acc5: 100.0000 (99.8004)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 600/1459]  eta: 0:00:04  loss: 0.0000 (0.1267)  acc1: 100.0000 (96.6722)  acc5: 100.0000 (99.8336)  time: 0.0054  data: 0.0003  max mem: 282\n",
            "Test:   [ 700/1459]  eta: 0:00:03  loss: 0.0001 (0.1103)  acc1: 100.0000 (97.0043)  acc5: 100.0000 (99.8573)  time: 0.0055  data: 0.0003  max mem: 282\n",
            "Test:   [ 800/1459]  eta: 0:00:03  loss: 0.0000 (0.1227)  acc1: 100.0000 (96.5044)  acc5: 100.0000 (99.8752)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 900/1459]  eta: 0:00:02  loss: 0.0001 (0.1291)  acc1: 100.0000 (96.3374)  acc5: 100.0000 (99.8890)  time: 0.0054  data: 0.0003  max mem: 282\n",
            "Test:   [1000/1459]  eta: 0:00:02  loss: 0.0001 (0.1187)  acc1: 100.0000 (96.6034)  acc5: 100.0000 (99.9001)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1100/1459]  eta: 0:00:01  loss: 0.0000 (0.1164)  acc1: 100.0000 (96.7302)  acc5: 100.0000 (99.9092)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1200/1459]  eta: 0:00:01  loss: 0.0002 (0.1188)  acc1: 100.0000 (96.7527)  acc5: 100.0000 (99.9167)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1300/1459]  eta: 0:00:00  loss: 0.0000 (0.1214)  acc1: 100.0000 (96.6949)  acc5: 100.0000 (99.9231)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1400/1459]  eta: 0:00:00  loss: 0.0000 (0.1169)  acc1: 100.0000 (96.7880)  acc5: 100.0000 (99.9286)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:  Total time: 0:00:07\n",
            "Test:  Acc@1 96.779 Acc@5 99.931  Kappa 0.964 Loss 0.119\n",
            "Epoch: [5]  [ 0/46]  eta: 0:00:02  lr: 0.0003  img/s: 4940.151019093628  loss: 0.0016 (0.0016)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0493  data: 0.0234  max mem: 282\n",
            "Epoch: [5]  [10/46]  eta: 0:00:01  lr: 0.0003  img/s: 5496.615359413553  loss: 0.0060 (0.0176)  acc1: 100.0000 (99.7159)  acc5: 100.0000 (100.0000)  time: 0.0445  data: 0.0200  max mem: 282\n",
            "Epoch: [5]  [20/46]  eta: 0:00:01  lr: 0.0003  img/s: 5200.373044547981  loss: 0.0114 (0.0198)  acc1: 100.0000 (99.6280)  acc5: 100.0000 (100.0000)  time: 0.0440  data: 0.0199  max mem: 282\n",
            "Epoch: [5]  [30/46]  eta: 0:00:00  lr: 0.0003  img/s: 5448.861878228745  loss: 0.0107 (0.0174)  acc1: 100.0000 (99.5716)  acc5: 100.0000 (100.0000)  time: 0.0445  data: 0.0205  max mem: 282\n",
            "Epoch: [5]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 5349.664315038463  loss: 0.0090 (0.0199)  acc1: 99.2188 (99.4474)  acc5: 100.0000 (100.0000)  time: 0.0449  data: 0.0206  max mem: 282\n",
            "Epoch: [5] Total time: 0:00:02\n",
            "Test:   [   0/1459]  eta: 0:00:07  loss: 0.0001 (0.0001)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0054  data: 0.0005  max mem: 282\n",
            "Test:   [ 100/1459]  eta: 0:00:07  loss: 0.0001 (0.0580)  acc1: 100.0000 (96.0396)  acc5: 100.0000 (100.0000)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 200/1459]  eta: 0:00:06  loss: 0.0004 (0.0758)  acc1: 100.0000 (97.0149)  acc5: 100.0000 (100.0000)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 300/1459]  eta: 0:00:06  loss: 0.0001 (0.1212)  acc1: 100.0000 (96.3455)  acc5: 100.0000 (99.6678)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 400/1459]  eta: 0:00:05  loss: 0.0001 (0.1169)  acc1: 100.0000 (96.0100)  acc5: 100.0000 (99.7506)  time: 0.0055  data: 0.0003  max mem: 282\n",
            "Test:   [ 500/1459]  eta: 0:00:05  loss: 0.0003 (0.1139)  acc1: 100.0000 (96.2076)  acc5: 100.0000 (99.8004)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 600/1459]  eta: 0:00:04  loss: 0.0000 (0.1282)  acc1: 100.0000 (96.0067)  acc5: 100.0000 (99.8336)  time: 0.0057  data: 0.0003  max mem: 282\n",
            "Test:   [ 700/1459]  eta: 0:00:04  loss: 0.0002 (0.1152)  acc1: 100.0000 (96.2910)  acc5: 100.0000 (99.8573)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [ 800/1459]  eta: 0:00:03  loss: 0.0001 (0.1158)  acc1: 100.0000 (96.3795)  acc5: 100.0000 (99.8752)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 900/1459]  eta: 0:00:02  loss: 0.0001 (0.1233)  acc1: 100.0000 (96.1154)  acc5: 100.0000 (99.8890)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [1000/1459]  eta: 0:00:02  loss: 0.0002 (0.1123)  acc1: 100.0000 (96.5035)  acc5: 100.0000 (99.9001)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1100/1459]  eta: 0:00:01  loss: 0.0000 (0.1126)  acc1: 100.0000 (96.5486)  acc5: 100.0000 (99.9092)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [1200/1459]  eta: 0:00:01  loss: 0.0000 (0.1123)  acc1: 100.0000 (96.5029)  acc5: 100.0000 (99.9167)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [1300/1459]  eta: 0:00:00  loss: 0.0001 (0.1110)  acc1: 100.0000 (96.4643)  acc5: 100.0000 (99.9231)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1400/1459]  eta: 0:00:00  loss: 0.0001 (0.1110)  acc1: 100.0000 (96.5739)  acc5: 100.0000 (99.9286)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:  Total time: 0:00:07\n",
            "Test:  Acc@1 96.642 Acc@5 99.931  Kappa 0.962 Loss 0.111\n",
            "Epoch: [6]  [ 0/46]  eta: 0:00:02  lr: 0.0003  img/s: 4541.709277635375  loss: 0.0442 (0.0442)  acc1: 97.6562 (97.6562)  acc5: 100.0000 (100.0000)  time: 0.0496  data: 0.0214  max mem: 282\n",
            "Epoch: [6]  [10/46]  eta: 0:00:01  lr: 0.0003  img/s: 5480.343721609179  loss: 0.0168 (0.0256)  acc1: 99.2188 (99.0767)  acc5: 100.0000 (100.0000)  time: 0.0470  data: 0.0208  max mem: 282\n",
            "Epoch: [6]  [20/46]  eta: 0:00:01  lr: 0.0003  img/s: 5446.595434716445  loss: 0.0146 (0.0223)  acc1: 99.2188 (99.1815)  acc5: 100.0000 (100.0000)  time: 0.0452  data: 0.0202  max mem: 282\n",
            "Epoch: [6]  [30/46]  eta: 0:00:00  lr: 0.0003  img/s: 5412.332520112103  loss: 0.0121 (0.0210)  acc1: 100.0000 (99.3700)  acc5: 100.0000 (100.0000)  time: 0.0431  data: 0.0195  max mem: 282\n",
            "Epoch: [6]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 5429.300109218882  loss: 0.0111 (0.0204)  acc1: 100.0000 (99.3902)  acc5: 100.0000 (100.0000)  time: 0.0432  data: 0.0196  max mem: 282\n",
            "Epoch: [6] Total time: 0:00:02\n",
            "Test:   [   0/1459]  eta: 0:00:07  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0053  data: 0.0004  max mem: 282\n",
            "Test:   [ 100/1459]  eta: 0:00:07  loss: 0.0000 (0.0108)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0054  data: 0.0003  max mem: 282\n",
            "Test:   [ 200/1459]  eta: 0:00:06  loss: 0.0001 (0.0999)  acc1: 100.0000 (98.0100)  acc5: 100.0000 (100.0000)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [ 300/1459]  eta: 0:00:06  loss: 0.0000 (0.1605)  acc1: 100.0000 (97.3422)  acc5: 100.0000 (99.6678)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 400/1459]  eta: 0:00:05  loss: 0.0009 (0.1344)  acc1: 100.0000 (97.2569)  acc5: 100.0000 (99.7506)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 500/1459]  eta: 0:00:05  loss: 0.0003 (0.1273)  acc1: 100.0000 (97.2056)  acc5: 100.0000 (99.8004)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 600/1459]  eta: 0:00:04  loss: 0.0000 (0.1203)  acc1: 100.0000 (97.0050)  acc5: 100.0000 (99.8336)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 700/1459]  eta: 0:00:04  loss: 0.0002 (0.1045)  acc1: 100.0000 (97.4322)  acc5: 100.0000 (99.8573)  time: 0.0054  data: 0.0003  max mem: 282\n",
            "Test:   [ 800/1459]  eta: 0:00:03  loss: 0.0002 (0.1213)  acc1: 100.0000 (96.8789)  acc5: 100.0000 (99.8752)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 900/1459]  eta: 0:00:02  loss: 0.0002 (0.1157)  acc1: 100.0000 (97.0033)  acc5: 100.0000 (99.8890)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1000/1459]  eta: 0:00:02  loss: 0.0000 (0.1091)  acc1: 100.0000 (97.1029)  acc5: 100.0000 (99.9001)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [1100/1459]  eta: 0:00:01  loss: 0.0000 (0.1049)  acc1: 100.0000 (97.2752)  acc5: 100.0000 (99.8183)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1200/1459]  eta: 0:00:01  loss: 0.0001 (0.1100)  acc1: 100.0000 (97.2523)  acc5: 100.0000 (99.8335)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1300/1459]  eta: 0:00:00  loss: 0.0001 (0.1056)  acc1: 100.0000 (97.3866)  acc5: 100.0000 (99.8463)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [1400/1459]  eta: 0:00:00  loss: 0.0000 (0.1063)  acc1: 100.0000 (97.4304)  acc5: 100.0000 (99.8572)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:  Total time: 0:00:07\n",
            "Test:  Acc@1 97.395 Acc@5 99.863  Kappa 0.971 Loss 0.106\n",
            "Epoch: [7]  [ 0/46]  eta: 0:00:02  lr: 0.0003  img/s: 4271.763078955116  loss: 0.0033 (0.0033)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0514  data: 0.0214  max mem: 282\n",
            "Epoch: [7]  [10/46]  eta: 0:00:01  lr: 0.0003  img/s: 5017.578945400848  loss: 0.0055 (0.0210)  acc1: 100.0000 (99.5028)  acc5: 100.0000 (100.0000)  time: 0.0478  data: 0.0203  max mem: 282\n",
            "Epoch: [7]  [20/46]  eta: 0:00:01  lr: 0.0003  img/s: 5269.174415295076  loss: 0.0099 (0.0170)  acc1: 100.0000 (99.5164)  acc5: 100.0000 (100.0000)  time: 0.0466  data: 0.0207  max mem: 282\n",
            "Epoch: [7]  [30/46]  eta: 0:00:00  lr: 0.0003  img/s: 5474.0852612796325  loss: 0.0104 (0.0205)  acc1: 99.2188 (99.4204)  acc5: 100.0000 (100.0000)  time: 0.0445  data: 0.0204  max mem: 282\n",
            "Epoch: [7]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 5378.605754588442  loss: 0.0127 (0.0191)  acc1: 99.2188 (99.4284)  acc5: 100.0000 (100.0000)  time: 0.0432  data: 0.0195  max mem: 282\n",
            "Epoch: [7] Total time: 0:00:02\n",
            "Test:   [   0/1459]  eta: 0:00:07  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0053  data: 0.0005  max mem: 282\n",
            "Test:   [ 100/1459]  eta: 0:00:07  loss: 0.0000 (0.0302)  acc1: 100.0000 (99.0099)  acc5: 100.0000 (100.0000)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 200/1459]  eta: 0:00:06  loss: 0.0000 (0.0319)  acc1: 100.0000 (98.5075)  acc5: 100.0000 (100.0000)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 300/1459]  eta: 0:00:06  loss: 0.0000 (0.0857)  acc1: 100.0000 (98.3389)  acc5: 100.0000 (99.6678)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [ 400/1459]  eta: 0:00:05  loss: 0.0000 (0.0741)  acc1: 100.0000 (98.2544)  acc5: 100.0000 (99.7506)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 500/1459]  eta: 0:00:04  loss: 0.0001 (0.0637)  acc1: 100.0000 (98.4032)  acc5: 100.0000 (99.8004)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [ 600/1459]  eta: 0:00:04  loss: 0.0000 (0.0745)  acc1: 100.0000 (98.1697)  acc5: 100.0000 (99.8336)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [ 700/1459]  eta: 0:00:03  loss: 0.0001 (0.0655)  acc1: 100.0000 (98.2882)  acc5: 100.0000 (99.8573)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 800/1459]  eta: 0:00:03  loss: 0.0000 (0.0772)  acc1: 100.0000 (98.1273)  acc5: 100.0000 (99.8752)  time: 0.0049  data: 0.0003  max mem: 282\n",
            "Test:   [ 900/1459]  eta: 0:00:02  loss: 0.0000 (0.0717)  acc1: 100.0000 (98.2242)  acc5: 100.0000 (99.8890)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1000/1459]  eta: 0:00:02  loss: 0.0001 (0.0657)  acc1: 100.0000 (98.3017)  acc5: 100.0000 (99.9001)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1100/1459]  eta: 0:00:01  loss: 0.0000 (0.0661)  acc1: 100.0000 (98.2743)  acc5: 100.0000 (99.9092)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [1200/1459]  eta: 0:00:01  loss: 0.0001 (0.0668)  acc1: 100.0000 (98.1682)  acc5: 100.0000 (99.9167)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1300/1459]  eta: 0:00:00  loss: 0.0000 (0.0659)  acc1: 100.0000 (98.0784)  acc5: 100.0000 (99.9231)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1400/1459]  eta: 0:00:00  loss: 0.0000 (0.0638)  acc1: 100.0000 (98.1442)  acc5: 100.0000 (99.9286)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:  Total time: 0:00:07\n",
            "Test:  Acc@1 98.218 Acc@5 99.931  Kappa 0.980 Loss 0.062\n",
            "Epoch: [8]  [ 0/46]  eta: 0:00:02  lr: 0.0003  img/s: 4387.454844113921  loss: 0.0774 (0.0774)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0488  data: 0.0197  max mem: 282\n",
            "Epoch: [8]  [10/46]  eta: 0:00:01  lr: 0.0003  img/s: 5524.613719154541  loss: 0.0089 (0.0226)  acc1: 100.0000 (99.2898)  acc5: 100.0000 (100.0000)  time: 0.0455  data: 0.0196  max mem: 282\n",
            "Epoch: [8]  [20/46]  eta: 0:00:01  lr: 0.0003  img/s: 5529.2224476554375  loss: 0.0069 (0.0171)  acc1: 100.0000 (99.4792)  acc5: 100.0000 (100.0000)  time: 0.0439  data: 0.0193  max mem: 282\n",
            "Epoch: [8]  [30/46]  eta: 0:00:00  lr: 0.0003  img/s: 5475.983639497761  loss: 0.0081 (0.0164)  acc1: 99.2188 (99.4960)  acc5: 100.0000 (100.0000)  time: 0.0425  data: 0.0191  max mem: 282\n",
            "Epoch: [8]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 5553.300839918905  loss: 0.0123 (0.0153)  acc1: 99.2188 (99.5046)  acc5: 100.0000 (100.0000)  time: 0.0426  data: 0.0193  max mem: 282\n",
            "Epoch: [8] Total time: 0:00:01\n",
            "Test:   [   0/1459]  eta: 0:00:08  loss: 0.0456 (0.0456)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0057  data: 0.0005  max mem: 282\n",
            "Test:   [ 100/1459]  eta: 0:00:07  loss: 0.0001 (0.0215)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [ 200/1459]  eta: 0:00:06  loss: 0.0003 (0.0485)  acc1: 100.0000 (98.5075)  acc5: 100.0000 (100.0000)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 300/1459]  eta: 0:00:05  loss: 0.0001 (0.1266)  acc1: 100.0000 (97.6744)  acc5: 100.0000 (99.6678)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 400/1459]  eta: 0:00:05  loss: 0.0001 (0.1343)  acc1: 100.0000 (97.0075)  acc5: 100.0000 (99.7506)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 500/1459]  eta: 0:00:05  loss: 0.0001 (0.1271)  acc1: 100.0000 (97.0060)  acc5: 100.0000 (99.8004)  time: 0.0054  data: 0.0003  max mem: 282\n",
            "Test:   [ 600/1459]  eta: 0:00:04  loss: 0.0000 (0.1414)  acc1: 100.0000 (96.6722)  acc5: 100.0000 (99.8336)  time: 0.0054  data: 0.0003  max mem: 282\n",
            "Test:   [ 700/1459]  eta: 0:00:04  loss: 0.0001 (0.1342)  acc1: 100.0000 (96.7190)  acc5: 100.0000 (99.8573)  time: 0.0057  data: 0.0003  max mem: 282\n",
            "Test:   [ 800/1459]  eta: 0:00:03  loss: 0.0000 (0.1354)  acc1: 100.0000 (96.7541)  acc5: 100.0000 (99.7503)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 900/1459]  eta: 0:00:02  loss: 0.0003 (0.1386)  acc1: 100.0000 (96.7814)  acc5: 100.0000 (99.7780)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1000/1459]  eta: 0:00:02  loss: 0.0000 (0.1252)  acc1: 100.0000 (97.1029)  acc5: 100.0000 (99.8002)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1100/1459]  eta: 0:00:01  loss: 0.0000 (0.1171)  acc1: 100.0000 (97.2752)  acc5: 100.0000 (99.8183)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1200/1459]  eta: 0:00:01  loss: 0.0001 (0.1179)  acc1: 100.0000 (97.0858)  acc5: 100.0000 (99.8335)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1300/1459]  eta: 0:00:00  loss: 0.0001 (0.1135)  acc1: 100.0000 (97.2329)  acc5: 100.0000 (99.8463)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [1400/1459]  eta: 0:00:00  loss: 0.0001 (0.1121)  acc1: 100.0000 (97.3590)  acc5: 100.0000 (99.8572)  time: 0.0054  data: 0.0003  max mem: 282\n",
            "Test:  Total time: 0:00:07\n",
            "Test:  Acc@1 97.327 Acc@5 99.863  Kappa 0.970 Loss 0.113\n",
            "Epoch: [9]  [ 0/46]  eta: 0:00:02  lr: 0.0003  img/s: 4543.361982296092  loss: 0.0449 (0.0449)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0490  data: 0.0208  max mem: 282\n",
            "Epoch: [9]  [10/46]  eta: 0:00:01  lr: 0.0003  img/s: 5422.336023270142  loss: 0.0129 (0.0201)  acc1: 99.2188 (99.4318)  acc5: 100.0000 (100.0000)  time: 0.0464  data: 0.0202  max mem: 282\n",
            "Epoch: [9]  [20/46]  eta: 0:00:01  lr: 0.0003  img/s: 5382.704150792059  loss: 0.0076 (0.0142)  acc1: 100.0000 (99.6652)  acc5: 100.0000 (100.0000)  time: 0.0452  data: 0.0203  max mem: 282\n",
            "Epoch: [9]  [30/46]  eta: 0:00:00  lr: 0.0003  img/s: 5214.870441962117  loss: 0.0079 (0.0183)  acc1: 100.0000 (99.5464)  acc5: 100.0000 (100.0000)  time: 0.0446  data: 0.0207  max mem: 282\n",
            "Epoch: [9]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 5417.029018848125  loss: 0.0106 (0.0170)  acc1: 99.2188 (99.5427)  acc5: 100.0000 (100.0000)  time: 0.0454  data: 0.0213  max mem: 282\n",
            "Epoch: [9] Total time: 0:00:02\n",
            "Test:   [   0/1459]  eta: 0:00:07  loss: 0.0001 (0.0001)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0054  data: 0.0005  max mem: 282\n",
            "Test:   [ 100/1459]  eta: 0:00:07  loss: 0.0000 (0.0437)  acc1: 100.0000 (98.0198)  acc5: 100.0000 (100.0000)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 200/1459]  eta: 0:00:06  loss: 0.0000 (0.0610)  acc1: 100.0000 (97.5124)  acc5: 100.0000 (100.0000)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 300/1459]  eta: 0:00:05  loss: 0.0000 (0.1314)  acc1: 100.0000 (96.6777)  acc5: 100.0000 (100.0000)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [ 400/1459]  eta: 0:00:05  loss: 0.0002 (0.1217)  acc1: 100.0000 (96.7581)  acc5: 100.0000 (100.0000)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 500/1459]  eta: 0:00:04  loss: 0.0003 (0.1202)  acc1: 100.0000 (96.8064)  acc5: 100.0000 (100.0000)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [ 600/1459]  eta: 0:00:04  loss: 0.0000 (0.1524)  acc1: 100.0000 (96.5058)  acc5: 100.0000 (99.8336)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 700/1459]  eta: 0:00:03  loss: 0.0001 (0.1421)  acc1: 100.0000 (96.8616)  acc5: 100.0000 (99.8573)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 800/1459]  eta: 0:00:03  loss: 0.0000 (0.1350)  acc1: 100.0000 (97.0037)  acc5: 100.0000 (99.8752)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [ 900/1459]  eta: 0:00:02  loss: 0.0000 (0.1275)  acc1: 100.0000 (97.1143)  acc5: 100.0000 (99.8890)  time: 0.0054  data: 0.0003  max mem: 282\n",
            "Test:   [1000/1459]  eta: 0:00:02  loss: 0.0001 (0.1168)  acc1: 100.0000 (97.3027)  acc5: 100.0000 (99.9001)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1100/1459]  eta: 0:00:01  loss: 0.0000 (0.1114)  acc1: 100.0000 (97.2752)  acc5: 100.0000 (99.9092)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1200/1459]  eta: 0:00:01  loss: 0.0001 (0.1146)  acc1: 100.0000 (97.1690)  acc5: 100.0000 (99.9167)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1300/1459]  eta: 0:00:00  loss: 0.0000 (0.1172)  acc1: 100.0000 (97.0792)  acc5: 100.0000 (99.9231)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1400/1459]  eta: 0:00:00  loss: 0.0000 (0.1216)  acc1: 100.0000 (97.1449)  acc5: 100.0000 (99.9286)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:  Total time: 0:00:07\n",
            "Test:  Acc@1 97.258 Acc@5 99.931  Kappa 0.969 Loss 0.117\n",
            "Epoch: [10]  [ 0/46]  eta: 0:00:02  lr: 0.0003  img/s: 4566.354900443136  loss: 0.0655 (0.0655)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  time: 0.0496  data: 0.0216  max mem: 282\n",
            "Epoch: [10]  [10/46]  eta: 0:00:01  lr: 0.0003  img/s: 5420.748303715671  loss: 0.0069 (0.0201)  acc1: 100.0000 (99.5739)  acc5: 100.0000 (100.0000)  time: 0.0448  data: 0.0196  max mem: 282\n",
            "Epoch: [10]  [20/46]  eta: 0:00:01  lr: 0.0003  img/s: 5285.046828701653  loss: 0.0058 (0.0156)  acc1: 100.0000 (99.5908)  acc5: 100.0000 (100.0000)  time: 0.0441  data: 0.0197  max mem: 282\n",
            "Epoch: [10]  [30/46]  eta: 0:00:00  lr: 0.0003  img/s: 5245.082524888381  loss: 0.0048 (0.0159)  acc1: 100.0000 (99.5716)  acc5: 100.0000 (100.0000)  time: 0.0438  data: 0.0200  max mem: 282\n",
            "Epoch: [10]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 5560.778406148364  loss: 0.0071 (0.0142)  acc1: 100.0000 (99.6380)  acc5: 100.0000 (100.0000)  time: 0.0431  data: 0.0196  max mem: 282\n",
            "Epoch: [10] Total time: 0:00:01\n",
            "Test:   [   0/1459]  eta: 0:00:09  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0063  data: 0.0009  max mem: 282\n",
            "Test:   [ 100/1459]  eta: 0:00:06  loss: 0.0000 (0.0295)  acc1: 100.0000 (99.0099)  acc5: 100.0000 (100.0000)  time: 0.0049  data: 0.0003  max mem: 282\n",
            "Test:   [ 200/1459]  eta: 0:00:06  loss: 0.0001 (0.0223)  acc1: 100.0000 (99.0050)  acc5: 100.0000 (100.0000)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 300/1459]  eta: 0:00:05  loss: 0.0000 (0.1179)  acc1: 100.0000 (98.3389)  acc5: 100.0000 (99.6678)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 400/1459]  eta: 0:00:05  loss: 0.0000 (0.1281)  acc1: 100.0000 (98.2544)  acc5: 100.0000 (99.7506)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 500/1459]  eta: 0:00:04  loss: 0.0001 (0.1137)  acc1: 100.0000 (98.0040)  acc5: 100.0000 (99.8004)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 600/1459]  eta: 0:00:04  loss: 0.0000 (0.1025)  acc1: 100.0000 (98.0033)  acc5: 100.0000 (99.8336)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 700/1459]  eta: 0:00:03  loss: 0.0002 (0.0963)  acc1: 100.0000 (97.8602)  acc5: 100.0000 (99.8573)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 800/1459]  eta: 0:00:03  loss: 0.0000 (0.1205)  acc1: 100.0000 (97.6280)  acc5: 100.0000 (99.8752)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 900/1459]  eta: 0:00:02  loss: 0.0000 (0.1101)  acc1: 100.0000 (97.7802)  acc5: 100.0000 (99.8890)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1000/1459]  eta: 0:00:02  loss: 0.0000 (0.1022)  acc1: 100.0000 (97.9021)  acc5: 100.0000 (99.9001)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [1100/1459]  eta: 0:00:01  loss: 0.0000 (0.0990)  acc1: 100.0000 (97.9110)  acc5: 100.0000 (99.9092)  time: 0.0055  data: 0.0003  max mem: 282\n",
            "Test:   [1200/1459]  eta: 0:00:01  loss: 0.0000 (0.1032)  acc1: 100.0000 (97.7519)  acc5: 100.0000 (99.9167)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1300/1459]  eta: 0:00:00  loss: 0.0001 (0.1073)  acc1: 100.0000 (97.6941)  acc5: 100.0000 (99.9231)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [1400/1459]  eta: 0:00:00  loss: 0.0000 (0.1118)  acc1: 100.0000 (97.5732)  acc5: 100.0000 (99.9286)  time: 0.0054  data: 0.0003  max mem: 282\n",
            "Test:  Total time: 0:00:07\n",
            "Test:  Acc@1 97.533 Acc@5 99.931  Kappa 0.972 Loss 0.109\n",
            "Epoch: [11]  [ 0/46]  eta: 0:00:02  lr: 0.0003  img/s: 5030.319525518378  loss: 0.0135 (0.0135)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0475  data: 0.0221  max mem: 282\n",
            "Epoch: [11]  [10/46]  eta: 0:00:01  lr: 0.0003  img/s: 5457.72460836239  loss: 0.0063 (0.0135)  acc1: 100.0000 (99.7159)  acc5: 100.0000 (100.0000)  time: 0.0455  data: 0.0206  max mem: 282\n",
            "Epoch: [11]  [20/46]  eta: 0:00:01  lr: 0.0003  img/s: 5477.380346065948  loss: 0.0049 (0.0139)  acc1: 100.0000 (99.7396)  acc5: 100.0000 (100.0000)  time: 0.0441  data: 0.0200  max mem: 282\n",
            "Epoch: [11]  [30/46]  eta: 0:00:00  lr: 0.0003  img/s: 5375.428405506884  loss: 0.0049 (0.0125)  acc1: 100.0000 (99.6976)  acc5: 100.0000 (100.0000)  time: 0.0430  data: 0.0195  max mem: 282\n",
            "Epoch: [11]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 5388.701201457407  loss: 0.0072 (0.0122)  acc1: 100.0000 (99.6570)  acc5: 100.0000 (100.0000)  time: 0.0433  data: 0.0196  max mem: 282\n",
            "Epoch: [11] Total time: 0:00:02\n",
            "Test:   [   0/1459]  eta: 0:00:07  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0053  data: 0.0005  max mem: 282\n",
            "Test:   [ 100/1459]  eta: 0:00:06  loss: 0.0000 (0.0415)  acc1: 100.0000 (98.0198)  acc5: 100.0000 (100.0000)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 200/1459]  eta: 0:00:06  loss: 0.0003 (0.0539)  acc1: 100.0000 (97.5124)  acc5: 100.0000 (100.0000)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 300/1459]  eta: 0:00:05  loss: 0.0000 (0.1152)  acc1: 100.0000 (97.3422)  acc5: 100.0000 (99.6678)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 400/1459]  eta: 0:00:05  loss: 0.0001 (0.0961)  acc1: 100.0000 (97.5062)  acc5: 100.0000 (99.7506)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 500/1459]  eta: 0:00:04  loss: 0.0003 (0.1131)  acc1: 100.0000 (97.2056)  acc5: 100.0000 (99.8004)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 600/1459]  eta: 0:00:04  loss: 0.0000 (0.1228)  acc1: 100.0000 (97.1714)  acc5: 100.0000 (99.8336)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 700/1459]  eta: 0:00:03  loss: 0.0001 (0.1133)  acc1: 100.0000 (97.2896)  acc5: 100.0000 (99.8573)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 800/1459]  eta: 0:00:03  loss: 0.0000 (0.1198)  acc1: 100.0000 (97.1286)  acc5: 100.0000 (99.8752)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 900/1459]  eta: 0:00:02  loss: 0.0000 (0.1230)  acc1: 100.0000 (97.1143)  acc5: 100.0000 (99.8890)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1000/1459]  eta: 0:00:02  loss: 0.0000 (0.1125)  acc1: 100.0000 (97.3027)  acc5: 100.0000 (99.9001)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1100/1459]  eta: 0:00:01  loss: 0.0000 (0.1036)  acc1: 100.0000 (97.5477)  acc5: 100.0000 (99.9092)  time: 0.0055  data: 0.0003  max mem: 282\n",
            "Test:   [1200/1459]  eta: 0:00:01  loss: 0.0000 (0.1138)  acc1: 100.0000 (97.4188)  acc5: 100.0000 (99.9167)  time: 0.0055  data: 0.0004  max mem: 282\n",
            "Test:   [1300/1459]  eta: 0:00:00  loss: 0.0000 (0.1152)  acc1: 100.0000 (97.3098)  acc5: 100.0000 (99.9231)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1400/1459]  eta: 0:00:00  loss: 0.0000 (0.1316)  acc1: 100.0000 (97.1449)  acc5: 100.0000 (99.8572)  time: 0.0056  data: 0.0003  max mem: 282\n",
            "Test:  Total time: 0:00:07\n",
            "Test:  Acc@1 97.053 Acc@5 99.863  Kappa 0.967 Loss 0.131\n",
            "Epoch: [12]  [ 0/46]  eta: 0:00:02  lr: 0.0003  img/s: 4678.613612200435  loss: 0.0613 (0.0613)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0482  data: 0.0208  max mem: 282\n",
            "Epoch: [12]  [10/46]  eta: 0:00:01  lr: 0.0003  img/s: 5100.087510805855  loss: 0.0409 (0.0441)  acc1: 99.2188 (98.8636)  acc5: 100.0000 (100.0000)  time: 0.0463  data: 0.0199  max mem: 282\n",
            "Epoch: [12]  [20/46]  eta: 0:00:01  lr: 0.0003  img/s: 5480.847254833901  loss: 0.0300 (0.0387)  acc1: 99.2188 (98.9583)  acc5: 100.0000 (100.0000)  time: 0.0447  data: 0.0197  max mem: 282\n",
            "Epoch: [12]  [30/46]  eta: 0:00:00  lr: 0.0003  img/s: 5537.1491986220835  loss: 0.0125 (0.0329)  acc1: 99.2188 (99.0927)  acc5: 100.0000 (99.9748)  time: 0.0432  data: 0.0196  max mem: 282\n",
            "Epoch: [12]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 5462.8893320851475  loss: 0.0168 (0.0316)  acc1: 99.2188 (99.1235)  acc5: 100.0000 (99.9809)  time: 0.0429  data: 0.0194  max mem: 282\n",
            "Epoch: [12] Total time: 0:00:02\n",
            "Test:   [   0/1459]  eta: 0:00:07  loss: 0.0001 (0.0001)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0054  data: 0.0005  max mem: 282\n",
            "Test:   [ 100/1459]  eta: 0:00:07  loss: 0.0000 (0.0595)  acc1: 100.0000 (99.0099)  acc5: 100.0000 (100.0000)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 200/1459]  eta: 0:00:06  loss: 0.0001 (0.0325)  acc1: 100.0000 (99.5025)  acc5: 100.0000 (100.0000)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [ 300/1459]  eta: 0:00:05  loss: 0.0000 (0.0895)  acc1: 100.0000 (98.3389)  acc5: 100.0000 (99.6678)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [ 400/1459]  eta: 0:00:05  loss: 0.0001 (0.0834)  acc1: 100.0000 (98.2544)  acc5: 100.0000 (99.7506)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [ 500/1459]  eta: 0:00:04  loss: 0.0001 (0.0780)  acc1: 100.0000 (98.0040)  acc5: 100.0000 (99.8004)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [ 600/1459]  eta: 0:00:04  loss: 0.0000 (0.0745)  acc1: 100.0000 (97.8369)  acc5: 100.0000 (99.8336)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 700/1459]  eta: 0:00:03  loss: 0.0000 (0.0738)  acc1: 100.0000 (97.8602)  acc5: 100.0000 (99.8573)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [ 800/1459]  eta: 0:00:03  loss: 0.0000 (0.0808)  acc1: 100.0000 (97.7528)  acc5: 100.0000 (99.8752)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 900/1459]  eta: 0:00:02  loss: 0.0000 (0.0749)  acc1: 100.0000 (97.8912)  acc5: 100.0000 (99.8890)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1000/1459]  eta: 0:00:02  loss: 0.0001 (0.0680)  acc1: 100.0000 (98.1019)  acc5: 100.0000 (99.9001)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1100/1459]  eta: 0:00:01  loss: 0.0000 (0.0719)  acc1: 100.0000 (98.1835)  acc5: 100.0000 (99.9092)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [1200/1459]  eta: 0:00:01  loss: 0.0000 (0.0769)  acc1: 100.0000 (98.0849)  acc5: 100.0000 (99.9167)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [1300/1459]  eta: 0:00:00  loss: 0.0000 (0.0743)  acc1: 100.0000 (98.0784)  acc5: 100.0000 (99.9231)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1400/1459]  eta: 0:00:00  loss: 0.0000 (0.0754)  acc1: 100.0000 (98.1442)  acc5: 100.0000 (99.9286)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:  Total time: 0:00:07\n",
            "Test:  Acc@1 98.149 Acc@5 99.931  Kappa 0.979 Loss 0.078\n",
            "Epoch: [13]  [ 0/46]  eta: 0:00:02  lr: 0.0003  img/s: 4717.173162759639  loss: 0.0023 (0.0023)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0496  data: 0.0224  max mem: 282\n",
            "Epoch: [13]  [10/46]  eta: 0:00:01  lr: 0.0003  img/s: 5178.902348912362  loss: 0.0096 (0.0268)  acc1: 100.0000 (99.1477)  acc5: 100.0000 (100.0000)  time: 0.0479  data: 0.0217  max mem: 282\n",
            "Epoch: [13]  [20/46]  eta: 0:00:01  lr: 0.0003  img/s: 5484.934890326008  loss: 0.0096 (0.0206)  acc1: 100.0000 (99.3304)  acc5: 100.0000 (99.9628)  time: 0.0473  data: 0.0219  max mem: 282\n",
            "Epoch: [13]  [30/46]  eta: 0:00:00  lr: 0.0003  img/s: 5406.173905162778  loss: 0.0055 (0.0177)  acc1: 100.0000 (99.3952)  acc5: 100.0000 (99.9748)  time: 0.0454  data: 0.0212  max mem: 282\n",
            "Epoch: [13]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 5430.398446350542  loss: 0.0061 (0.0188)  acc1: 100.0000 (99.4093)  acc5: 100.0000 (99.9809)  time: 0.0437  data: 0.0200  max mem: 282\n",
            "Epoch: [13] Total time: 0:00:02\n",
            "Test:   [   0/1459]  eta: 0:00:07  loss: 0.0019 (0.0019)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0053  data: 0.0005  max mem: 282\n",
            "Test:   [ 100/1459]  eta: 0:00:07  loss: 0.0000 (0.0262)  acc1: 100.0000 (99.0099)  acc5: 100.0000 (100.0000)  time: 0.0054  data: 0.0003  max mem: 282\n",
            "Test:   [ 200/1459]  eta: 0:00:06  loss: 0.0001 (0.0381)  acc1: 100.0000 (99.0050)  acc5: 100.0000 (100.0000)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 300/1459]  eta: 0:00:06  loss: 0.0000 (0.1047)  acc1: 100.0000 (98.3389)  acc5: 100.0000 (99.6678)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 400/1459]  eta: 0:00:05  loss: 0.0002 (0.0922)  acc1: 100.0000 (98.0050)  acc5: 100.0000 (99.7506)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 500/1459]  eta: 0:00:05  loss: 0.0001 (0.0780)  acc1: 100.0000 (98.4032)  acc5: 100.0000 (99.8004)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 600/1459]  eta: 0:00:04  loss: 0.0000 (0.0799)  acc1: 100.0000 (98.3361)  acc5: 100.0000 (99.8336)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 700/1459]  eta: 0:00:03  loss: 0.0001 (0.0779)  acc1: 100.0000 (98.4308)  acc5: 100.0000 (99.8573)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [ 800/1459]  eta: 0:00:03  loss: 0.0000 (0.0821)  acc1: 100.0000 (98.2522)  acc5: 100.0000 (99.8752)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 900/1459]  eta: 0:00:02  loss: 0.0001 (0.0818)  acc1: 100.0000 (98.1132)  acc5: 100.0000 (99.8890)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [1000/1459]  eta: 0:00:02  loss: 0.0001 (0.0763)  acc1: 100.0000 (98.2018)  acc5: 100.0000 (99.9001)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1100/1459]  eta: 0:00:01  loss: 0.0000 (0.0742)  acc1: 100.0000 (98.2743)  acc5: 100.0000 (99.9092)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1200/1459]  eta: 0:00:01  loss: 0.0001 (0.0761)  acc1: 100.0000 (98.2515)  acc5: 100.0000 (99.9167)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1300/1459]  eta: 0:00:00  loss: 0.0000 (0.0746)  acc1: 100.0000 (98.2321)  acc5: 100.0000 (99.9231)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1400/1459]  eta: 0:00:00  loss: 0.0000 (0.0816)  acc1: 100.0000 (98.1442)  acc5: 100.0000 (99.9286)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:  Total time: 0:00:07\n",
            "Test:  Acc@1 98.149 Acc@5 99.931  Kappa 0.979 Loss 0.082\n",
            "Epoch: [14]  [ 0/46]  eta: 0:00:02  lr: 0.0003  img/s: 4446.872459206494  loss: 0.0164 (0.0164)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0509  data: 0.0221  max mem: 282\n",
            "Epoch: [14]  [10/46]  eta: 0:00:01  lr: 0.0003  img/s: 5241.037447772267  loss: 0.0040 (0.0101)  acc1: 100.0000 (99.5739)  acc5: 100.0000 (100.0000)  time: 0.0473  data: 0.0213  max mem: 282\n",
            "Epoch: [14]  [20/46]  eta: 0:00:01  lr: 0.0003  img/s: 5424.308279868654  loss: 0.0047 (0.0138)  acc1: 100.0000 (99.6280)  acc5: 100.0000 (100.0000)  time: 0.0462  data: 0.0212  max mem: 282\n",
            "Epoch: [14]  [30/46]  eta: 0:00:00  lr: 0.0003  img/s: 5516.099293111952  loss: 0.0050 (0.0149)  acc1: 100.0000 (99.5212)  acc5: 100.0000 (100.0000)  time: 0.0446  data: 0.0206  max mem: 282\n",
            "Epoch: [14]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 5352.437709363535  loss: 0.0116 (0.0157)  acc1: 99.2188 (99.4855)  acc5: 100.0000 (100.0000)  time: 0.0445  data: 0.0207  max mem: 282\n",
            "Epoch: [14] Total time: 0:00:02\n",
            "Test:   [   0/1459]  eta: 0:00:08  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0056  data: 0.0005  max mem: 282\n",
            "Test:   [ 100/1459]  eta: 0:00:07  loss: 0.0000 (0.0245)  acc1: 100.0000 (99.0099)  acc5: 100.0000 (100.0000)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [ 200/1459]  eta: 0:00:06  loss: 0.0000 (0.0396)  acc1: 100.0000 (98.5075)  acc5: 100.0000 (100.0000)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [ 300/1459]  eta: 0:00:06  loss: 0.0000 (0.1264)  acc1: 100.0000 (98.0066)  acc5: 100.0000 (99.6678)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 400/1459]  eta: 0:00:05  loss: 0.0001 (0.1133)  acc1: 100.0000 (97.7556)  acc5: 100.0000 (99.7506)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [ 500/1459]  eta: 0:00:05  loss: 0.0000 (0.1187)  acc1: 100.0000 (97.4052)  acc5: 100.0000 (99.8004)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [ 600/1459]  eta: 0:00:04  loss: 0.0000 (0.1123)  acc1: 100.0000 (97.3378)  acc5: 100.0000 (99.8336)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 700/1459]  eta: 0:00:03  loss: 0.0000 (0.1065)  acc1: 100.0000 (97.4322)  acc5: 100.0000 (99.8573)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 800/1459]  eta: 0:00:03  loss: 0.0000 (0.1256)  acc1: 100.0000 (97.2534)  acc5: 100.0000 (99.7503)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [ 900/1459]  eta: 0:00:02  loss: 0.0000 (0.1301)  acc1: 100.0000 (97.2253)  acc5: 100.0000 (99.7780)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1000/1459]  eta: 0:00:02  loss: 0.0000 (0.1204)  acc1: 100.0000 (97.4026)  acc5: 100.0000 (99.8002)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1100/1459]  eta: 0:00:01  loss: 0.0000 (0.1132)  acc1: 100.0000 (97.4569)  acc5: 100.0000 (99.8183)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1200/1459]  eta: 0:00:01  loss: 0.0000 (0.1126)  acc1: 100.0000 (97.1690)  acc5: 100.0000 (99.8335)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1300/1459]  eta: 0:00:00  loss: 0.0000 (0.1169)  acc1: 100.0000 (97.0792)  acc5: 100.0000 (99.8463)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1400/1459]  eta: 0:00:00  loss: 0.0000 (0.1178)  acc1: 100.0000 (97.0735)  acc5: 100.0000 (99.8572)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:  Total time: 0:00:07\n",
            "Test:  Acc@1 97.190 Acc@5 99.863  Kappa 0.968 Loss 0.114\n",
            "Epoch: [15]  [ 0/46]  eta: 0:00:02  lr: 0.0003  img/s: 4576.514465944932  loss: 0.0378 (0.0378)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0490  data: 0.0211  max mem: 282\n",
            "Epoch: [15]  [10/46]  eta: 0:00:01  lr: 0.0003  img/s: 5096.021034446754  loss: 0.0239 (0.0273)  acc1: 99.2188 (99.0767)  acc5: 100.0000 (100.0000)  time: 0.0461  data: 0.0199  max mem: 282\n",
            "Epoch: [15]  [20/46]  eta: 0:00:01  lr: 0.0003  img/s: 5547.963831392285  loss: 0.0160 (0.0236)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0448  data: 0.0198  max mem: 282\n",
            "Epoch: [15]  [30/46]  eta: 0:00:00  lr: 0.0003  img/s: 5397.6404729349315  loss: 0.0109 (0.0219)  acc1: 100.0000 (99.2944)  acc5: 100.0000 (100.0000)  time: 0.0435  data: 0.0198  max mem: 282\n",
            "Epoch: [15]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 5428.257100391293  loss: 0.0092 (0.0192)  acc1: 100.0000 (99.3712)  acc5: 100.0000 (100.0000)  time: 0.0431  data: 0.0194  max mem: 282\n",
            "Epoch: [15] Total time: 0:00:02\n",
            "Test:   [   0/1459]  eta: 0:00:08  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0058  data: 0.0005  max mem: 282\n",
            "Test:   [ 100/1459]  eta: 0:00:07  loss: 0.0000 (0.0162)  acc1: 100.0000 (99.0099)  acc5: 100.0000 (100.0000)  time: 0.0057  data: 0.0004  max mem: 282\n",
            "Test:   [ 200/1459]  eta: 0:00:06  loss: 0.0006 (0.0266)  acc1: 100.0000 (99.0050)  acc5: 100.0000 (100.0000)  time: 0.0058  data: 0.0004  max mem: 282\n",
            "Test:   [ 300/1459]  eta: 0:00:06  loss: 0.0000 (0.0953)  acc1: 100.0000 (98.3389)  acc5: 100.0000 (99.6678)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 400/1459]  eta: 0:00:05  loss: 0.0001 (0.0771)  acc1: 100.0000 (98.5037)  acc5: 100.0000 (99.7506)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 500/1459]  eta: 0:00:05  loss: 0.0001 (0.0665)  acc1: 100.0000 (98.6028)  acc5: 100.0000 (99.8004)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 600/1459]  eta: 0:00:04  loss: 0.0000 (0.0778)  acc1: 100.0000 (98.3361)  acc5: 100.0000 (99.8336)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 700/1459]  eta: 0:00:04  loss: 0.0000 (0.0800)  acc1: 100.0000 (98.4308)  acc5: 100.0000 (99.8573)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [ 800/1459]  eta: 0:00:03  loss: 0.0000 (0.0932)  acc1: 100.0000 (98.2522)  acc5: 100.0000 (99.8752)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 900/1459]  eta: 0:00:02  loss: 0.0000 (0.0875)  acc1: 100.0000 (98.1132)  acc5: 100.0000 (99.8890)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [1000/1459]  eta: 0:00:02  loss: 0.0000 (0.0814)  acc1: 100.0000 (98.2018)  acc5: 100.0000 (99.9001)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [1100/1459]  eta: 0:00:01  loss: 0.0000 (0.0819)  acc1: 100.0000 (98.1835)  acc5: 100.0000 (99.9092)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [1200/1459]  eta: 0:00:01  loss: 0.0000 (0.0867)  acc1: 100.0000 (98.1682)  acc5: 100.0000 (99.9167)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1300/1459]  eta: 0:00:00  loss: 0.0000 (0.0885)  acc1: 100.0000 (98.1553)  acc5: 100.0000 (99.9231)  time: 0.0056  data: 0.0003  max mem: 282\n",
            "Test:   [1400/1459]  eta: 0:00:00  loss: 0.0000 (0.0922)  acc1: 100.0000 (98.2156)  acc5: 100.0000 (99.9286)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:  Total time: 0:00:07\n",
            "Test:  Acc@1 98.286 Acc@5 99.931  Kappa 0.981 Loss 0.089\n",
            "Epoch: [16]  [ 0/46]  eta: 0:00:02  lr: 0.0003  img/s: 4903.60242955656  loss: 0.0058 (0.0058)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0497  data: 0.0236  max mem: 282\n",
            "Epoch: [16]  [10/46]  eta: 0:00:01  lr: 0.0003  img/s: 5546.5309006756615  loss: 0.0058 (0.0084)  acc1: 100.0000 (99.6449)  acc5: 100.0000 (100.0000)  time: 0.0437  data: 0.0194  max mem: 282\n",
            "Epoch: [16]  [20/46]  eta: 0:00:01  lr: 0.0003  img/s: 5231.793094711403  loss: 0.0027 (0.0062)  acc1: 100.0000 (99.8140)  acc5: 100.0000 (100.0000)  time: 0.0432  data: 0.0193  max mem: 282\n",
            "Epoch: [16]  [30/46]  eta: 0:00:00  lr: 0.0003  img/s: 5508.51523670764  loss: 0.0025 (0.0061)  acc1: 100.0000 (99.7984)  acc5: 100.0000 (100.0000)  time: 0.0434  data: 0.0196  max mem: 282\n",
            "Epoch: [16]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 5451.351610413874  loss: 0.0034 (0.0079)  acc1: 100.0000 (99.7523)  acc5: 100.0000 (100.0000)  time: 0.0435  data: 0.0196  max mem: 282\n",
            "Epoch: [16] Total time: 0:00:01\n",
            "Test:   [   0/1459]  eta: 0:00:08  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0058  data: 0.0005  max mem: 282\n",
            "Test:   [ 100/1459]  eta: 0:00:07  loss: 0.0000 (0.0483)  acc1: 100.0000 (99.0099)  acc5: 100.0000 (100.0000)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 200/1459]  eta: 0:00:06  loss: 0.0000 (0.0748)  acc1: 100.0000 (98.5075)  acc5: 100.0000 (100.0000)  time: 0.0054  data: 0.0003  max mem: 282\n",
            "Test:   [ 300/1459]  eta: 0:00:06  loss: 0.0000 (0.1283)  acc1: 100.0000 (98.0066)  acc5: 100.0000 (99.6678)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [ 400/1459]  eta: 0:00:05  loss: 0.0000 (0.1211)  acc1: 100.0000 (97.7556)  acc5: 100.0000 (99.7506)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [ 500/1459]  eta: 0:00:05  loss: 0.0001 (0.1183)  acc1: 100.0000 (97.4052)  acc5: 100.0000 (99.8004)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 600/1459]  eta: 0:00:04  loss: 0.0000 (0.1109)  acc1: 100.0000 (97.5042)  acc5: 100.0000 (99.8336)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [ 700/1459]  eta: 0:00:04  loss: 0.0000 (0.1104)  acc1: 100.0000 (97.5749)  acc5: 100.0000 (99.8573)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 800/1459]  eta: 0:00:03  loss: 0.0000 (0.1159)  acc1: 100.0000 (97.2534)  acc5: 100.0000 (99.8752)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [ 900/1459]  eta: 0:00:02  loss: 0.0000 (0.1053)  acc1: 100.0000 (97.4473)  acc5: 100.0000 (99.8890)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [1000/1459]  eta: 0:00:02  loss: 0.0000 (0.0970)  acc1: 100.0000 (97.6024)  acc5: 100.0000 (99.9001)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [1100/1459]  eta: 0:00:01  loss: 0.0000 (0.0951)  acc1: 100.0000 (97.6385)  acc5: 100.0000 (99.9092)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1200/1459]  eta: 0:00:01  loss: 0.0000 (0.1068)  acc1: 100.0000 (97.5021)  acc5: 100.0000 (99.9167)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [1300/1459]  eta: 0:00:00  loss: 0.0000 (0.1083)  acc1: 100.0000 (97.3098)  acc5: 100.0000 (99.9231)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1400/1459]  eta: 0:00:00  loss: 0.0000 (0.1075)  acc1: 100.0000 (97.4304)  acc5: 100.0000 (99.9286)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:  Total time: 0:00:07\n",
            "Test:  Acc@1 97.464 Acc@5 99.931  Kappa 0.972 Loss 0.104\n",
            "Epoch: [17]  [ 0/46]  eta: 0:00:02  lr: 0.0003  img/s: 4655.003919120452  loss: 0.0014 (0.0014)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0482  data: 0.0207  max mem: 282\n",
            "Epoch: [17]  [10/46]  eta: 0:00:01  lr: 0.0003  img/s: 5454.896484454379  loss: 0.0043 (0.0045)  acc1: 100.0000 (99.9290)  acc5: 100.0000 (100.0000)  time: 0.0460  data: 0.0199  max mem: 282\n",
            "Epoch: [17]  [20/46]  eta: 0:00:01  lr: 0.0003  img/s: 5476.709838005468  loss: 0.0027 (0.0065)  acc1: 100.0000 (99.8140)  acc5: 100.0000 (100.0000)  time: 0.0447  data: 0.0198  max mem: 282\n",
            "Epoch: [17]  [30/46]  eta: 0:00:00  lr: 0.0003  img/s: 5462.166793842648  loss: 0.0018 (0.0073)  acc1: 100.0000 (99.8236)  acc5: 100.0000 (100.0000)  time: 0.0430  data: 0.0194  max mem: 282\n",
            "Epoch: [17]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 5395.145332127425  loss: 0.0025 (0.0077)  acc1: 100.0000 (99.7904)  acc5: 100.0000 (100.0000)  time: 0.0428  data: 0.0193  max mem: 282\n",
            "Epoch: [17] Total time: 0:00:02\n",
            "Test:   [   0/1459]  eta: 0:00:08  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0055  data: 0.0005  max mem: 282\n",
            "Test:   [ 100/1459]  eta: 0:00:07  loss: 0.0000 (0.0406)  acc1: 100.0000 (99.0099)  acc5: 100.0000 (100.0000)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 200/1459]  eta: 0:00:06  loss: 0.0000 (0.0342)  acc1: 100.0000 (98.5075)  acc5: 100.0000 (100.0000)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 300/1459]  eta: 0:00:05  loss: 0.0000 (0.1238)  acc1: 100.0000 (97.3422)  acc5: 100.0000 (99.6678)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 400/1459]  eta: 0:00:05  loss: 0.0000 (0.1120)  acc1: 100.0000 (97.5062)  acc5: 100.0000 (99.7506)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 500/1459]  eta: 0:00:04  loss: 0.0000 (0.0985)  acc1: 100.0000 (97.8044)  acc5: 100.0000 (99.8004)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 600/1459]  eta: 0:00:04  loss: 0.0000 (0.0889)  acc1: 100.0000 (97.8369)  acc5: 100.0000 (99.8336)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 700/1459]  eta: 0:00:03  loss: 0.0000 (0.0892)  acc1: 100.0000 (97.7175)  acc5: 100.0000 (99.8573)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 800/1459]  eta: 0:00:03  loss: 0.0000 (0.1045)  acc1: 100.0000 (97.5031)  acc5: 100.0000 (99.8752)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [ 900/1459]  eta: 0:00:02  loss: 0.0000 (0.1032)  acc1: 100.0000 (97.4473)  acc5: 100.0000 (99.8890)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [1000/1459]  eta: 0:00:02  loss: 0.0000 (0.0977)  acc1: 100.0000 (97.6024)  acc5: 100.0000 (99.9001)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1100/1459]  eta: 0:00:01  loss: 0.0000 (0.0967)  acc1: 100.0000 (97.5477)  acc5: 100.0000 (99.9092)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1200/1459]  eta: 0:00:01  loss: 0.0000 (0.1008)  acc1: 100.0000 (97.5021)  acc5: 100.0000 (99.9167)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [1300/1459]  eta: 0:00:00  loss: 0.0000 (0.0949)  acc1: 100.0000 (97.5404)  acc5: 100.0000 (99.9231)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1400/1459]  eta: 0:00:00  loss: 0.0000 (0.0960)  acc1: 100.0000 (97.6445)  acc5: 100.0000 (99.9286)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:  Total time: 0:00:07\n",
            "Test:  Acc@1 97.601 Acc@5 99.931  Kappa 0.973 Loss 0.096\n",
            "Epoch: [18]  [ 0/46]  eta: 0:00:02  lr: 0.0003  img/s: 4678.124396577265  loss: 0.0021 (0.0021)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0492  data: 0.0218  max mem: 282\n",
            "Epoch: [18]  [10/46]  eta: 0:00:01  lr: 0.0003  img/s: 5456.670650892385  loss: 0.0021 (0.0030)  acc1: 100.0000 (99.9290)  acc5: 100.0000 (100.0000)  time: 0.0465  data: 0.0206  max mem: 282\n",
            "Epoch: [18]  [20/46]  eta: 0:00:01  lr: 0.0003  img/s: 5535.55061555276  loss: 0.0019 (0.0076)  acc1: 100.0000 (99.8512)  acc5: 100.0000 (100.0000)  time: 0.0452  data: 0.0204  max mem: 282\n",
            "Epoch: [18]  [30/46]  eta: 0:00:00  lr: 0.0003  img/s: 4987.003845653669  loss: 0.0019 (0.0082)  acc1: 100.0000 (99.8488)  acc5: 100.0000 (100.0000)  time: 0.0446  data: 0.0205  max mem: 282\n",
            "Epoch: [18]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 5439.972763197892  loss: 0.0014 (0.0087)  acc1: 100.0000 (99.7713)  acc5: 100.0000 (100.0000)  time: 0.0445  data: 0.0204  max mem: 282\n",
            "Epoch: [18] Total time: 0:00:02\n",
            "Test:   [   0/1459]  eta: 0:00:07  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0054  data: 0.0005  max mem: 282\n",
            "Test:   [ 100/1459]  eta: 0:00:06  loss: 0.0000 (0.0416)  acc1: 100.0000 (98.0198)  acc5: 100.0000 (100.0000)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 200/1459]  eta: 0:00:06  loss: 0.0000 (0.0527)  acc1: 100.0000 (97.0149)  acc5: 100.0000 (100.0000)  time: 0.0054  data: 0.0003  max mem: 282\n",
            "Test:   [ 300/1459]  eta: 0:00:05  loss: 0.0000 (0.1361)  acc1: 100.0000 (96.6777)  acc5: 100.0000 (99.6678)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 400/1459]  eta: 0:00:05  loss: 0.0000 (0.1278)  acc1: 100.0000 (96.7581)  acc5: 100.0000 (99.7506)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [ 500/1459]  eta: 0:00:04  loss: 0.0001 (0.1042)  acc1: 100.0000 (97.4052)  acc5: 100.0000 (99.8004)  time: 0.0054  data: 0.0003  max mem: 282\n",
            "Test:   [ 600/1459]  eta: 0:00:04  loss: 0.0000 (0.1044)  acc1: 100.0000 (97.3378)  acc5: 100.0000 (99.8336)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 700/1459]  eta: 0:00:03  loss: 0.0000 (0.0981)  acc1: 100.0000 (97.5749)  acc5: 100.0000 (99.8573)  time: 0.0058  data: 0.0004  max mem: 282\n",
            "Test:   [ 800/1459]  eta: 0:00:03  loss: 0.0000 (0.1089)  acc1: 100.0000 (97.5031)  acc5: 100.0000 (99.8752)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [ 900/1459]  eta: 0:00:02  loss: 0.0000 (0.1008)  acc1: 100.0000 (97.6693)  acc5: 100.0000 (99.8890)  time: 0.0055  data: 0.0003  max mem: 282\n",
            "Test:   [1000/1459]  eta: 0:00:02  loss: 0.0000 (0.0919)  acc1: 100.0000 (97.8022)  acc5: 100.0000 (99.9001)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1100/1459]  eta: 0:00:01  loss: 0.0000 (0.0930)  acc1: 100.0000 (97.8202)  acc5: 100.0000 (99.9092)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1200/1459]  eta: 0:00:01  loss: 0.0000 (0.0947)  acc1: 100.0000 (97.7519)  acc5: 100.0000 (99.9167)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1300/1459]  eta: 0:00:00  loss: 0.0000 (0.0890)  acc1: 100.0000 (97.8478)  acc5: 100.0000 (99.9231)  time: 0.0053  data: 0.0004  max mem: 282\n",
            "Test:   [1400/1459]  eta: 0:00:00  loss: 0.0000 (0.0898)  acc1: 100.0000 (97.9300)  acc5: 100.0000 (99.9286)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:  Total time: 0:00:07\n",
            "Test:  Acc@1 97.944 Acc@5 99.931  Kappa 0.977 Loss 0.089\n",
            "Epoch: [19]  [ 0/46]  eta: 0:00:02  lr: 0.0003  img/s: 4760.000283718126  loss: 0.0018 (0.0018)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0494  data: 0.0225  max mem: 282\n",
            "Epoch: [19]  [10/46]  eta: 0:00:01  lr: 0.0003  img/s: 5526.319759542142  loss: 0.0023 (0.0043)  acc1: 100.0000 (99.8580)  acc5: 100.0000 (100.0000)  time: 0.0455  data: 0.0201  max mem: 282\n",
            "Epoch: [19]  [20/46]  eta: 0:00:01  lr: 0.0003  img/s: 5500.782917857765  loss: 0.0013 (0.0029)  acc1: 100.0000 (99.9256)  acc5: 100.0000 (100.0000)  time: 0.0440  data: 0.0197  max mem: 282\n",
            "Epoch: [19]  [30/46]  eta: 0:00:00  lr: 0.0003  img/s: 5431.387329785727  loss: 0.0008 (0.0026)  acc1: 100.0000 (99.9496)  acc5: 100.0000 (100.0000)  time: 0.0430  data: 0.0194  max mem: 282\n",
            "Epoch: [19]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 5329.325405255165  loss: 0.0014 (0.0052)  acc1: 100.0000 (99.9047)  acc5: 100.0000 (100.0000)  time: 0.0430  data: 0.0193  max mem: 282\n",
            "Epoch: [19] Total time: 0:00:02\n",
            "Test:   [   0/1459]  eta: 0:00:08  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0055  data: 0.0005  max mem: 282\n",
            "Test:   [ 100/1459]  eta: 0:00:07  loss: 0.0000 (0.0155)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [ 200/1459]  eta: 0:00:06  loss: 0.0000 (0.0449)  acc1: 100.0000 (98.5075)  acc5: 100.0000 (100.0000)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 300/1459]  eta: 0:00:05  loss: 0.0000 (0.1242)  acc1: 100.0000 (97.3422)  acc5: 100.0000 (99.6678)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 400/1459]  eta: 0:00:05  loss: 0.0000 (0.1146)  acc1: 100.0000 (97.2569)  acc5: 100.0000 (99.7506)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [ 500/1459]  eta: 0:00:04  loss: 0.0000 (0.1025)  acc1: 100.0000 (97.4052)  acc5: 100.0000 (99.8004)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [ 600/1459]  eta: 0:00:04  loss: 0.0000 (0.0917)  acc1: 100.0000 (97.5042)  acc5: 100.0000 (99.8336)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [ 700/1459]  eta: 0:00:03  loss: 0.0000 (0.0887)  acc1: 100.0000 (97.7175)  acc5: 100.0000 (99.8573)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 800/1459]  eta: 0:00:03  loss: 0.0000 (0.1069)  acc1: 100.0000 (97.3783)  acc5: 100.0000 (99.8752)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [ 900/1459]  eta: 0:00:02  loss: 0.0000 (0.0976)  acc1: 100.0000 (97.5583)  acc5: 100.0000 (99.8890)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1000/1459]  eta: 0:00:02  loss: 0.0000 (0.0880)  acc1: 100.0000 (97.8022)  acc5: 100.0000 (99.9001)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1100/1459]  eta: 0:00:01  loss: 0.0000 (0.0860)  acc1: 100.0000 (97.8202)  acc5: 100.0000 (99.9092)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1200/1459]  eta: 0:00:01  loss: 0.0000 (0.0914)  acc1: 100.0000 (97.6686)  acc5: 100.0000 (99.9167)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [1300/1459]  eta: 0:00:00  loss: 0.0000 (0.0936)  acc1: 100.0000 (97.6172)  acc5: 100.0000 (99.9231)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1400/1459]  eta: 0:00:00  loss: 0.0000 (0.0931)  acc1: 100.0000 (97.7159)  acc5: 100.0000 (99.9286)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:  Total time: 0:00:07\n",
            "Test:  Acc@1 97.738 Acc@5 99.931  Kappa 0.975 Loss 0.090\n",
            "Epoch: [20]  [ 0/46]  eta: 0:00:02  lr: 0.0003  img/s: 4488.586984148217  loss: 0.0288 (0.0288)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0495  data: 0.0210  max mem: 282\n",
            "Epoch: [20]  [10/46]  eta: 0:00:01  lr: 0.0003  img/s: 5325.941807287481  loss: 0.0025 (0.0072)  acc1: 100.0000 (99.7869)  acc5: 100.0000 (100.0000)  time: 0.0456  data: 0.0196  max mem: 282\n",
            "Epoch: [20]  [20/46]  eta: 0:00:01  lr: 0.0003  img/s: 5435.7316917593935  loss: 0.0014 (0.0067)  acc1: 100.0000 (99.7396)  acc5: 100.0000 (100.0000)  time: 0.0446  data: 0.0197  max mem: 282\n",
            "Epoch: [20]  [30/46]  eta: 0:00:00  lr: 0.0003  img/s: 5411.896050482853  loss: 0.0005 (0.0070)  acc1: 100.0000 (99.6976)  acc5: 100.0000 (100.0000)  time: 0.0439  data: 0.0200  max mem: 282\n",
            "Epoch: [20]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 5506.255379376833  loss: 0.0017 (0.0066)  acc1: 100.0000 (99.6951)  acc5: 100.0000 (100.0000)  time: 0.0432  data: 0.0195  max mem: 282\n",
            "Epoch: [20] Total time: 0:00:02\n",
            "Test:   [   0/1459]  eta: 0:00:11  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0080  data: 0.0004  max mem: 282\n",
            "Test:   [ 100/1459]  eta: 0:00:07  loss: 0.0000 (0.0508)  acc1: 100.0000 (98.0198)  acc5: 100.0000 (100.0000)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 200/1459]  eta: 0:00:06  loss: 0.0000 (0.0931)  acc1: 100.0000 (97.5124)  acc5: 100.0000 (100.0000)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 300/1459]  eta: 0:00:05  loss: 0.0000 (0.1414)  acc1: 100.0000 (96.6777)  acc5: 100.0000 (99.6678)  time: 0.0049  data: 0.0003  max mem: 282\n",
            "Test:   [ 400/1459]  eta: 0:00:05  loss: 0.0000 (0.1163)  acc1: 100.0000 (97.0075)  acc5: 100.0000 (99.7506)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 500/1459]  eta: 0:00:04  loss: 0.0000 (0.0965)  acc1: 100.0000 (97.4052)  acc5: 100.0000 (99.8004)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [ 600/1459]  eta: 0:00:04  loss: 0.0000 (0.0872)  acc1: 100.0000 (97.5042)  acc5: 100.0000 (99.8336)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 700/1459]  eta: 0:00:03  loss: 0.0000 (0.0837)  acc1: 100.0000 (97.7175)  acc5: 100.0000 (99.8573)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [ 800/1459]  eta: 0:00:03  loss: 0.0000 (0.1081)  acc1: 100.0000 (97.2534)  acc5: 100.0000 (99.8752)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 900/1459]  eta: 0:00:02  loss: 0.0000 (0.1003)  acc1: 100.0000 (97.4473)  acc5: 100.0000 (99.8890)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1000/1459]  eta: 0:00:02  loss: 0.0000 (0.0924)  acc1: 100.0000 (97.6024)  acc5: 100.0000 (99.9001)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1100/1459]  eta: 0:00:01  loss: 0.0000 (0.0882)  acc1: 100.0000 (97.7293)  acc5: 100.0000 (99.9092)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1200/1459]  eta: 0:00:01  loss: 0.0000 (0.0904)  acc1: 100.0000 (97.6686)  acc5: 100.0000 (99.9167)  time: 0.0055  data: 0.0003  max mem: 282\n",
            "Test:   [1300/1459]  eta: 0:00:00  loss: 0.0000 (0.0953)  acc1: 100.0000 (97.6172)  acc5: 100.0000 (99.9231)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1400/1459]  eta: 0:00:00  loss: 0.0000 (0.0972)  acc1: 100.0000 (97.7159)  acc5: 100.0000 (99.9286)  time: 0.0056  data: 0.0003  max mem: 282\n",
            "Test:  Total time: 0:00:07\n",
            "Test:  Acc@1 97.738 Acc@5 99.931  Kappa 0.975 Loss 0.096\n",
            "Epoch: [21]  [ 0/46]  eta: 0:00:02  lr: 0.0003  img/s: 4515.162753145394  loss: 0.0003 (0.0003)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0505  data: 0.0221  max mem: 282\n",
            "Epoch: [21]  [10/46]  eta: 0:00:01  lr: 0.0003  img/s: 5393.08586812392  loss: 0.0003 (0.0017)  acc1: 100.0000 (99.9290)  acc5: 100.0000 (100.0000)  time: 0.0462  data: 0.0199  max mem: 282\n",
            "Epoch: [21]  [20/46]  eta: 0:00:01  lr: 0.0003  img/s: 5312.555409323451  loss: 0.0014 (0.0069)  acc1: 100.0000 (99.8140)  acc5: 100.0000 (100.0000)  time: 0.0445  data: 0.0196  max mem: 282\n",
            "Epoch: [21]  [30/46]  eta: 0:00:00  lr: 0.0003  img/s: 5227.157689761265  loss: 0.0014 (0.0068)  acc1: 100.0000 (99.7984)  acc5: 100.0000 (100.0000)  time: 0.0435  data: 0.0196  max mem: 282\n",
            "Epoch: [21]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 5270.778063578708  loss: 0.0013 (0.0066)  acc1: 100.0000 (99.7904)  acc5: 100.0000 (100.0000)  time: 0.0435  data: 0.0196  max mem: 282\n",
            "Epoch: [21] Total time: 0:00:02\n",
            "Test:   [   0/1459]  eta: 0:00:07  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0052  data: 0.0004  max mem: 282\n",
            "Test:   [ 100/1459]  eta: 0:00:07  loss: 0.0000 (0.0720)  acc1: 100.0000 (97.0297)  acc5: 100.0000 (100.0000)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 200/1459]  eta: 0:00:06  loss: 0.0000 (0.0934)  acc1: 100.0000 (97.5124)  acc5: 100.0000 (100.0000)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [ 300/1459]  eta: 0:00:05  loss: 0.0000 (0.1451)  acc1: 100.0000 (97.0100)  acc5: 100.0000 (99.6678)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [ 400/1459]  eta: 0:00:05  loss: 0.0001 (0.1255)  acc1: 100.0000 (97.0075)  acc5: 100.0000 (99.7506)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 500/1459]  eta: 0:00:04  loss: 0.0001 (0.1093)  acc1: 100.0000 (97.2056)  acc5: 100.0000 (99.8004)  time: 0.0056  data: 0.0003  max mem: 282\n",
            "Test:   [ 600/1459]  eta: 0:00:04  loss: 0.0000 (0.1052)  acc1: 100.0000 (97.3378)  acc5: 100.0000 (99.8336)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 700/1459]  eta: 0:00:03  loss: 0.0000 (0.0980)  acc1: 100.0000 (97.5749)  acc5: 100.0000 (99.8573)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 800/1459]  eta: 0:00:03  loss: 0.0000 (0.1077)  acc1: 100.0000 (97.3783)  acc5: 100.0000 (99.8752)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 900/1459]  eta: 0:00:02  loss: 0.0000 (0.0998)  acc1: 100.0000 (97.4473)  acc5: 100.0000 (99.8890)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1000/1459]  eta: 0:00:02  loss: 0.0000 (0.0919)  acc1: 100.0000 (97.5025)  acc5: 100.0000 (99.9001)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [1100/1459]  eta: 0:00:01  loss: 0.0000 (0.0924)  acc1: 100.0000 (97.5477)  acc5: 100.0000 (99.9092)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [1200/1459]  eta: 0:00:01  loss: 0.0000 (0.1000)  acc1: 100.0000 (97.4188)  acc5: 100.0000 (99.9167)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [1300/1459]  eta: 0:00:00  loss: 0.0000 (0.0954)  acc1: 100.0000 (97.5404)  acc5: 100.0000 (99.9231)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1400/1459]  eta: 0:00:00  loss: 0.0000 (0.0972)  acc1: 100.0000 (97.6445)  acc5: 100.0000 (99.9286)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:  Total time: 0:00:07\n",
            "Test:  Acc@1 97.738 Acc@5 99.931  Kappa 0.975 Loss 0.094\n",
            "Epoch: [22]  [ 0/46]  eta: 0:00:02  lr: 0.0003  img/s: 5011.256214238377  loss: 0.0357 (0.0357)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0470  data: 0.0214  max mem: 282\n",
            "Epoch: [22]  [10/46]  eta: 0:00:01  lr: 0.0003  img/s: 5360.454020807956  loss: 0.0037 (0.0065)  acc1: 100.0000 (99.9290)  acc5: 100.0000 (100.0000)  time: 0.0475  data: 0.0215  max mem: 282\n",
            "Epoch: [22]  [20/46]  eta: 0:00:01  lr: 0.0003  img/s: 5438.925650143351  loss: 0.0020 (0.0051)  acc1: 100.0000 (99.8884)  acc5: 100.0000 (100.0000)  time: 0.0463  data: 0.0212  max mem: 282\n",
            "Epoch: [22]  [30/46]  eta: 0:00:00  lr: 0.0003  img/s: 5432.211674474608  loss: 0.0016 (0.0049)  acc1: 100.0000 (99.8488)  acc5: 100.0000 (100.0000)  time: 0.0439  data: 0.0202  max mem: 282\n",
            "Epoch: [22]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 5412.769060149618  loss: 0.0015 (0.0042)  acc1: 100.0000 (99.8857)  acc5: 100.0000 (100.0000)  time: 0.0431  data: 0.0196  max mem: 282\n",
            "Epoch: [22] Total time: 0:00:02\n",
            "Test:   [   0/1459]  eta: 0:00:08  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0055  data: 0.0005  max mem: 282\n",
            "Test:   [ 100/1459]  eta: 0:00:07  loss: 0.0000 (0.0299)  acc1: 100.0000 (98.0198)  acc5: 100.0000 (100.0000)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 200/1459]  eta: 0:00:06  loss: 0.0000 (0.0489)  acc1: 100.0000 (98.5075)  acc5: 100.0000 (100.0000)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 300/1459]  eta: 0:00:05  loss: 0.0000 (0.1523)  acc1: 100.0000 (97.6744)  acc5: 100.0000 (99.6678)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [ 400/1459]  eta: 0:00:05  loss: 0.0000 (0.1330)  acc1: 100.0000 (98.0050)  acc5: 100.0000 (99.7506)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 500/1459]  eta: 0:00:04  loss: 0.0000 (0.1083)  acc1: 100.0000 (98.4032)  acc5: 100.0000 (99.8004)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 600/1459]  eta: 0:00:04  loss: 0.0000 (0.1013)  acc1: 100.0000 (98.1697)  acc5: 100.0000 (99.8336)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 700/1459]  eta: 0:00:03  loss: 0.0000 (0.0924)  acc1: 100.0000 (98.2882)  acc5: 100.0000 (99.8573)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [ 800/1459]  eta: 0:00:03  loss: 0.0000 (0.1195)  acc1: 100.0000 (97.8777)  acc5: 100.0000 (99.8752)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 900/1459]  eta: 0:00:02  loss: 0.0000 (0.1077)  acc1: 100.0000 (98.0022)  acc5: 100.0000 (99.8890)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1000/1459]  eta: 0:00:02  loss: 0.0000 (0.0990)  acc1: 100.0000 (98.1019)  acc5: 100.0000 (99.9001)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [1100/1459]  eta: 0:00:01  loss: 0.0000 (0.0923)  acc1: 100.0000 (98.1835)  acc5: 100.0000 (99.9092)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1200/1459]  eta: 0:00:01  loss: 0.0000 (0.0931)  acc1: 100.0000 (97.9184)  acc5: 100.0000 (99.9167)  time: 0.0054  data: 0.0003  max mem: 282\n",
            "Test:   [1300/1459]  eta: 0:00:00  loss: 0.0000 (0.0944)  acc1: 100.0000 (97.9247)  acc5: 100.0000 (99.9231)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1400/1459]  eta: 0:00:00  loss: 0.0000 (0.0966)  acc1: 100.0000 (97.9300)  acc5: 100.0000 (99.9286)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:  Total time: 0:00:07\n",
            "Test:  Acc@1 98.012 Acc@5 99.931  Kappa 0.978 Loss 0.093\n",
            "Epoch: [23]  [ 0/46]  eta: 0:00:02  lr: 0.0003  img/s: 4585.857402772676  loss: 0.0001 (0.0001)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0487  data: 0.0208  max mem: 282\n",
            "Epoch: [23]  [10/46]  eta: 0:00:01  lr: 0.0003  img/s: 5382.812087669695  loss: 0.0006 (0.0065)  acc1: 100.0000 (99.7159)  acc5: 100.0000 (100.0000)  time: 0.0453  data: 0.0195  max mem: 282\n",
            "Epoch: [23]  [20/46]  eta: 0:00:01  lr: 0.0003  img/s: 5101.347497648255  loss: 0.0006 (0.0077)  acc1: 100.0000 (99.7024)  acc5: 100.0000 (100.0000)  time: 0.0446  data: 0.0197  max mem: 282\n",
            "Epoch: [23]  [30/46]  eta: 0:00:00  lr: 0.0003  img/s: 5497.403332002171  loss: 0.0008 (0.0055)  acc1: 100.0000 (99.7984)  acc5: 100.0000 (100.0000)  time: 0.0445  data: 0.0206  max mem: 282\n",
            "Epoch: [23]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 5362.970741306802  loss: 0.0009 (0.0059)  acc1: 100.0000 (99.7904)  acc5: 100.0000 (100.0000)  time: 0.0440  data: 0.0203  max mem: 282\n",
            "Epoch: [23] Total time: 0:00:02\n",
            "Test:   [   0/1459]  eta: 0:00:08  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0062  data: 0.0006  max mem: 282\n",
            "Test:   [ 100/1459]  eta: 0:00:07  loss: 0.0000 (0.0526)  acc1: 100.0000 (98.0198)  acc5: 100.0000 (100.0000)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 200/1459]  eta: 0:00:06  loss: 0.0000 (0.0892)  acc1: 100.0000 (96.5174)  acc5: 100.0000 (100.0000)  time: 0.0058  data: 0.0004  max mem: 282\n",
            "Test:   [ 300/1459]  eta: 0:00:06  loss: 0.0000 (0.1885)  acc1: 100.0000 (95.6811)  acc5: 100.0000 (99.6678)  time: 0.0054  data: 0.0003  max mem: 282\n",
            "Test:   [ 400/1459]  eta: 0:00:05  loss: 0.0000 (0.1995)  acc1: 100.0000 (95.7606)  acc5: 100.0000 (99.7506)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 500/1459]  eta: 0:00:05  loss: 0.0000 (0.1840)  acc1: 100.0000 (95.8084)  acc5: 100.0000 (99.8004)  time: 0.0054  data: 0.0003  max mem: 282\n",
            "Test:   [ 600/1459]  eta: 0:00:04  loss: 0.0000 (0.1836)  acc1: 100.0000 (95.5075)  acc5: 100.0000 (99.8336)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 700/1459]  eta: 0:00:03  loss: 0.0000 (0.1721)  acc1: 100.0000 (95.4351)  acc5: 100.0000 (99.8573)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 800/1459]  eta: 0:00:03  loss: 0.0000 (0.1883)  acc1: 100.0000 (95.2559)  acc5: 100.0000 (99.8752)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 900/1459]  eta: 0:00:02  loss: 0.0000 (0.1773)  acc1: 100.0000 (95.3385)  acc5: 100.0000 (99.8890)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1000/1459]  eta: 0:00:02  loss: 0.0000 (0.1717)  acc1: 100.0000 (95.3047)  acc5: 100.0000 (99.9001)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1100/1459]  eta: 0:00:01  loss: 0.0000 (0.1710)  acc1: 100.0000 (95.4587)  acc5: 100.0000 (99.9092)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1200/1459]  eta: 0:00:01  loss: 0.0000 (0.1724)  acc1: 100.0000 (95.5037)  acc5: 100.0000 (99.9167)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1300/1459]  eta: 0:00:00  loss: 0.0000 (0.1745)  acc1: 100.0000 (95.5419)  acc5: 100.0000 (99.9231)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1400/1459]  eta: 0:00:00  loss: 0.0000 (0.1671)  acc1: 100.0000 (95.7887)  acc5: 100.0000 (99.9286)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:  Total time: 0:00:07\n",
            "Test:  Acc@1 95.682 Acc@5 99.931  Kappa 0.952 Loss 0.164\n",
            "Epoch: [24]  [ 0/46]  eta: 0:00:02  lr: 0.0003  img/s: 4622.180713037339  loss: 0.0096 (0.0096)  acc1: 99.2188 (99.2188)  acc5: 100.0000 (100.0000)  time: 0.0486  data: 0.0209  max mem: 282\n",
            "Epoch: [24]  [10/46]  eta: 0:00:01  lr: 0.0003  img/s: 5334.249865866503  loss: 0.0012 (0.0131)  acc1: 100.0000 (99.4318)  acc5: 100.0000 (100.0000)  time: 0.0452  data: 0.0193  max mem: 282\n",
            "Epoch: [24]  [20/46]  eta: 0:00:01  lr: 0.0003  img/s: 5293.123319004614  loss: 0.0008 (0.0175)  acc1: 100.0000 (99.5164)  acc5: 100.0000 (100.0000)  time: 0.0438  data: 0.0192  max mem: 282\n",
            "Epoch: [24]  [30/46]  eta: 0:00:00  lr: 0.0003  img/s: 5352.918011864998  loss: 0.0032 (0.0171)  acc1: 100.0000 (99.5464)  acc5: 100.0000 (100.0000)  time: 0.0430  data: 0.0194  max mem: 282\n",
            "Epoch: [24]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 5422.500323206205  loss: 0.0041 (0.0157)  acc1: 100.0000 (99.5808)  acc5: 100.0000 (100.0000)  time: 0.0430  data: 0.0194  max mem: 282\n",
            "Epoch: [24] Total time: 0:00:01\n",
            "Test:   [   0/1459]  eta: 0:00:07  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0053  data: 0.0005  max mem: 282\n",
            "Test:   [ 100/1459]  eta: 0:00:07  loss: 0.0000 (0.0452)  acc1: 100.0000 (98.0198)  acc5: 100.0000 (100.0000)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 200/1459]  eta: 0:00:06  loss: 0.0000 (0.0498)  acc1: 100.0000 (98.0100)  acc5: 100.0000 (100.0000)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [ 300/1459]  eta: 0:00:06  loss: 0.0000 (0.1466)  acc1: 100.0000 (96.3455)  acc5: 100.0000 (99.6678)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [ 400/1459]  eta: 0:00:05  loss: 0.0000 (0.1524)  acc1: 100.0000 (96.7581)  acc5: 100.0000 (99.7506)  time: 0.0054  data: 0.0003  max mem: 282\n",
            "Test:   [ 500/1459]  eta: 0:00:05  loss: 0.0000 (0.1235)  acc1: 100.0000 (97.4052)  acc5: 100.0000 (99.8004)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 600/1459]  eta: 0:00:04  loss: 0.0000 (0.1316)  acc1: 100.0000 (96.8386)  acc5: 100.0000 (99.8336)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 700/1459]  eta: 0:00:03  loss: 0.0000 (0.1204)  acc1: 100.0000 (97.1469)  acc5: 100.0000 (99.8573)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [ 800/1459]  eta: 0:00:03  loss: 0.0000 (0.1385)  acc1: 100.0000 (97.0037)  acc5: 100.0000 (99.8752)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 900/1459]  eta: 0:00:02  loss: 0.0000 (0.1360)  acc1: 100.0000 (97.0033)  acc5: 100.0000 (99.8890)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1000/1459]  eta: 0:00:02  loss: 0.0000 (0.1227)  acc1: 100.0000 (97.3027)  acc5: 100.0000 (99.9001)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1100/1459]  eta: 0:00:01  loss: 0.0000 (0.1256)  acc1: 100.0000 (97.3660)  acc5: 100.0000 (99.9092)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1200/1459]  eta: 0:00:01  loss: 0.0000 (0.1270)  acc1: 100.0000 (97.2523)  acc5: 100.0000 (99.9167)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1300/1459]  eta: 0:00:00  loss: 0.0000 (0.1320)  acc1: 100.0000 (97.1560)  acc5: 100.0000 (99.9231)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [1400/1459]  eta: 0:00:00  loss: 0.0000 (0.1338)  acc1: 100.0000 (97.2877)  acc5: 100.0000 (99.8572)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:  Total time: 0:00:07\n",
            "Test:  Acc@1 97.395 Acc@5 99.863  Kappa 0.971 Loss 0.129\n",
            "Epoch: [25]  [ 0/46]  eta: 0:00:02  lr: 0.0003  img/s: 4570.125406472922  loss: 0.0018 (0.0018)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0499  data: 0.0219  max mem: 282\n",
            "Epoch: [25]  [10/46]  eta: 0:00:01  lr: 0.0003  img/s: 5380.492398352391  loss: 0.0031 (0.0072)  acc1: 100.0000 (99.7869)  acc5: 100.0000 (100.0000)  time: 0.0460  data: 0.0200  max mem: 282\n",
            "Epoch: [25]  [20/46]  eta: 0:00:01  lr: 0.0003  img/s: 5394.928472375746  loss: 0.0031 (0.0086)  acc1: 100.0000 (99.7768)  acc5: 100.0000 (100.0000)  time: 0.0444  data: 0.0196  max mem: 282\n",
            "Epoch: [25]  [30/46]  eta: 0:00:00  lr: 0.0003  img/s: 5329.5899299144285  loss: 0.0035 (0.0112)  acc1: 100.0000 (99.5968)  acc5: 100.0000 (100.0000)  time: 0.0440  data: 0.0200  max mem: 282\n",
            "Epoch: [25]  [40/46]  eta: 0:00:00  lr: 0.0003  img/s: 5400.518172033276  loss: 0.0057 (0.0100)  acc1: 100.0000 (99.6380)  acc5: 100.0000 (100.0000)  time: 0.0442  data: 0.0203  max mem: 282\n",
            "Epoch: [25] Total time: 0:00:02\n",
            "Test:   [   0/1459]  eta: 0:00:08  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0055  data: 0.0006  max mem: 282\n",
            "Test:   [ 100/1459]  eta: 0:00:07  loss: 0.0000 (0.0158)  acc1: 100.0000 (99.0099)  acc5: 100.0000 (100.0000)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 200/1459]  eta: 0:00:06  loss: 0.0000 (0.0653)  acc1: 100.0000 (98.0100)  acc5: 100.0000 (100.0000)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 300/1459]  eta: 0:00:05  loss: 0.0000 (0.1517)  acc1: 100.0000 (97.0100)  acc5: 100.0000 (99.6678)  time: 0.0055  data: 0.0003  max mem: 282\n",
            "Test:   [ 400/1459]  eta: 0:00:05  loss: 0.0000 (0.1398)  acc1: 100.0000 (96.7581)  acc5: 100.0000 (99.7506)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [ 500/1459]  eta: 0:00:05  loss: 0.0000 (0.1246)  acc1: 100.0000 (97.0060)  acc5: 100.0000 (99.8004)  time: 0.0060  data: 0.0004  max mem: 282\n",
            "Test:   [ 600/1459]  eta: 0:00:04  loss: 0.0000 (0.1232)  acc1: 100.0000 (97.0050)  acc5: 100.0000 (99.8336)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 700/1459]  eta: 0:00:03  loss: 0.0000 (0.1112)  acc1: 100.0000 (97.1469)  acc5: 100.0000 (99.8573)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 800/1459]  eta: 0:00:03  loss: 0.0000 (0.1321)  acc1: 100.0000 (96.8789)  acc5: 100.0000 (99.8752)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 900/1459]  eta: 0:00:02  loss: 0.0000 (0.1255)  acc1: 100.0000 (97.0033)  acc5: 100.0000 (99.8890)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1000/1459]  eta: 0:00:02  loss: 0.0000 (0.1132)  acc1: 100.0000 (97.3027)  acc5: 100.0000 (99.9001)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [1100/1459]  eta: 0:00:01  loss: 0.0000 (0.1128)  acc1: 100.0000 (97.3660)  acc5: 100.0000 (99.9092)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1200/1459]  eta: 0:00:01  loss: 0.0000 (0.1113)  acc1: 100.0000 (97.2523)  acc5: 100.0000 (99.9167)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1300/1459]  eta: 0:00:00  loss: 0.0000 (0.1129)  acc1: 100.0000 (97.2329)  acc5: 100.0000 (99.9231)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1400/1459]  eta: 0:00:00  loss: 0.0000 (0.1121)  acc1: 100.0000 (97.3590)  acc5: 100.0000 (99.9286)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:  Total time: 0:00:07\n",
            "Test:  Acc@1 97.464 Acc@5 99.931  Kappa 0.972 Loss 0.108\n",
            "Early stopping triggered\n",
            "Training time 0:04:23\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "best_kappa = 0.0\n",
        "epochs_without_improvement = 0\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(0, MAX_EPOCHS):\n",
        "  train_metric_logger = train_one_epoch(model, criterion, optimizer, training_loader, device, epoch)\n",
        "  val_metric_logger = evaluate(model, criterion, val_loader, device=device)\n",
        "\n",
        "  checkpoint = {\"model\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
        "\n",
        "  train_loss = train_metric_logger.meters[\"loss\"].global_avg\n",
        "  train_losses.append(train_loss)\n",
        "\n",
        "  val_loss = val_metric_logger.meters[\"loss\"].global_avg\n",
        "  val_losses.append(val_loss)\n",
        "\n",
        "  kappa = val_metric_logger.meters[\"Kappa\"]\n",
        "\n",
        "  plot_losses(train_losses, val_losses, \"train_val_loss_graph.png\")\n",
        "\n",
        "\n",
        "  torch.save(checkpoint, \"checkpoint.pth\")\n",
        "\n",
        "  if kappa > best_kappa:\n",
        "      torch.save(checkpoint, \"best_model.pth\")\n",
        "      epochs_without_improvement = 0\n",
        "      best_kappa = kappa\n",
        "  else:\n",
        "      epochs_without_improvement += 1\n",
        "\n",
        "  if epochs_without_improvement >= PATIENCE:\n",
        "      print(\"Early stopping triggered\")\n",
        "      break\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "print(f\"Training time {total_time_str}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uY4jEYzhSrsk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYbnLvvtbfdK"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4iMYPmBma9dy"
      },
      "outputs": [],
      "source": [
        "CLASSES = [\n",
        "    \"0\",\n",
        "    \"1\",\n",
        "    \"2\",\n",
        "    \"3\",\n",
        "    \"4\",\n",
        "    \"5\",\n",
        "    \"6\",\n",
        "    \"7\",\n",
        "    \"8\",\n",
        "    \"9\"\n",
        "]\n",
        "\n",
        "\n",
        "def test(model, data_loader, device, print_freq=100, log_suffix=\"\"):\n",
        "    model.eval()\n",
        "    metric_logger = MetricLogger(delimiter=\"  \")\n",
        "    header = f\"Test: {log_suffix}\"\n",
        "\n",
        "    num_processed_samples = 0\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "    with torch.inference_mode():\n",
        "        for image, target in metric_logger.log_every(data_loader, print_freq, header):\n",
        "            image = image.to(device, non_blocking=True)\n",
        "            target = target.to(device, non_blocking=True)\n",
        "            output = model(image)\n",
        "            loss = criterion(output, target)\n",
        "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "\n",
        "            batch_size = image.shape[0]\n",
        "            metric_logger.update(loss=loss.item())\n",
        "            metric_logger.meters[\"acc1\"].update(acc1.item(), n=batch_size)\n",
        "            metric_logger.meters[\"acc5\"].update(acc5.item(), n=batch_size)\n",
        "            num_processed_samples += batch_size\n",
        "            _, predictions = output.max(1)\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_targets.extend(target.cpu().numpy())\n",
        "\n",
        "    metric_logger.synchronize_between_processes()\n",
        "\n",
        "    print(f\"{header} Acc@1 {metric_logger.acc1.global_avg:.3f} Acc@5 {metric_logger.acc5.global_avg:.3f} Loss {metric_logger.loss.global_avg:.3f}\") # Test Loss u print etme kısmı buraya eklendi\n",
        "\n",
        "\n",
        "    conf_matrix = confusion_matrix(all_targets, all_predictions)\n",
        "    kappa_score = cohen_kappa_score(all_targets, all_predictions)\n",
        "    print(\"Kappa score: \", kappa_score)\n",
        "\n",
        "\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=CLASSES)\n",
        "    disp.plot()\n",
        "    plt.savefig(os.path.join(\"confusion_matrix.png\"))\n",
        "    plt.clf()\n",
        "    return metric_logger.acc1.global_avg\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "LcqRfaEjTUH9",
        "outputId": "9b0ece87-292e-4c88-8e81-4cc9ab4b338a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start validating\n",
            "Test:   [   0/1459]  eta: 0:00:09  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0063  data: 0.0009  max mem: 282\n",
            "Test:   [ 100/1459]  eta: 0:00:07  loss: 0.0000 (0.0162)  acc1: 100.0000 (99.0099)  acc5: 100.0000 (100.0000)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [ 200/1459]  eta: 0:00:06  loss: 0.0006 (0.0266)  acc1: 100.0000 (99.0050)  acc5: 100.0000 (100.0000)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [ 300/1459]  eta: 0:00:06  loss: 0.0000 (0.0953)  acc1: 100.0000 (98.3389)  acc5: 100.0000 (99.6678)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 400/1459]  eta: 0:00:05  loss: 0.0001 (0.0771)  acc1: 100.0000 (98.5037)  acc5: 100.0000 (99.7506)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [ 500/1459]  eta: 0:00:04  loss: 0.0001 (0.0665)  acc1: 100.0000 (98.6028)  acc5: 100.0000 (99.8004)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [ 600/1459]  eta: 0:00:04  loss: 0.0000 (0.0778)  acc1: 100.0000 (98.3361)  acc5: 100.0000 (99.8336)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [ 700/1459]  eta: 0:00:03  loss: 0.0000 (0.0800)  acc1: 100.0000 (98.4308)  acc5: 100.0000 (99.8573)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 800/1459]  eta: 0:00:03  loss: 0.0000 (0.0932)  acc1: 100.0000 (98.2522)  acc5: 100.0000 (99.8752)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [ 900/1459]  eta: 0:00:02  loss: 0.0000 (0.0875)  acc1: 100.0000 (98.1132)  acc5: 100.0000 (99.8890)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1000/1459]  eta: 0:00:02  loss: 0.0000 (0.0814)  acc1: 100.0000 (98.2018)  acc5: 100.0000 (99.9001)  time: 0.0055  data: 0.0003  max mem: 282\n",
            "Test:   [1100/1459]  eta: 0:00:01  loss: 0.0000 (0.0819)  acc1: 100.0000 (98.1835)  acc5: 100.0000 (99.9092)  time: 0.0054  data: 0.0003  max mem: 282\n",
            "Test:   [1200/1459]  eta: 0:00:01  loss: 0.0000 (0.0867)  acc1: 100.0000 (98.1682)  acc5: 100.0000 (99.9167)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1300/1459]  eta: 0:00:00  loss: 0.0000 (0.0885)  acc1: 100.0000 (98.1553)  acc5: 100.0000 (99.9231)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [1400/1459]  eta: 0:00:00  loss: 0.0000 (0.0922)  acc1: 100.0000 (98.2156)  acc5: 100.0000 (99.9286)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:  Total time: 0:00:07\n",
            "Test:  Acc@1 98.286 Acc@5 99.931 Loss 0.089\n",
            "Kappa score:  0.9807746536406929\n",
            "Validating time 0:00:07\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title Varsayılan başlık metni\n",
        "# Validation results (burayı yeni ekledim)\n",
        "\n",
        "checkpoint = torch.load(\"best_model.pth\", map_location=\"cpu\")\n",
        "model.load_state_dict(checkpoint[\"model\"])\n",
        "\n",
        "print(\"Start validating\")\n",
        "start_time = time.time()\n",
        "test(model, val_loader, device=device)\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "print(f\"Validating time {total_time_str}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVHtrVgOggyn"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "zKADmqDOi3i2",
        "outputId": "a0ff2916-0391-44eb-e451-4936695a87f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start testing\n",
            "Test:   [   0/2007]  eta: 0:00:14  loss: 0.0000 (0.0000)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.0071  data: 0.0010  max mem: 282\n",
            "Test:   [ 100/2007]  eta: 0:00:09  loss: 0.0000 (0.0622)  acc1: 100.0000 (98.0198)  acc5: 100.0000 (100.0000)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 200/2007]  eta: 0:00:09  loss: 0.0001 (0.1688)  acc1: 100.0000 (96.0199)  acc5: 100.0000 (100.0000)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 300/2007]  eta: 0:00:08  loss: 0.0000 (0.1767)  acc1: 100.0000 (96.6777)  acc5: 100.0000 (100.0000)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [ 400/2007]  eta: 0:00:08  loss: 0.0000 (0.1454)  acc1: 100.0000 (97.2569)  acc5: 100.0000 (100.0000)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 500/2007]  eta: 0:00:07  loss: 0.0006 (0.1504)  acc1: 100.0000 (97.4052)  acc5: 100.0000 (100.0000)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [ 600/2007]  eta: 0:00:07  loss: 0.0000 (0.1616)  acc1: 100.0000 (97.0050)  acc5: 100.0000 (100.0000)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [ 700/2007]  eta: 0:00:06  loss: 0.0000 (0.1546)  acc1: 100.0000 (97.1469)  acc5: 100.0000 (100.0000)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 800/2007]  eta: 0:00:06  loss: 0.0000 (0.1394)  acc1: 100.0000 (97.2534)  acc5: 100.0000 (100.0000)  time: 0.0051  data: 0.0003  max mem: 282\n",
            "Test:   [ 900/2007]  eta: 0:00:05  loss: 0.0000 (0.1499)  acc1: 100.0000 (97.1143)  acc5: 100.0000 (100.0000)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1000/2007]  eta: 0:00:05  loss: 0.0000 (0.1807)  acc1: 100.0000 (96.8032)  acc5: 100.0000 (99.9001)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [1100/2007]  eta: 0:00:04  loss: 0.0001 (0.1933)  acc1: 100.0000 (96.2761)  acc5: 100.0000 (99.8183)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [1200/2007]  eta: 0:00:04  loss: 0.0000 (0.1867)  acc1: 100.0000 (96.4197)  acc5: 100.0000 (99.7502)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [1300/2007]  eta: 0:00:03  loss: 0.0000 (0.1782)  acc1: 100.0000 (96.5411)  acc5: 100.0000 (99.7694)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [1400/2007]  eta: 0:00:03  loss: 0.0000 (0.1948)  acc1: 100.0000 (96.1456)  acc5: 100.0000 (99.7859)  time: 0.0053  data: 0.0003  max mem: 282\n",
            "Test:   [1500/2007]  eta: 0:00:02  loss: 0.0000 (0.1889)  acc1: 100.0000 (96.1359)  acc5: 100.0000 (99.8001)  time: 0.0054  data: 0.0003  max mem: 282\n",
            "Test:   [1600/2007]  eta: 0:00:02  loss: 0.0000 (0.1863)  acc1: 100.0000 (96.2523)  acc5: 100.0000 (99.8126)  time: 0.0054  data: 0.0003  max mem: 282\n",
            "Test:   [1700/2007]  eta: 0:00:01  loss: 0.0000 (0.1863)  acc1: 100.0000 (96.2963)  acc5: 100.0000 (99.8236)  time: 0.0055  data: 0.0003  max mem: 282\n",
            "Test:   [1800/2007]  eta: 0:00:01  loss: 0.0000 (0.1878)  acc1: 100.0000 (96.1688)  acc5: 100.0000 (99.8334)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:   [1900/2007]  eta: 0:00:00  loss: 0.0000 (0.2159)  acc1: 100.0000 (95.6865)  acc5: 100.0000 (99.6318)  time: 0.0052  data: 0.0003  max mem: 282\n",
            "Test:   [2000/2007]  eta: 0:00:00  loss: 0.0000 (0.2209)  acc1: 100.0000 (95.6522)  acc5: 100.0000 (99.6002)  time: 0.0050  data: 0.0003  max mem: 282\n",
            "Test:  Total time: 0:00:10\n",
            "Test:  Acc@1 95.665 Acc@5 99.601 Loss 0.220\n",
            "Kappa score:  0.951331459161506\n",
            "Testing time 0:00:10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Test results\n",
        "\n",
        "checkpoint = torch.load(\"best_model.pth\", map_location=\"cpu\")\n",
        "model.load_state_dict(checkpoint[\"model\"])\n",
        "\n",
        "print(\"Start testing\")\n",
        "start_time = time.time()\n",
        "test(model, test_loader, device=device)\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "print(f\"Testing time {total_time_str}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qu4bIxSSdSBm"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}